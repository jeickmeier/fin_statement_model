# --- START FILE: fin_statement_model/logging_config.py ---
"""Centralized logging configuration for the fin_statement_model library."""

import logging

# Attach a NullHandler to the base fin_statement_model logger so that
# all child loggers inherit it and avoid 'No handler' warnings by default.
logging.getLogger("fin_statement_model").addHandler(logging.NullHandler())

# --- END FILE: fin_statement_model/logging_config.py ---

# --- START FILE: fin_statement_model/core/metrics/registry.py ---
"""Registry for loading and accessing metric definitions."""

from __future__ import annotations

import logging
from pathlib import Path
from typing import Any, Union, ClassVar, Callable, TYPE_CHECKING

# Use a try-except block for the YAML import
try:
    import yaml

    HAS_YAML = True
except ImportError:
    HAS_YAML = False

from fin_statement_model.core.errors import ConfigurationError

if TYPE_CHECKING:
    from fin_statement_model.core.nodes.metric_node import MetricCalculation

logger = logging.getLogger(__name__)

# Registry mapping metric type strings to MetricCalculation classes
_registry: ClassVar[dict[str, type[MetricCalculation]]] = {}


class MetricRegistry:
    """Manages loading and accessing metric definitions from YAML files.

    Responsibilities:
    - Discovering and loading YAML metric definitions from specified directories.
    - Validating the structure of loaded metric definitions.
    - Providing access to metric definitions by ID.
    """

    _REQUIRED_FIELDS: ClassVar[list[str]] = ["inputs", "formula", "description", "name"]

    def __init__(self):
        """Initialize the registry with an empty store."""
        self._metrics: dict[str, dict[str, Any]] = {}
        logger.info("MetricRegistry initialized.")

    def load_metrics_from_directory(self, directory_path: Union[str, Path]) -> int:
        """Load all *.yaml metric definitions from a given directory.

        Args:
            directory_path: The path to the directory containing metric YAML files.

        Returns:
            int: The number of metrics successfully loaded.

        Raises:
            ImportError: If PyYAML is not installed.
            FileNotFoundError: If the directory_path does not exist.
            ConfigurationError: If a YAML file is invalid or missing required fields.
        """
        if not HAS_YAML:
            logger.error("PyYAML is required to load metrics from YAML files. Please install it.")
            raise ImportError("PyYAML is required to load metrics from YAML files.")

        dir_path = Path(directory_path)
        if not dir_path.is_dir():
            logger.error(f"Metric directory not found: {dir_path}")
            raise FileNotFoundError(f"Metric directory not found: {dir_path}")

        logger.info(f"Loading metrics from directory: {dir_path}")
        loaded_count = 0
        for filepath in dir_path.glob("*.yaml"):
            metric_id = filepath.stem  # Use filename without extension as ID (e.g., "gross_profit")
            logger.debug(f"Attempting to load metric '{metric_id}' from {filepath}")
            try:
                with open(filepath, encoding="utf-8") as f:
                    data = yaml.safe_load(f)

                if not isinstance(data, dict):
                    raise TypeError("YAML content must be a dictionary.")

                # Validate required fields
                missing_fields = [field for field in self._REQUIRED_FIELDS if field not in data]
                if missing_fields:
                    raise ValueError(f"Missing required fields: {missing_fields}")

                # Basic type validation for key fields
                if not isinstance(data["name"], str):
                    raise TypeError("'name' field must be a string.")
                if not isinstance(data["description"], str):
                    raise TypeError("'description' field must be a string.")
                if not isinstance(data["inputs"], list):
                    raise TypeError("'inputs' field must be a list.")
                if not isinstance(data["formula"], str):
                    raise TypeError("'formula' field must be a string.")

                # Store the validated metric definition
                if metric_id in self._metrics:
                    logger.warning(
                        f"Overwriting existing metric definition for '{metric_id}' from {filepath}"
                    )
                self._metrics[metric_id] = data
                logger.debug(f"Successfully loaded and validated metric '{metric_id}'")
                loaded_count += 1

            except yaml.YAMLError as e:
                logger.exception(f"Error parsing YAML file {filepath}")
                raise ConfigurationError(
                    f"Invalid YAML syntax in {filepath}", config_path=str(filepath)
                ) from e
            except (TypeError, ValueError) as e:
                logger.exception(f"Invalid metric definition structure in {filepath}")
                raise ConfigurationError(
                    f"Invalid metric structure in {filepath}: {e}",
                    config_path=str(filepath),
                ) from e
            except Exception as e:
                logger.error(
                    f"Unexpected error loading metric from {filepath}",
                    exc_info=True,
                )
                raise ConfigurationError(
                    f"Failed to load metric from {filepath} due to: {e}",
                    config_path=str(filepath),
                ) from e

        logger.info(f"Successfully loaded {loaded_count} metrics from {dir_path}.")
        return loaded_count

    def get(self, metric_id: str) -> dict[str, Any]:
        """Retrieve a loaded metric definition by its ID.

        Args:
            metric_id: The identifier of the metric (usually the filename stem).

        Returns:
            Dict[str, Any]: The dictionary containing the metric definition.

        Raises:
            KeyError: If the metric_id is not found in the registry.
        """
        try:
            return self._metrics[metric_id]
        except KeyError:
            logger.warning(f"Metric ID '{metric_id}' not found in registry.")
            raise KeyError(f"Metric ID '{metric_id}' not found. Available: {self.list_metrics()}")

    def list_metrics(self) -> list[str]:
        """Get a sorted list of all loaded metric IDs.

        Returns:
            List[str]: Sorted list of available metric IDs.
        """
        return sorted(self._metrics.keys())

    def __len__(self) -> int:
        """Return the number of loaded metrics."""
        return len(self._metrics)

    def __contains__(self, metric_id: str) -> bool:
        """Check if a metric ID exists in the registry."""
        return metric_id in self._metrics

    @classmethod
    def register(cls, name: str) -> Callable[[type[MetricCalculation]], type[MetricCalculation]]:
        """Class method decorator to register a new metric calculation type.

        Args:
            name: The name of the metric calculation type.

        Returns:
            Callable[[Type["MetricCalculation"]], Type["MetricCalculation"]]: The decorator function.
        """

        def decorator(metric_class: type[MetricCalculation]) -> type[MetricCalculation]:
            _registry[name] = metric_class
            return metric_class

        return decorator

# --- END FILE: fin_statement_model/core/metrics/registry.py ---

# --- START FILE: fin_statement_model/core/metrics/__init__.py ---
"""Metrics Subpackage.

Handles definition, loading, and access for financial metrics.
"""

import logging
from pathlib import Path

from .registry import MetricRegistry, HAS_YAML

logger = logging.getLogger(__name__)

# --- Singleton Registry Instance ---
# Create a single instance of the registry for the application lifetime.
metric_registry = MetricRegistry()

# --- Auto-load Built-in Metrics ---
# Determine the path to the built-in metrics directory relative to this file.
_current_dir = Path(__file__).parent
_builtin_dir = _current_dir / "builtin"

# Attempt to load metrics only if PyYAML is installed and the directory exists.
if HAS_YAML:
    if _builtin_dir.is_dir():
        try:
            loaded_count = metric_registry.load_metrics_from_directory(_builtin_dir)
            logger.info(f"Auto-loaded {loaded_count} built-in metrics from {_builtin_dir}")
        except Exception as e:
            # Log error but don't prevent library import if built-ins fail to load
            logger.error(
                f"Failed to auto-load built-in metrics from {_builtin_dir}: {e}",
                exc_info=True,
            )
    else:
        logger.warning(
            f"Built-in metric directory not found: {_builtin_dir}. No built-in metrics loaded."
        )
else:
    logger.warning("PyYAML not installed. Cannot load YAML metrics. Skipping auto-load.")


# --- Public API ---
__all__ = [
    "MetricRegistry",
    "metric_registry",  # Expose the singleton instance
]

# --- Deprecation Warning for METRIC_DEFINITIONS ---
# Provide a way to access the old dictionary format for compatibility,
# but issue a warning.

# Optional: Remove this completely if breaking change is acceptable
# from .definitions_basic import METRIC_DEFINITIONS as _OLD_METRIC_DEFINITIONS
_OLD_METRIC_DEFINITIONS = {}  # Start empty, populate if needed

# --- END FILE: fin_statement_model/core/metrics/__init__.py ---

# --- START FILE: fin_statement_model/core/nodes/stats_nodes.py ---
"""Nodes for statistical calculations on financial data across periods.

This module provides nodes for common time-series statistical analyses:
- `YoYGrowthNode`: Calculates year-over-year percentage growth.
- `MultiPeriodStatNode`: Computes statistics (mean, stddev, etc.) over a range of periods.
- `TwoPeriodAverageNode`: Calculates the simple average over two specific periods.
"""

import logging
import math
import statistics

# Use lowercase built-in types for annotations
from typing import Optional, Callable, Union
from collections.abc import Sequence

# Use absolute imports
from fin_statement_model.core.nodes.base import Node
from fin_statement_model.core.errors import CalculationError

# Added logger instance
logger = logging.getLogger(__name__)

Numeric = Union[int, float]
StatFunc = Callable[[Sequence[Numeric]], Numeric]


class YoYGrowthNode(Node):
    """Calculates year-over-year (YoY) percentage growth.

    Compares the value of an input node between two specified periods
    (prior and current) and calculates the relative change.

    Growth = (Current Value - Prior Value) / Prior Value

    Attributes:
        name (str): The node's identifier.
        input_node (Node): The node providing the values for comparison.
        prior_period (str): Identifier for the earlier time period.
        current_period (str): Identifier for the later time period.

    Example:
        >>> # Assume revenue_node holds {"2022": 100, "2023": 120}
        >>> revenue_node = FinancialStatementItemNode("revenue", {"2022": 100.0, "2023": 120.0})
        >>> yoy_growth = YoYGrowthNode(
        ...     "revenue_yoy",
        ...     input_node=revenue_node,
        ...     prior_period="2022",
        ...     current_period="2023"
        ... )
        >>> print(yoy_growth.calculate("any_period")) # Period arg is ignored
        0.2
    """

    def __init__(self, name: str, input_node: Node, prior_period: str, current_period: str):
        """Initialize the YoY Growth node.

        Args:
            name (str): The identifier for this growth node.
            input_node (Node): The node whose values will be compared.
            prior_period (str): The identifier for the earlier period.
            current_period (str): The identifier for the later period.

        Raises:
            TypeError: If `input_node` is not a Node instance or periods are not strings.
        """
        super().__init__(name)
        if not isinstance(input_node, Node):
            raise TypeError("YoYGrowthNode input_node must be a Node instance.")
        if not isinstance(prior_period, str) or not isinstance(current_period, str):
            raise TypeError("YoYGrowthNode prior_period and current_period must be strings.")

        self.input_node = input_node
        self.prior_period = prior_period
        self.current_period = current_period

    def calculate(self, period: Optional[str] = None) -> float:
        """Calculate the year-over-year growth rate.

        Retrieves values for the prior and current periods from the input node
        and computes the percentage growth. The `period` argument is ignored
        as the calculation periods are fixed during initialization.

        Args:
            period (Optional[str]): Ignored. The calculation uses the periods
                defined during initialization.

        Returns:
            float: The calculated growth rate (e.g., 0.2 for 20% growth).
                   Returns `float('nan')` if the prior period value is zero
                   or non-numeric.

        Raises:
            CalculationError: If the input node fails to provide numeric values
                for the required periods.
        """
        try:
            prior_value = self.input_node.calculate(self.prior_period)
            current_value = self.input_node.calculate(self.current_period)

            # Validate input types
            if not isinstance(prior_value, (int, float)):
                raise TypeError(f"Prior period ('{self.prior_period}') value is non-numeric.")
            if not isinstance(current_value, (int, float)):
                raise TypeError(f"Current period ('{self.current_period}') value is non-numeric.")

            # Handle division by zero or non-finite prior value
            if prior_value == 0 or not math.isfinite(prior_value):
                logger.warning(
                    f"YoYGrowthNode '{self.name}': Prior period '{self.prior_period}' value is zero or non-finite ({prior_value}). Returning NaN."
                )
                return float("nan")

            # Calculate growth
            growth = (float(current_value) - float(prior_value)) / float(prior_value)
            return growth

        except Exception as e:
            # Wrap any exception during calculation
            raise CalculationError(
                message=f"Failed to calculate YoY growth for node '{self.name}'",
                node_id=self.name,
                period=f"{self.prior_period}_to_{self.current_period}",  # Indicate period span
                details={
                    "input_node": self.input_node.name,
                    "prior_period": self.prior_period,
                    "current_period": self.current_period,
                    "original_error": str(e),
                },
            ) from e

    def get_dependencies(self) -> list[str]:
        """Return the names of nodes this node depends on."""
        return [self.input_node.name]

    def has_calculation(self) -> bool:
        """Indicate that this node performs a calculation."""
        return True


class MultiPeriodStatNode(Node):
    """Calculates a statistical measure across multiple periods.

    Applies a specified statistical function (e.g., mean, standard deviation)
    to the values of an input node over a list of periods.

    Attributes:
        name (str): The node's identifier.
        input_node (Node): The node providing the values for analysis.
        periods (List[str]): The list of period identifiers to include.
        stat_func (StatFunc): The statistical function to apply (e.g.,
            `statistics.mean`, `statistics.stdev`). Must accept a sequence
            of numbers and return a single number.

    Example:
        >>> # Assume sales_node holds {"Q1": 10, "Q2": 12, "Q3": 11, "Q4": 13}
        >>> sales_node = FinancialStatementItemNode("sales", {"Q1": 10, "Q2": 12, "Q3": 11, "Q4": 13})
        >>> mean_sales = MultiPeriodStatNode(
        ...     "avg_quarterly_sales",
        ...     input_node=sales_node,
        ...     periods=["Q1", "Q2", "Q3", "Q4"],
        ...     stat_func=statistics.mean
        ... )
        >>> print(mean_sales.calculate()) # Period arg is ignored
        11.5
        >>> stddev_sales = MultiPeriodStatNode(
        ...     "sales_volatility",
        ...     input_node=sales_node,
        ...     periods=["Q1", "Q2", "Q3", "Q4"],
        ...     stat_func=statistics.stdev # Default
        ... )
        >>> print(round(stddev_sales.calculate(), 2))
        1.29
    """

    def __init__(
        self,
        name: str,
        input_node: Node,
        periods: list[str],
        stat_func: StatFunc = statistics.stdev,  # Default to standard deviation
    ):
        """Initialize the multi-period statistics node.

        Args:
            name (str): The identifier for this statistical node.
            input_node (Node): The node providing the source values.
            periods (List[str]): A list of period identifiers to analyze.
            stat_func (StatFunc): The statistical function to apply. Defaults to
                `statistics.stdev`. It must accept a sequence of numerics and
                return a numeric value.

        Raises:
            ValueError: If `periods` is not a list or is empty.
            TypeError: If `input_node` is not a Node, `periods` contains non-strings,
                or `stat_func` is not callable.
        """
        super().__init__(name)
        if not isinstance(input_node, Node):
            raise TypeError("MultiPeriodStatNode input_node must be a Node instance.")
        if not isinstance(periods, list) or not periods:
            raise ValueError("MultiPeriodStatNode periods must be a non-empty list.")
        if not all(isinstance(p, str) for p in periods):
            raise TypeError("MultiPeriodStatNode periods must contain only strings.")
        if not callable(stat_func):
            raise TypeError("MultiPeriodStatNode stat_func must be a callable function.")

        self.input_node = input_node
        self.periods = periods
        self.stat_func = stat_func

    def calculate(self, period: Optional[str] = None) -> float:
        """Calculate the statistical measure across the specified periods.

        Retrieves values from the input node for each period in the configured list,
        then applies the `stat_func`. The `period` argument is ignored.

        Args:
            period (Optional[str]): Ignored. Calculation uses the periods defined
                during initialization.

        Returns:
            float: The result of the statistical function. Returns `float('nan')`
                   if the statistical function requires more data points than
                   available (e.g., standard deviation with < 2 values) or if
                   no valid numeric data is found.

        Raises:
            CalculationError: If retrieving input node values fails or if the
                statistical function itself raises an unexpected error.
        """
        values: list[Numeric] = []
        retrieval_errors = []
        try:
            for p in self.periods:
                try:
                    value = self.input_node.calculate(p)
                    if isinstance(value, (int, float)) and math.isfinite(value):
                        values.append(float(value))
                    else:
                        # Log non-numeric/non-finite values but continue if possible
                        logger.warning(
                            f"MultiPeriodStatNode '{self.name}': Input '{self.input_node.name}' gave non-numeric/non-finite value ({value}) for period '{p}'. Skipping."
                        )
                except Exception as node_err:
                    # Log error fetching data for a specific period but continue
                    logger.error(
                        f"MultiPeriodStatNode '{self.name}': Error getting value for period '{p}' from '{self.input_node.name}': {node_err}",
                        exc_info=True,
                    )
                    retrieval_errors.append(p)

            # If no valid numeric values were collected
            if not values:
                logger.warning(
                    f"MultiPeriodStatNode '{self.name}': No valid numeric data points found across periods {self.periods}. Returning NaN."
                )
                return float("nan")

            # Attempt the statistical calculation
            try:
                result = self.stat_func(values)
                # Ensure result is float, handle potential NaN from stat_func
                return float(result) if math.isfinite(result) else float("nan")
            except (statistics.StatisticsError, ValueError, TypeError) as stat_err:
                # Handle errors specific to statistical functions (e.g., stdev needs >= 2 points)
                logger.warning(
                    f"MultiPeriodStatNode '{self.name}': Stat function '{self.stat_func.__name__}' failed ({stat_err}). Values: {values}. Returning NaN."
                )
                return float("nan")

        except Exception as e:
            # Catch any other unexpected errors during the process
            raise CalculationError(
                message=f"Failed to calculate multi-period stat for node '{self.name}'",
                node_id=self.name,
                period="multi-period",  # Indicate calculation context
                details={
                    "input_node": self.input_node.name,
                    "periods": self.periods,
                    "stat_func": self.stat_func.__name__,
                    "collected_values_count": len(values),
                    "retrieval_errors_periods": retrieval_errors,
                    "original_error": str(e),
                },
            ) from e

    def get_dependencies(self) -> list[str]:
        """Return the names of nodes this node depends on."""
        return [self.input_node.name]

    def has_calculation(self) -> bool:
        """Indicate that this node performs a calculation."""
        return True


class TwoPeriodAverageNode(Node):
    """Computes the simple average of an input node's value over two periods.

    Calculates (Value at Period 1 + Value at Period 2) / 2.

    Attributes:
        name (str): Identifier for this node.
        input_node (Node): Node providing the values to be averaged.
        period1 (str): Identifier for the first period.
        period2 (str): Identifier for the second period.

    Example:
        >>> # Assume price_node holds {"Jan": 10.0, "Feb": 11.0}
        >>> price_node = FinancialStatementItemNode("price", {"Jan": 10.0, "Feb": 11.0})
        >>> avg_price = TwoPeriodAverageNode(
        ...     "jan_feb_avg_price",
        ...     input_node=price_node,
        ...     period1="Jan",
        ...     period2="Feb"
        ... )
        >>> print(avg_price.calculate()) # Period arg is ignored
        10.5
    """

    def __init__(self, name: str, input_node: Node, period1: str, period2: str):
        """Initialize the two-period average node.

        Args:
            name (str): The identifier for this node.
            input_node (Node): The node providing values.
            period1 (str): The identifier for the first period.
            period2 (str): The identifier for the second period.

        Raises:
            TypeError: If `input_node` is not a Node, or periods are not strings.
        """
        super().__init__(name)
        if not isinstance(input_node, Node):
            raise TypeError(
                f"TwoPeriodAverageNode input_node must be a Node instance, got {type(input_node).__name__}"
            )
        if not isinstance(period1, str) or not isinstance(period2, str):
            raise TypeError("TwoPeriodAverageNode period1 and period2 must be strings.")

        self.input_node = input_node
        self.period1 = period1
        self.period2 = period2

    def calculate(self, period: Optional[str] = None) -> float:
        """Calculate the average of the input node for the two fixed periods.

        Ignores the `period` argument, using `period1` and `period2` defined
        during initialization.

        Args:
            period (Optional[str]): Ignored.

        Returns:
            float: The average of the input node's values for `period1` and `period2`.
                   Returns `float('nan')` if either input value is non-numeric.

        Raises:
            CalculationError: If retrieving values from the input node fails.
        """
        try:
            val1 = self.input_node.calculate(self.period1)
            val2 = self.input_node.calculate(self.period2)

            # Ensure values are numeric and finite
            if not isinstance(val1, (int, float)) or not math.isfinite(val1):
                logger.warning(
                    f"TwoPeriodAverageNode '{self.name}': Value for period '{self.period1}' is non-numeric/non-finite ({val1}). Returning NaN."
                )
                return float("nan")
            if not isinstance(val2, (int, float)) or not math.isfinite(val2):
                logger.warning(
                    f"TwoPeriodAverageNode '{self.name}': Value for period '{self.period2}' is non-numeric/non-finite ({val2}). Returning NaN."
                )
                return float("nan")

            # Calculate the average
            return (float(val1) + float(val2)) / 2.0

        except Exception as e:
            # Wrap potential errors during input node calculation
            raise CalculationError(
                message=f"Failed to calculate two-period average for node '{self.name}'",
                node_id=self.name,
                period=f"{self.period1}_and_{self.period2}",  # Indicate context
                details={
                    "input_node": self.input_node.name,
                    "period1": self.period1,
                    "period2": self.period2,
                    "original_error": str(e),
                },
            ) from e

    def get_dependencies(self) -> list[str]:
        """Return the names of nodes this node depends on."""
        return [self.input_node.name]

    def has_calculation(self) -> bool:
        """Indicate that this node performs a calculation."""
        return True


__all__ = [
    "MultiPeriodStatNode",
    "TwoPeriodAverageNode",
    "YoYGrowthNode",
]

# --- END FILE: fin_statement_model/core/nodes/stats_nodes.py ---

# --- START FILE: fin_statement_model/core/nodes/__init__.py ---
"""Core Node Implementations for the Financial Statement Model.

This package exports the base `Node` class and various concrete node types
used to build the financial model graph. These include:

- Data Nodes:
    - `FinancialStatementItemNode`: Stores raw numerical data for specific periods.

- Calculation Nodes:
    - `FormulaCalculationNode`: Calculates based on mathematical string formulas.
    - `StrategyCalculationNode`: Delegates calculation to a strategy object.
    - `MetricCalculationNode`: Calculates based on registered metric definitions.
    - `CustomCalculationNode`: Uses arbitrary Python functions for calculation.

- Statistical Nodes:
    - `YoYGrowthNode`: Calculates year-over-year percentage growth.
    - `MultiPeriodStatNode`: Computes statistics (mean, stddev) over multiple periods.
    - `TwoPeriodAverageNode`: Calculates the average over two specific periods.

The `__all__` list defines the public API of this package.
"""

# Core node package public interface: re-export submodules
from .base import Node
from .item_node import FinancialStatementItemNode

# Imports from consolidated files
from .calculation_nodes import (
    FormulaCalculationNode,
    StrategyCalculationNode,
    MetricCalculationNode,
    CustomCalculationNode,
)
from .stats_nodes import (
    YoYGrowthNode,
    MultiPeriodStatNode,
    TwoPeriodAverageNode,
)
from .forecast_nodes import (
    ForecastNode,
    FixedGrowthForecastNode,
    CurveGrowthForecastNode,
    StatisticalGrowthForecastNode,
    CustomGrowthForecastNode,
    AverageValueForecastNode,
    AverageHistoricalGrowthForecastNode,
)

__all__ = [
    "AverageHistoricalGrowthForecastNode",
    "AverageValueForecastNode",
    "CurveGrowthForecastNode",
    "CustomCalculationNode",
    "CustomGrowthForecastNode",
    "FinancialStatementItemNode",
    "FixedGrowthForecastNode",
    # Forecast Nodes
    "ForecastNode",
    # Calculation Nodes
    "FormulaCalculationNode",
    "MetricCalculationNode",
    "MultiPeriodStatNode",
    "Node",
    "StatisticalGrowthForecastNode",
    "StrategyCalculationNode",
    "TwoPeriodAverageNode",
    # Stats Nodes
    "YoYGrowthNode",
]

# --- END FILE: fin_statement_model/core/nodes/__init__.py ---

# --- START FILE: fin_statement_model/core/nodes/calculation_nodes.py ---
"""Contains node implementations for performing calculations in the financial model.

This module defines the different types of calculation nodes available in the system:
- FormulaCalculationNode: Evaluates a formula expression string (e.g., "a + b / 2")
- StrategyCalculationNode: Uses the Strategy pattern for calculation logic
- MetricCalculationNode: Calculates a registered financial metric
- CustomCalculationNode: Calculates using a Python callable/function
"""

from __future__ import annotations

import ast
import operator
from typing import (
    Callable,
    Optional,
    TYPE_CHECKING,
)  # Add TYPE_CHECKING
from typing import ClassVar

# Use absolute imports
from fin_statement_model.core.nodes.base import Node
from fin_statement_model.core.metrics import metric_registry
from fin_statement_model.core.errors import (
    CalculationError,
    ConfigurationError,
    MetricError,
)

if TYPE_CHECKING:
    from fin_statement_model.core.nodes.base import (
        Node,
    )  # Keep forward reference absolute
    from fin_statement_model.core.strategies.strategy import Strategy

# === FormulaCalculationNode ===


class FormulaCalculationNode(Node):
    """Calculates a value based on a mathematical formula string.

    Parses and evaluates simple mathematical expressions involving input nodes.
    Supports basic arithmetic operators (+, -, *, /) and unary negation.

    Attributes:
        name (str): Identifier for this node.
        inputs (Dict[str, Node]): Mapping of variable names used in the formula
            to their corresponding input Node instances.
        formula (str): The mathematical expression string to evaluate (e.g., "a + b").
        _ast (ast.Expression): The parsed Abstract Syntax Tree of the formula.

    Example:
        >>> # Assume revenue and cogs are Node instances
        >>> revenue = FinancialStatementItemNode("revenue", {"2023": 100})
        >>> cogs = FinancialStatementItemNode("cogs", {"2023": 60})
        >>> gross_profit = FormulaCalculationNode(
        ...     "gross_profit",
        ...     inputs={"rev": revenue, "cost": cogs},
        ...     formula="rev - cost"
        ... )
        >>> print(gross_profit.calculate("2023"))
        40.0
    """

    # Supported AST operators mapping to Python operator functions
    OPERATORS: ClassVar[dict[type, Callable]] = {
        ast.Add: operator.add,
        ast.Sub: operator.sub,
        ast.Mult: operator.mul,
        ast.Div: operator.truediv,
        ast.USub: operator.neg,
    }

    def __init__(self, name: str, inputs: dict[str, Node], formula: str):
        """Initializes the formula calculation node.

        Args:
            name (str): The unique identifier for this node.
            inputs (Dict[str, Node]): Dictionary mapping variable names in the
                formula to the corresponding input nodes.
            formula (str): The mathematical formula string.

        Raises:
            ValueError: If the formula string has invalid syntax.
            TypeError: If any value in `inputs` is not a Node instance.
        """
        super().__init__(name)
        if not isinstance(inputs, dict) or not all(isinstance(n, Node) for n in inputs.values()):
            raise TypeError("FormulaCalculationNode inputs must be a dict of Node instances.")
        self.inputs = inputs
        self.formula = formula
        try:
            # Parse the formula string into an AST expression
            self._ast = ast.parse(formula, mode="eval").body
        except SyntaxError as e:
            raise ValueError(f"Invalid formula syntax for node '{name}': {formula}") from e

    def calculate(self, period: str) -> float:
        """Calculate the node's value for the period by evaluating the formula.

        Args:
            period (str): The time period for which to perform the calculation.

        Returns:
            float: The result of the formula evaluation.

        Raises:
            CalculationError: If an error occurs during evaluation, such as
                an unknown variable, unsupported operator, or if an input node
                fails to provide a numeric value for the period.
        """
        try:
            return self._evaluate(self._ast, period)
        except (ValueError, TypeError, KeyError, ZeroDivisionError) as e:
            raise CalculationError(
                message=f"Error evaluating formula for node '{self.name}'",
                node_id=self.name,
                period=period,
                details={"formula": self.formula, "error": str(e)},
            ) from e

    def _evaluate(self, node: ast.AST, period: str) -> float:
        """Recursively evaluate the parsed AST node for the formula.

        Args:
            node (ast.AST): The current AST node to evaluate.
            period (str): The time period context for the evaluation.

        Returns:
            float: The result of evaluating the AST node.

        Raises:
            TypeError: If a non-numeric constant or input node value is encountered.
            ValueError: If an unknown variable or unsupported operator/syntax is found.
            ZeroDivisionError: If division by zero occurs.
        """
        # Numeric literal (Constant in Python 3.8+, Num in earlier versions)
        if isinstance(node, ast.Constant):
            if isinstance(node.value, (int, float)):
                return float(node.value)
            else:
                raise TypeError(
                    f"Unsupported constant type '{type(node.value).__name__}' in formula for node '{self.name}'"
                )

        # Variable reference
        elif isinstance(node, ast.Name):
            var_name = node.id
            if var_name not in self.inputs:
                raise ValueError(
                    f"Unknown variable '{var_name}' in formula for node '{self.name}'. Available: {list(self.inputs.keys())}"
                )
            input_node = self.inputs[var_name]
            # Recursively calculate the value of the input node
            value = input_node.calculate(period)
            if not isinstance(value, (int, float)):
                raise TypeError(
                    f"Input node '{input_node.name}' (variable '{var_name}') did not return a numeric value for period '{period}'"
                )
            return float(value)

        # Binary operation (e.g., a + b)
        elif isinstance(node, ast.BinOp):
            left_val = self._evaluate(node.left, period)
            right_val = self._evaluate(node.right, period)
            op_type = type(node.op)
            if op_type not in self.OPERATORS:
                raise ValueError(
                    f"Unsupported binary operator '{op_type.__name__}' in formula for node '{self.name}'"
                )
            # Perform the operation
            return float(self.OPERATORS[op_type](left_val, right_val))

        # Unary operation (e.g., -a)
        elif isinstance(node, ast.UnaryOp):
            operand_val = self._evaluate(node.operand, period)
            op_type = type(node.op)
            if op_type not in self.OPERATORS:
                raise ValueError(
                    f"Unsupported unary operator '{op_type.__name__}' in formula for node '{self.name}'"
                )
            # Perform the operation
            return float(self.OPERATORS[op_type](operand_val))

        # If the node type is unsupported
        else:
            raise TypeError(
                f"Unsupported syntax node type '{type(node).__name__}' in formula for node '{self.name}': {ast.dump(node)}"
            )

    def get_dependencies(self) -> list[str]:
        """Return the names of the input nodes used in the formula."""
        return [node.name for node in self.inputs.values()]

    def has_calculation(self) -> bool:
        """Indicate that this node performs a calculation."""
        return True


# === StrategyCalculationNode ===


class StrategyCalculationNode(Node):
    """Delegates calculation logic to a separate strategy object.

    Uses the Strategy design pattern. The actual calculation algorithm is
    encapsulated in a 'strategy' object provided during initialization.
    This allows for flexible and interchangeable calculation logic.

    Attributes:
        name (str): Identifier for this node.
        inputs (List[Node]): A list of input nodes required by the strategy.
        strategy (Any): An object possessing a `calculate(inputs: List[Node], period: str) -> float` method.
        _values (Dict[str, float]): Internal cache for calculated results.

    Example:
        >>> class SumStrategy:
        ...     def calculate(self, inputs: List[Node], period: str) -> float:
        ...         return sum(node.calculate(period) for node in inputs)
        >>> node_a = FinancialStatementItemNode("a", {"2023": 10})
        >>> node_b = FinancialStatementItemNode("b", {"2023": 20})
        >>> sum_node = StrategyCalculationNode(
        ...     "sum_ab",
        ...     inputs=[node_a, node_b],
        ...     strategy=SumStrategy()
        ... )
        >>> print(sum_node.calculate("2023"))
        30.0
    """

    def __init__(self, name: str, inputs: list[Node], strategy: Strategy):
        """Initialize the strategy calculation node.

        Args:
            name (str): The unique identifier for this node.
            inputs (List[Node]): List of input nodes needed by the strategy.
            strategy (Any): The strategy object implementing the calculation.
                Must have a `calculate` method.

        Raises:
            TypeError: If `inputs` is not a list of Nodes, or if `strategy`
                does not have a callable `calculate` method.
        """
        super().__init__(name)
        if not isinstance(inputs, list) or not all(isinstance(n, Node) for n in inputs):
            raise TypeError("StrategyCalculationNode inputs must be a list of Node instances.")
        if not hasattr(strategy, "calculate") or not callable(getattr(strategy, "calculate")):
            raise TypeError("Strategy object must have a callable 'calculate' method.")

        self.inputs = inputs
        self.strategy = strategy
        self._values: dict[str, float] = {}  # Cache for calculated values

    def calculate(self, period: str) -> float:
        """Calculate the value for the period using the assigned strategy.

        Checks the cache first. If not found, delegates to the strategy's
        `calculate` method and stores the result.

        Args:
            period (str): The time period for the calculation.

        Returns:
            float: The calculated value from the strategy.

        Raises:
            CalculationError: If the strategy's calculation fails or returns
                a non-numeric value.
        """
        if period in self._values:
            return self._values[period]

        try:
            # Delegate to the strategy object's calculate method
            result = self.strategy.calculate(self.inputs, period)
            if not isinstance(result, (int, float)):
                raise TypeError(
                    f"Strategy for node '{self.name}' did not return a numeric value (got {type(result).__name__})."
                )
            # Cache and return the result
            self._values[period] = float(result)
            return self._values[period]
        except Exception as e:
            # Wrap potential errors from the strategy
            raise CalculationError(
                message=f"Error during strategy calculation for node '{self.name}'",
                node_id=self.name,
                period=period,
                details={"strategy": type(self.strategy).__name__, "error": str(e)},
            ) from e

    def set_strategy(self, strategy: Strategy) -> None:
        """Change the calculation strategy at runtime.

        Args:
            strategy (Any): The new strategy object. Must have a callable
                `calculate` method.

        Raises:
            TypeError: If the new strategy is invalid.
        """
        if not hasattr(strategy, "calculate") or not callable(getattr(strategy, "calculate")):
            raise TypeError("New strategy object must have a callable 'calculate' method.")
        self.strategy = strategy
        self.clear_cache()  # Clear cache as logic has changed

    def clear_cache(self) -> None:
        """Clear the internal cache of calculated values."""
        self._values.clear()

    def get_dependencies(self) -> list[str]:
        """Return the names of the input nodes used by the strategy."""
        return [node.name for node in self.inputs]

    def has_calculation(self) -> bool:
        """Indicate that this node performs a calculation."""
        return True


# === MetricCalculationNode (Already documented in metric_node.py, refined here) ===
# Note: This class seems to duplicate metric_node.py. Assuming this is the consolidated version.


class MetricCalculationNode(Node):
    """Calculates a value based on a predefined metric definition from the registry.

    Looks up a metric in `metric_registry`, resolves input nodes, and uses an
    appropriate calculation method based on the metric definition.

    Attributes:
        name (str): Identifier for this node.
        metric_name (str): The identifier for the metric in the registry.
        input_nodes (Dict[str, Node]): Mapping of input variable names to Node instances.
        _values (Dict[str, float]): Internal cache for calculated results.

    Example:
        >>> # Assuming gross_margin metric is registered with formula "revenue - cogs"
        >>> revenue = FinancialStatementItemNode("revenue", {"2023": 100})
        >>> cogs = FinancialStatementItemNode("cogs", {"2023": 60})
        >>> gross_margin = MetricCalculationNode(
        ...     "gross_margin_calc",
        ...     metric_name="gross_margin",
        ...     input_nodes={"revenue": revenue, "cogs": cogs}
        ... )
        >>> print(gross_margin.calculate("2023"))
        40.0
    """

    def __init__(self, name: str, metric_name: str, input_nodes: dict[str, Node]):
        """Initializes the metric calculation node.

        Args:
            name (str): The unique identifier for this node.
            metric_name (str): The identifier for the metric in the registry.
            input_nodes (Dict[str, Node]): Dictionary mapping variable names in the
                metric definition to the corresponding input nodes.

        Raises:
            ConfigurationError: If the metric_name is not registered in `metric_registry`.
            MetricError: If the metric definition is invalid or there's a mismatch between
                input_nodes and required inputs from the metric definition.
            TypeError: If any value in `input_nodes` is not a Node instance.
        """
        super().__init__(name)

        # Validate input_nodes type
        if not isinstance(input_nodes, dict):
            raise TypeError("MetricCalculationNode input_nodes must be a dict of Node instances")

        if not all(isinstance(node, Node) for node in input_nodes.values()):
            raise TypeError("MetricCalculationNode input_nodes must be a dict of Node instances")

        self.metric_name = metric_name
        self.input_nodes = input_nodes
        self._values: dict[str, float] = {}  # Cache for calculated results

        # Try to get the metric definition from the registry
        try:
            self.definition = metric_registry.get(metric_name)
            if self.definition is None:
                raise KeyError(f"Metric '{metric_name}' not found")
        except KeyError:
            raise ConfigurationError(f"Metric definition '{metric_name}' not found")

        # Validate the metric definition
        required_fields = ["inputs", "formula"]
        missing_fields = [field for field in required_fields if field not in self.definition]
        if missing_fields:
            raise MetricError(
                f"Metric definition '{metric_name}' is invalid. Missing fields: {missing_fields}"
            )

        # Validate the input_nodes match what's required in the definition
        required_inputs = set(self.definition["inputs"])
        provided_inputs = set(input_nodes.keys())

        missing_inputs = required_inputs - provided_inputs
        if missing_inputs:
            raise MetricError(
                f"Input nodes mismatch for metric '{metric_name}': missing required inputs: {missing_inputs}"
            )

        extra_inputs = provided_inputs - required_inputs
        if extra_inputs:
            raise MetricError(
                f"Input nodes mismatch for metric '{metric_name}': unexpected inputs provided: {extra_inputs}"
            )

        # Create internal formula calculation node
        self.calc_node = FormulaCalculationNode(
            name=f"_{name}_formula_calc",
            inputs=input_nodes,
            formula=self.definition["formula"],
        )

    def calculate(self, period: str) -> float:
        """Calculate the node's value for the period using the metric definition.

        Looks up the metric in `metric_registry`, resolves input nodes, and uses an
        appropriate calculation method based on the metric definition.

        Args:
            period (str): The time period for which to perform the calculation.

        Returns:
            float: The calculated value from the metric.

        Raises:
            CalculationError: If an error occurs during calculation, such as
                an unknown variable, unsupported operator, or if an input node
                fails to provide a numeric value for the period.
        """
        if period in self._values:
            return self._values[period]

        try:
            # Delegate calculation to the internal formula node
            result = self.calc_node.calculate(period)

            # Cache and return the result
            self._values[period] = float(result)
            return self._values[period]
        except Exception as e:
            # Wrap potential errors from the formula node
            raise CalculationError(
                message=f"Error calculating metric '{self.metric_name}' for node '{self.name}' and period '{period}'",
                node_id=self.name,
                period=period,
                details={"metric_name": self.metric_name, "original_error": str(e)},
            ) from e

    def get_dependencies(self) -> list[str]:
        """Return the names of the input nodes used in the metric definition."""
        return list(self.input_nodes.keys())

    def has_calculation(self) -> bool:
        """Indicate that this node performs a calculation."""
        return True


# === CustomCalculationNode ===


class CustomCalculationNode(Node):
    """Calculates a value using a Python callable/function.

    Uses a Python callable/function to calculate the value for a node.
    The function is provided during initialization.

    Attributes:
        name (str): Identifier for this node.
        inputs (List[Node]): List of input nodes needed for calculation.
        formula_func (Callable): The Python callable/function to use for calculation.
        description (str, optional): Description of what this calculation does.
        _values (Dict[str, float]): Internal cache for calculated results.

    Example:
        >>> def custom_calculation(a, b):
        ...     return a + b
        >>> node_a = FinancialStatementItemNode("NodeA", values={"2023": 10.0})
        >>> node_b = FinancialStatementItemNode("NodeB", values={"2023": 5.0})
        >>> node = CustomCalculationNode(
        ...     "custom_calc",
        ...     inputs=[node_a, node_b],
        ...     formula_func=custom_calculation
        ... )
        >>> print(node.calculate("2023"))
        15.0
    """

    def __init__(
        self,
        name: str,
        inputs: list[Node],
        formula_func: Callable,
        description: Optional[str] = None,
    ):
        """Initializes the custom calculation node.

        Args:
            name (str): The unique identifier for this node.
            inputs (List[Node]): The input nodes whose values will be passed to formula_func.
            formula_func (Callable): The Python callable/function to use for calculation.
            description (str, optional): Description of what this calculation does.

        Raises:
            TypeError: If `inputs` is not a list of Nodes or `formula_func` is not a callable.
        """
        super().__init__(name)
        if not isinstance(inputs, list) or not all(isinstance(n, Node) for n in inputs):
            raise TypeError("CustomCalculationNode inputs must be a list of Node instances")
        if not callable(formula_func):
            raise TypeError("CustomCalculationNode formula_func must be a callable function")

        self.inputs = inputs
        self.formula_func = formula_func
        self.description = description
        self._values: dict[str, float] = {}  # Cache for calculated results

    def calculate(self, period: str) -> float:
        """Calculate the node's value for the period using the provided function.

        Args:
            period (str): The time period for which to perform the calculation.

        Returns:
            float: The calculated value from the function.

        Raises:
            CalculationError: If an error occurs during calculation, such as
                if an input node fails to provide a numeric value for the period.
        """
        if period in self._values:
            return self._values[period]

        try:
            # Get input values
            input_values = []
            for node in self.inputs:
                value = node.calculate(period)
                if not isinstance(value, (int, float)):
                    raise TypeError(
                        f"Input node '{node.name}' did not return a numeric value for period '{period}'. Got {type(value).__name__}."
                    )
                input_values.append(value)

            # Calculate the value using the provided function
            result = self.formula_func(*input_values)
            if not isinstance(result, (int, float)):
                raise TypeError(
                    f"Formula did not return a numeric value. Got {type(result).__name__}."
                )

            # Cache and return the result
            self._values[period] = float(result)
            return self._values[period]
        except Exception as e:
            # Wrap potential errors from the function
            raise CalculationError(
                message=f"Error during custom calculation for node '{self.name}'",
                node_id=self.name,
                period=period,
                details={"function": self.formula_func.__name__, "error": str(e)},
            ) from e

    def get_dependencies(self) -> list[str]:
        """Return the names of the input nodes used in the function."""
        return [node.name for node in self.inputs]

    def has_calculation(self) -> bool:
        """Indicate that this node performs a calculation."""
        return True

# --- END FILE: fin_statement_model/core/nodes/calculation_nodes.py ---

# --- START FILE: fin_statement_model/core/nodes/forecast_nodes.py ---
"""Forecast nodes for projecting future values based on historical data.

This module defines the base `ForecastNode` class and its subclasses,
implementing various forecasting strategies (fixed, curve, statistical,
custom, average, and historical growth).
"""

import logging
from typing import Callable

# Use absolute imports
from fin_statement_model.core.nodes.base import Node

logger = logging.getLogger(__name__)


class ForecastNode(Node):
    """Base class for forecast nodes that project future values based on historical data.

    A forecast node takes an input node (typically a financial statement item) and projects its
    future values using various growth methods. The node caches calculated values to avoid
    redundant computations.

    Attributes:
        name (str): Identifier for the forecast node (derived from input_node.name)
        input_node (Node): Source node containing historical values to forecast from
        base_period (str): Last historical period to use as basis for forecasting
        forecast_periods (List[str]): List of future periods to generate forecasts for
        _cache (dict): Internal cache of calculated values
        values (dict): Dictionary mapping periods to values (including historical)

    Methods:
        calculate(period): Get value for a specific period (historical or forecast)
        forecast_value(period): Alias for calculate() to meet project standards
        _calculate_value(period): Core calculation logic for a period
        _get_previous_period(period): Helper to get chronologically previous period
        _get_growth_factor_for_period(): Abstract method for growth rate calculation

    Example:
        # Create 5% fixed growth forecast for revenue
        base = "FY2022"
        forecasts = ["FY2023", "FY2024", "FY2025"]
        node = FixedGrowthForecastNode(revenue_node, base, forecasts, 0.05)

        # Get forecasted value
        fy2024_revenue = node.calculate("FY2024")
    """

    def __init__(self, input_node: Node, base_period: str, forecast_periods: list[str]):
        """Initialize ForecastNode with input node and forecast periods.

        Args:
            input_node: Source node containing historical values.
            base_period: The last historical period serving as the forecast base.
            forecast_periods: List of future periods for which forecasts will be generated.
        """
        self.name = input_node.name
        self.input_node = input_node
        self.base_period = base_period
        self.forecast_periods = forecast_periods
        self._cache = {}

        # Copy historical values from input node
        if hasattr(input_node, "values"):
            self.values = input_node.values.copy()
        else:
            self.values = {}

    def calculate(self, period: str) -> float:
        """Calculate the value for a specific period, using cached results if available.

        This method returns historical values for periods up to the base period, and
        calculates forecasted values for future periods. Results are cached to avoid
        redundant calculations.

        Args:
            period (str): The period to calculate the value for (e.g. "FY2023")

        Returns:
            float: The calculated value for the specified period

        Raises:
            ValueError: If the requested period is not in base_period or forecast_periods

        Example:
            # Get historical value
            base_value = node.calculate("FY2022")  # Returns actual historical value

            # Get forecasted value
            forecast_value = node.calculate("FY2024")  # Returns projected value
        """
        if period not in self._cache:
            self._cache[period] = self._calculate_value(period)
        return self._cache[period]

    def forecast_value(self, period: str) -> float:
        """Alias for calculate() method to meet project standards.

        Args:
            period (str): The period to calculate the value for (e.g. "FY2023")

        Returns:
            float: The calculated value for the specified period
        """
        return self.calculate(period)

    def clear_cache(self):
        """Clear the calculation cache.

        This method clears any cached calculation results, forcing future calls to
        calculate() to recompute values rather than using cached results.

        Example:
            # Clear cached calculations
            node.clear_cache()  # Future calculate() calls will recompute values
        """
        self._cache.clear()

    def _calculate_value(self, period: str) -> float:
        """Calculate the value for a specific period.

        For historical periods (up to base_period), returns the actual value.
        For forecast periods, calculates the value using the growth rate.

        Args:
            period: The period to calculate the value for

        Returns:
            float: The calculated value for the period

        Raises:
            ValueError: If the period is not in base_period or forecast_periods
        """
        # For historical periods, return the actual value
        if period <= self.base_period:
            return self.values.get(period, 0.0)

        # For forecast periods, calculate using growth rate
        if period not in self.forecast_periods:
            raise ValueError(f"Period '{period}' not in forecast periods for {self.name}")

        # Get the previous period's value
        prev_period = self._get_previous_period(period)
        prev_value = self.calculate(prev_period)

        # Get the growth rate for this period
        growth_factor = self._get_growth_factor_for_period(period, prev_period, prev_value)

        # Calculate the new value
        return prev_value * (1 + growth_factor)

    def _get_previous_period(self, current_period: str) -> str:
        all_periods = sorted([self.base_period, *self.forecast_periods])
        idx = all_periods.index(current_period)
        return all_periods[idx - 1]

    def _get_growth_factor_for_period(
        self, period: str, prev_period: str, prev_value: float
    ) -> float:
        raise NotImplementedError("Implement in subclass.")


class FixedGrowthForecastNode(ForecastNode):
    """A forecast node that applies a fixed growth rate to project future values.

    This node takes a constant growth rate and applies it to each forecast period,
    compounding from the base period value. It's useful for simple forecasting scenarios
    where steady growth is expected.

    Args:
        input_node (Node): The node containing historical/base values
        base_period (str): The last historical period (e.g. "FY2022")
        forecast_periods (List[str]): List of future periods to forecast
        growth_rate (float): The fixed growth rate to apply (e.g. 0.05 for 5% growth)

    Example:
        # Create node forecasting 5% annual revenue growth
        forecast = FixedGrowthForecastNode(
            revenue_node,
            "FY2022",
            ["FY2023", "FY2024", "FY2025"],
            0.05
        )

        # Get forecasted value
        fy2024_revenue = forecast.calculate("FY2024")
        # Returns: base_value * (1.05)^2
    """

    def __init__(
        self,
        input_node: Node,
        base_period: str,
        forecast_periods: list[str],
        growth_rate: float,
    ):
        """Initialize FixedGrowthForecastNode with a constant growth rate.

        Args:
            input_node: Node containing historical values to base the forecast on.
            base_period: The last historical period.
            forecast_periods: List of future periods to forecast.
            growth_rate: Fixed growth rate (e.g., 0.05 for 5% growth).
        """
        super().__init__(input_node, base_period, forecast_periods)
        self.growth_rate = float(growth_rate)  # Ensure it's a float
        logger.debug(f"Created FixedGrowthForecastNode with growth rate: {self.growth_rate}")

    def _get_growth_factor_for_period(
        self, period: str, prev_period: str, prev_value: float
    ) -> float:
        logger.debug(
            f"FixedGrowthForecastNode: Using growth rate {self.growth_rate} for period {period}"
        )
        return self.growth_rate


class CurveGrowthForecastNode(ForecastNode):
    """A forecast node that applies different growth rates for each forecast period.

    This node takes a list of growth rates corresponding to each forecast period,
    allowing for varying growth assumptions over time. This is useful when you expect
    growth patterns to change, such as high initial growth followed by moderation.

    Args:
        input_node (Node): The node containing historical/base values
        base_period (str): The last historical period (e.g. "FY2022")
        forecast_periods (List[str]): List of future periods to forecast
        growth_rates (List[float]): List of growth rates for each period (e.g. [0.08, 0.06, 0.04])
                                   Must match length of forecast_periods.

    Raises:
        ValueError: If length of growth_rates doesn't match forecast_periods

    Example:
        # Create node with declining growth rates
        forecast = CurveGrowthForecastNode(
            revenue_node,
            "FY2022",
            ["FY2023", "FY2024", "FY2025"],
            [0.08, 0.06, 0.04]  # 8% then 6% then 4% growth
        )

        # Get forecasted value
        fy2024_revenue = forecast.calculate("FY2024")
        # Returns: base_value * (1.08) * (1.06)
    """

    def __init__(
        self,
        input_node: Node,
        base_period: str,
        forecast_periods: list[str],
        growth_rates: list[float],
    ):
        """Initialize CurveGrowthForecastNode with variable growth rates per period.

        Args:
            input_node: Node containing historical data.
            base_period: The last historical period.
            forecast_periods: List of future periods to forecast.
            growth_rates: List of growth rates matching each forecast period.
        """
        super().__init__(input_node, base_period, forecast_periods)
        if len(growth_rates) != len(forecast_periods):
            raise ValueError("Number of growth rates must match forecast periods.")
        self.growth_rates = [float(rate) for rate in growth_rates]  # Ensure all are floats
        logger.debug(f"Created CurveGrowthForecastNode with growth rates: {self.growth_rates}")
        logger.debug(f"  Base period: {base_period}")
        logger.debug(f"  Forecast periods: {forecast_periods}")
        logger.debug(f"  Base value: {input_node.calculate(base_period)}")

    def _get_growth_factor_for_period(
        self, period: str, prev_period: str, prev_value: float
    ) -> float:
        """Get the growth factor for a specific period."""
        idx = self.forecast_periods.index(period)
        growth_rate = self.growth_rates[idx]
        logger.debug(
            f"CurveGrowthForecastNode: Using growth rate {growth_rate} for period {period}"
        )
        logger.debug(f"  Previous period: {prev_period}")
        logger.debug(f"  Previous value: {prev_value}")
        return growth_rate


class StatisticalGrowthForecastNode(ForecastNode):
    """A forecast node that generates growth rates from a statistical distribution.

    This node uses a provided statistical distribution function to randomly generate
    growth rates for each forecast period. This is useful for modeling uncertainty
    and running Monte Carlo simulations of different growth scenarios.

    Args:
        input_node (Node): The node containing historical/base values
        base_period (str): The last historical period (e.g. "FY2022")
        forecast_periods (List[str]): List of future periods to forecast
        distribution_callable (Callable[[], float]): Function that returns random growth rates
                                                   from a statistical distribution

    Example:
        # Create node with normally distributed growth rates
        from numpy.random import normal
        forecast = StatisticalGrowthForecastNode(
            revenue_node,
            "FY2022",
            ["FY2023", "FY2024", "FY2025"],
            lambda: normal(0.05, 0.02)  # Mean 5% growth, 2% std dev
        )

        # Get forecasted value (will vary due to randomness)
        fy2024_revenue = forecast.calculate("FY2024")
        # Returns: base_value * (1 + r1) * (1 + r2) where r1,r2 are random
    """

    def __init__(
        self,
        input_node: Node,
        base_period: str,
        forecast_periods: list[str],
        distribution_callable: Callable[[], float],
    ):
        """Initialize StatisticalGrowthForecastNode with a distribution function.

        Args:
            input_node: Node containing historical data.
            base_period: The last historical period.
            forecast_periods: List of future periods to forecast.
            distribution_callable: Function that returns a random growth rate.
        """
        super().__init__(input_node, base_period, forecast_periods)
        self.distribution_callable = distribution_callable

    def _get_growth_factor_for_period(
        self, period: str, prev_period: str, prev_value: float
    ) -> float:
        return self.distribution_callable()


class CustomGrowthForecastNode(ForecastNode):
    """A forecast node that uses a custom function to determine growth rates.

    This node allows complete flexibility in how growth rates are calculated by accepting
    a custom function that can incorporate any logic or external data to determine the
    growth rate for each period.

    Args:
        input_node (Node): The node containing historical/base values
        base_period (str): The last historical period (e.g. "FY2022")
        forecast_periods (List[str]): List of future periods to forecast
        growth_function (Callable[[str, str, float], float]): Function that returns growth rate
            given current period, previous period, and previous value

    The growth_function should accept three parameters:
        - current_period (str): The period being forecasted
        - prev_period (str): The previous period
        - prev_value (float): The value from the previous period
    And return a float representing the growth rate for that period.

    Example:
        def custom_growth(period, prev_period, prev_value):
            # Growth rate increases by 1% each year, starting at 5%
            year_diff = int(period[-4:]) - int(prev_period[-4:])
            return 0.05 + (0.01 * year_diff)

        forecast = CustomGrowthForecastNode(
            revenue_node,
            "FY2022",
            ["FY2023", "FY2024", "FY2025"],
            custom_growth
        )
    """

    def __init__(
        self,
        input_node: Node,
        base_period: str,
        forecast_periods: list[str],
        growth_function: Callable[[str, str, float], float],
    ):
        """Initialize CustomGrowthForecastNode with a custom growth function.

        Args:
            input_node: Node containing historical data.
            base_period: The last historical period.
            forecast_periods: List of future periods to forecast.
            growth_function: Callable(period, prev_period, prev_value) -> growth rate.
        """
        super().__init__(input_node, base_period, forecast_periods)
        self.growth_function = growth_function

    def _get_growth_factor_for_period(
        self, period: str, prev_period: str, prev_value: float
    ) -> float:
        return self.growth_function(period, prev_period, prev_value)


class AverageValueForecastNode(ForecastNode):
    """A forecast node that uses the average of historical values for all forecast periods.

    This node calculates the average of historical values and returns that constant value
    for all forecast periods. It's useful when you want to project future values based
    on the historical average, without any growth.

    Args:
        input_node (Node): The node containing historical/base values
        base_period (str): The last historical period (e.g. "FY2022")
        forecast_periods (List[str]): List of future periods to forecast
        average_value (float): The pre-calculated average value to use

    Example:
        # Create node using historical average
        avg_value = sum(historical_values) / len(historical_values)
        forecast = AverageValueForecastNode(
            revenue_node,
            "FY2022",
            ["FY2023", "FY2024", "FY2025"],
            avg_value
        )

        # Get forecasted value
        fy2024_revenue = forecast.calculate("FY2024")
        # Returns: avg_value
    """

    def __init__(
        self,
        input_node: Node,
        base_period: str,
        forecast_periods: list[str],
        average_value: float,
    ):
        """Initialize AverageValueForecastNode with a constant average value.

        Args:
            input_node: Node containing historical data.
            base_period: The last historical period.
            forecast_periods: List of future periods to forecast.
            average_value: Constant average value to apply for forecasts.
        """
        super().__init__(input_node, base_period, forecast_periods)
        self.average_value = float(average_value)  # Ensure it's a float
        logger.debug(f"Created AverageValueForecastNode with average value: {self.average_value}")

    def _calculate_value(self, period: str) -> float:
        """Calculate the value for a specific period."""
        # For historical periods, return the actual value
        if period <= self.base_period:
            return self.values.get(period, 0.0)

        # For forecast periods, return the average value
        if period not in self.forecast_periods:
            raise ValueError(f"Period '{period}' not in forecast periods for {self.name}")

        return self.average_value

    def _get_growth_factor_for_period(
        self, period: str, prev_period: str, prev_value: float
    ) -> float:
        """Not used for average value forecasts."""
        return 0.0


class AverageHistoricalGrowthForecastNode(ForecastNode):
    """A forecast node that uses the average historical growth rate for forecasting.

    This node calculates the average growth rate from historical values and applies
    that same growth rate consistently to all forecast periods. It's useful when you
    want to project future values based on the historical growth pattern.

    Args:
        input_node (Node): The node containing historical/base values
        base_period (str): The last historical period (e.g. "FY2022")
        forecast_periods (List[str]): List of future periods to forecast
        growth_params (float): Ignored parameter for compatibility with NodeFactory

    Example:
        # Create node using average historical growth
        forecast = AverageHistoricalGrowthForecastNode(
            revenue_node,
            "FY2022",
            ["FY2023", "FY2024", "FY2025"]
        )

        # Get forecasted value
        fy2024_revenue = forecast.calculate("FY2024")
        # Returns: base_value * (1 + avg_growth_rate)^2
    """

    def __init__(
        self,
        input_node: Node,
        base_period: str,
        forecast_periods: list[str],
        growth_params: float = 0.0,
    ):
        """Initialize AverageHistoricalGrowthForecastNode with initial growth parameters.

        Args:
            input_node: Node containing historical data.
            base_period: The last historical period.
            forecast_periods: List of future periods to forecast.
            growth_params: Initial parameter used to calculate average growth.
        """
        super().__init__(input_node, base_period, forecast_periods)
        self.avg_growth_rate = self._calculate_average_growth_rate()
        logger.debug(
            f"Created AverageHistoricalGrowthForecastNode with growth rate: {self.avg_growth_rate}"
        )

    def _calculate_average_growth_rate(self) -> float:
        """Calculate the average historical growth rate from input node values.

        Returns:
            float: The average growth rate across historical periods
        """
        if not self.values:
            logger.warning(f"No historical values found for {self.name}, using 0% growth")
            return 0.0

        # Get sorted historical periods up to base period
        historical_periods = sorted([p for p in self.values if p <= self.base_period])
        if len(historical_periods) < 2:
            logger.warning(f"Insufficient historical data for {self.name}, using 0% growth")
            return 0.0

        # Calculate growth rates between consecutive periods
        growth_rates = []
        for i in range(1, len(historical_periods)):
            prev_period = historical_periods[i - 1]
            curr_period = historical_periods[i]
            prev_value = self.values[prev_period]
            curr_value = self.values[curr_period]

            if prev_value == 0:
                logger.warning(
                    f"Zero value found for {self.name} in period {prev_period}, skipping growth rate"
                )
                continue

            growth_rate = (curr_value - prev_value) / prev_value
            growth_rates.append(growth_rate)

        if not growth_rates:
            logger.warning(f"No valid growth rates calculated for {self.name}, using 0% growth")
            return 0.0

        # Calculate and return average growth rate
        avg_growth = sum(growth_rates) / len(growth_rates)
        logger.debug(f"Calculated average growth rate for {self.name}: {avg_growth}")
        return avg_growth

    def _get_growth_factor_for_period(
        self, period: str, prev_period: str, prev_value: float
    ) -> float:
        """Get the growth factor for a specific period.

        Args:
            period (str): The current period
            prev_period (str): The previous period
            prev_value (float): The value from the previous period

        Returns:
            float: The growth rate to apply
        """
        logger.debug(
            f"AverageHistoricalGrowthForecastNode: Using growth rate {self.avg_growth_rate} for period {period}"
        )
        return self.avg_growth_rate

# --- END FILE: fin_statement_model/core/nodes/forecast_nodes.py ---

# --- START FILE: fin_statement_model/core/nodes/metric_node.py ---
"""Defines a node that calculates a value based on a registered metric."""

from __future__ import annotations

import logging
from typing import TYPE_CHECKING, Optional
import ast

if TYPE_CHECKING:
    from fin_statement_model.core.nodes.base import Node
    from fin_statement_model.core.graph.graph import Graph

from fin_statement_model.core.nodes.base import Node
from fin_statement_model.core.metrics import metric_registry
from fin_statement_model.core.nodes.calculation_nodes import FormulaCalculationNode
from fin_statement_model.core.errors import (
    ConfigurationError,
    CalculationError,
    MetricError,
)

logger = logging.getLogger(__name__)


class MetricCalculationNode(Node):
    """Calculates a value based on a predefined metric definition.

    This node looks up a metric in the `metric_registry`, resolves its
    input nodes from the provided graph, and delegates the actual calculation
    to an underlying `FormulaCalculationNode` based on the metric's formula.

    Attributes:
        name (str): The unique identifier for this metric node.
        metric_name (str): The key of the metric in the `metric_registry`.
        graph (GraphType): The financial statement graph instance used to resolve
            input nodes.
        definition (Dict): The loaded definition dictionary for the metric.
        calc_node (FormulaCalculationNode): The internal node performing the
            calculation.

    Example:
        >>> # Assume 'gross_profit' metric is registered:
        >>> #   inputs: ["revenue", "cogs"]
        >>> #   formula: "revenue - cogs"
        >>> # Assume graph object exists and metric_registry is populated
        >>> # (Need imports: FinancialStatementItemNode, metric_registry)
        >>> class MockGraph:
        ...     def get_node(self, name):
        ...         nodes = {
        ...             "revenue_item": FinancialStatementItemNode("revenue_item", {"2023": 500}),
        ...             "cogs_item": FinancialStatementItemNode("cogs_item", {"2023": 200})
        ...         }
        ...         return nodes.get(name)
        >>> graph = MockGraph()
        >>> # We need to register the metric first (or assume it's done elsewhere)
        >>> try:
        ...     metric_registry.register({
        ...         "gross_profit": {
        ...             "inputs": ["revenue_item", "cogs_item"],
        ...             "formula": "revenue_item - cogs_item",
        ...             "description": "Revenue minus Cost of Goods Sold."
        ...         }
        ...     })
        ... except Exception as e: # Handle potential re-registration
        ...     if "already registered" not in str(e): raise e
        >>>
        >>> gp_node = MetricCalculationNode(
        ...     "calculated_gp",
        ...     metric_name="gross_profit",
        ...     graph=graph
        ... )
        >>> # print(gp_node.calculate("2023")) # Actual result depends on live registry/graph
        >>> # Expected: 300.0
    """

    def __init__(self, name: str, metric_name: str, graph: Optional[Graph]):
        """Initialize the metric calculation node.

        Retrieves the metric definition, resolves input nodes from the graph,
        and sets up the underlying formula calculation node.

        Args:
            name (str): The identifier for this node.
            metric_name (str): The key identifying the metric in the registry.
            graph (GraphType): The graph instance containing potential input nodes.

        Raises:
            ConfigurationError: If the `metric_name` is not found in the registry,
                or if an input node specified by the metric is not found in the graph.
            ValueError: If the metric definition is invalid (e.g., missing formula
                or inputs).
            TypeError: If input nodes resolved from the graph are not `Node` instances.
        """
        super().__init__(name)
        self.metric_name = metric_name
        self.graph = graph
        self._formula_string: Optional[str] = None
        self._parsed_expr: Optional[ast.Expression] = None
        self._load_metric_definition()

    def _load_metric_definition(self):
        """Load and validate the metric definition from the registry."""
        try:
            self.definition = metric_registry.get(self.metric_name)
        except KeyError:
            raise MetricError(f"Metric '{self.metric_name}' not found in registry.")

        # Validate required fields in definition
        required = ["description", "inputs", "formula"]
        if not all(k in self.definition for k in required):
            missing = [k for k in required if k not in self.definition]
            raise ValueError(
                f"Metric definition '{self.metric_name}' is invalid: missing required field(s): {missing}"
            )

        input_nodes: dict[str, Node] = {}
        missing_inputs = []
        for input_name in self.definition["inputs"]:
            node = self.graph.get_node(input_name)
            if node is None:
                missing_inputs.append(input_name)
            elif not isinstance(node, Node):
                raise TypeError(
                    f"Resolved input '{input_name}' for metric '{self.metric_name}' is not a Node instance."
                )
            else:
                input_nodes[input_name] = node

        if missing_inputs:
            raise ConfigurationError(
                f"Input node(s) required by metric '{self.metric_name}' not found in graph: {missing_inputs}"
            )

        calc_node_name = f"_{self.name}_formula_calc"
        try:
            self.calc_node = FormulaCalculationNode(
                calc_node_name, input_nodes, self.definition["formula"]
            )
        except ValueError as e:
            raise ValueError(
                f"Error creating formula node for metric '{self.metric_name}' (node '{self.name}'): {e}"
            ) from e

    def calculate(self, period: str, graph: Optional[Graph] = None) -> float:
        """Calculate the metric's value for the specified period.

        Delegates the calculation to the internal `FormulaCalculationNode`.

        Args:
            period (str): The time period for which to calculate the metric.
            graph (GraphType): The graph instance containing potential input nodes.

        Returns:
            float: The calculated metric value.

        Raises:
            CalculationError: If an error occurs during the underlying formula
                evaluation (e.g., missing input data for the period, type errors).
        """
        try:
            return self.calc_node.calculate(period)
        except Exception as e:
            raise CalculationError(
                message=f"Failed to calculate metric '{self.metric_name}' for node '{self.name}'",
                node_id=self.name,
                period=period,
                details={"original_error": str(e)},
            ) from e

    def get_dependencies(self) -> list[str]:
        """Return the names of the input nodes required by the metric definition."""
        return self.definition.get("inputs", [])

    def has_calculation(self) -> bool:
        """Indicate that this node performs a calculation."""
        return True

# --- END FILE: fin_statement_model/core/nodes/metric_node.py ---

# --- START FILE: fin_statement_model/core/nodes/item_node.py ---
"""Defines a node representing a basic financial statement item."""

import logging

# Use absolute imports
from fin_statement_model.core.nodes.base import Node

logger = logging.getLogger(__name__)


class FinancialStatementItemNode(Node):
    """Represents a leaf node containing raw financial statement data.

    This node type typically stores actual reported values (e.g., Revenue,
    COGS) for different time periods.

    Attributes:
        name (str): The unique identifier for the financial item (e.g., "Revenue").
        values (Dict[str, float]): A dictionary mapping time periods (str)
            to their corresponding numerical values (float).

    Example:
        >>> revenue_data = {"2022": 1000.0, "2023": 1200.0}
        >>> revenue_node = FinancialStatementItemNode("Revenue", revenue_data)
        >>> print(revenue_node.name)
        Revenue
        >>> print(revenue_node.get_value("2023"))
        1200.0
        >>> print(revenue_node.calculate("2022")) # Calculate retrieves the value
        1000.0
        >>> revenue_node.set_value("2024", 1500.0)
        >>> print(revenue_node.get_value("2024"))
        1500.0
        >>> print(revenue_node.has_value("2021"))
        False
    """

    def __init__(self, name: str, values: dict[str, float]):
        """Initialize the financial statement item node.

        Args:
            name (str): The name of the financial statement item.
            values (Dict[str, float]): Dictionary of period-value pairs.
        """
        # Call base Node init if it requires name
        # super().__init__(name)  # Assuming base Node init takes name
        self.name = name
        self.values = values
        self._cache = {}  # Note: _cache seems unused here

    def calculate(self, period: str) -> float:
        """Retrieve the value for the specified period.

        For this node type, calculation simply means retrieving the stored value.

        Args:
            period (str): The time period for which to retrieve the value.

        Returns:
            float: The value for the given period, or 0.0 if the period is not found.
        """
        return self.get_value(period)

    def set_value(self, period: str, value: float) -> None:
        """Update or add a value for a specific period.

        Modifies the stored data for the given period.

        Args:
            period (str): The time period to set the value for.
            value (float): The numerical value to store for the period.
        """
        self.values[period] = value
        # self.clear_cache() # Clear cache if it were used

    def has_value(self, period: str) -> bool:
        """Check if a value exists for the specified period.

        Args:
            period (str): The time period to check.

        Returns:
            bool: True if a value is stored for the period, False otherwise.
        """
        return period in self.values

    def get_value(self, period: str) -> float:
        """Retrieve the stored value for a specific period.

        Args:
            period (str): The time period for which to get the value.

        Returns:
            float: The stored value, defaulting to 0.0 if the period is not found.
        """
        return self.values.get(period, 0.0)

# --- END FILE: fin_statement_model/core/nodes/item_node.py ---

# --- START FILE: fin_statement_model/core/nodes/base.py ---
"""Defines the abstract base class for all nodes in the graph."""

from abc import ABC, abstractmethod


class Node(ABC):
    """Abstract base class for graph nodes.

    Defines the essential interface for all nodes within the financial
    statement model graph, including calculation logic and attribute access.

    Attributes:
        name (str): The unique identifier for the node.
    """

    name: str

    def __init__(self, name: str):
        """Initialize the node with a unique name.

        Args:
            name (str): The unique identifier for the node. Must be non-empty.

        Raises:
            ValueError: If the provided name is empty or not a string.
        """
        if not isinstance(name, str) or not name:
            raise ValueError("Node name must be a non-empty string.")
        self.name = name

    @abstractmethod
    def calculate(self, period: str) -> float:
        """Calculate the node's value for a specific period.

        This method must be implemented by subclasses to define how the
        node's value is determined for a given time period.

        Args:
            period (str): The time period for which to calculate the value.

        Returns:
            float: The calculated value for the specified period.

        Raises:
            NotImplementedError: If the subclass does not implement this method.
        """

    def clear_cache(self):
        """Clear any cached calculation results for this node.

        Subclasses that implement caching should override this method
        to clear their internal cache. The default implementation does nothing.
        """
        # Default: no cache to clear

    def has_attribute(self, attr_name: str) -> bool:
        """Check if the node instance possesses a specific attribute.

        Args:
            attr_name (str): The name of the attribute to check for.

        Returns:
            bool: True if the attribute exists, False otherwise.
        """
        return hasattr(self, attr_name)

    def get_attribute(self, attribute_name: str) -> object:
        """Get an attribute from the node.

        Raises:
            AttributeError: If the attribute does not exist.
        """
        try:
            return getattr(self, attribute_name)
        except AttributeError:
            raise AttributeError(f"Node '{self.name}' has no attribute '{attribute_name}'")

    def has_value(self, period: str) -> bool:
        """Indicate if the node stores a direct value for the period.

        Primarily intended for nodes that store raw data rather than calculate.
        Calculation nodes typically override `has_calculation`.

        Args:
            period (str): The time period to check for a stored value.

        Returns:
            bool: False by default. Subclasses storing data should override.
        """
        return False

    def get_value(self, period: str) -> float:
        """Retrieve the node's directly stored value for a period.

        This method is intended for nodes that hold raw data. Subclasses
        that store data should implement this.

        Args:
            period (str): The time period for which to retrieve the value.

        Returns:
            float: The stored value for the period.

        Raises:
            NotImplementedError: If the node type does not store direct values.
        """
        raise NotImplementedError(f"Node {self.name} does not implement get_value")

    def has_calculation(self) -> bool:
        """Indicate if this node performs a calculation.

        Distinguishes calculation nodes from data-holding nodes.

        Returns:
            bool: False by default. Calculation nodes should override to True.
        """
        return False

# --- END FILE: fin_statement_model/core/nodes/base.py ---

# --- START FILE: fin_statement_model/core/strategies/registry.py ---
"""Registry for calculation strategies in the Financial Statement Model.

This module provides a central registry for discovering and accessing different
calculation strategy classes. Strategies can be registered using their class
object and later retrieved by their class name.
"""

from __future__ import annotations

# Use lowercase built-in types
from typing import ClassVar  # Keep Type for now
import logging

from .strategy import Strategy

# Configure logging
logger = logging.getLogger(__name__)


class Registry:
    """A central registry for managing and accessing calculation strategies.

    This class uses class methods to provide a global registry. Strategies
    are stored in a dictionary mapping their class name (string) to the
    strategy class itself.

    Attributes:
        _strategies: A dictionary holding the registered strategy classes.
                     Keys are strategy class names (str), values are strategy
                     types (Type[Strategy]).
    """

    _strategies: ClassVar[dict[str, type[Strategy]]] = {}  # Use dict, type

    @classmethod
    def register(cls, strategy: type[Strategy]) -> None:
        """Register a strategy class with the registry.

        If a strategy with the same name is already registered, it will be
        overwritten.

        Args:
            strategy: The calculation strategy class (Type[Strategy]) to register.
                      The class's __name__ attribute will be used as the key.
        """
        if not issubclass(strategy, Strategy):
            raise TypeError(f"Can only register subclasses of Strategy, not {strategy}")
        cls._strategies[strategy.__name__] = strategy
        logger.debug(f"Registered strategy: {strategy.__name__}")

    @classmethod
    def get(cls, name: str) -> type[Strategy]:
        """Retrieve a strategy class from the registry by its name.

        Args:
            name: The string name of the strategy class to retrieve.

        Returns:
            The strategy class (Type[Strategy]) associated with the given name.

        Raises:
            KeyError: If no strategy with the specified name is found in the
                      registry.
        """
        # Debug print including id of the dictionary
        if name not in cls._strategies:
            logger.error(f"Attempted to access unregistered strategy: {name}")
            raise KeyError(f"Strategy '{name}' not found in registry.")
        return cls._strategies[name]

    @classmethod
    def list(cls) -> dict[str, type[Strategy]]:  # Use dict, type
        """List all registered strategy classes.

        Returns:
            A dictionary containing all registered strategy names (str) and their
            corresponding strategy classes (Type[Strategy]). Returns a copy
            to prevent modification of the internal registry.
        """
        return cls._strategies.copy()

# --- END FILE: fin_statement_model/core/strategies/registry.py ---

# --- START FILE: fin_statement_model/core/strategies/__init__.py ---
"""Strategies module for the Financial Statement Model.

This module provides classes for implementing the Strategy Pattern for calculations
in the Financial Statement Model. It allows different calculation algorithms to be
defined, registered, and applied to financial data.
"""

from .strategy import (
    Strategy,
    AdditionStrategy,
    SubtractionStrategy,
    MultiplicationStrategy,
    DivisionStrategy,
    WeightedAverageStrategy,
    CustomFormulaStrategy,
)
from .registry import Registry

# Register strategies
Registry.register(AdditionStrategy)
Registry.register(SubtractionStrategy)
Registry.register(MultiplicationStrategy)
Registry.register(DivisionStrategy)
Registry.register(WeightedAverageStrategy)
Registry.register(CustomFormulaStrategy)

__all__ = [
    "AdditionStrategy",
    "CustomFormulaStrategy",
    "DivisionStrategy",
    "MultiplicationStrategy",
    "Registry",
    "Strategy",
    "SubtractionStrategy",
    "WeightedAverageStrategy",
]

# --- END FILE: fin_statement_model/core/strategies/__init__.py ---

# --- START FILE: fin_statement_model/core/strategies/strategy.py ---
"""Strategy for the Financial Statement Model.

This module provides the Strategy Pattern implementation for strategies,
allowing different calculation types to be encapsulated in strategy classes.
"""

from __future__ import annotations

from abc import ABC, abstractmethod
from typing import Callable, Optional, TYPE_CHECKING
import logging

if TYPE_CHECKING:
    from fin_statement_model.core.nodes.base import Node  # Absolute

# Configure logging
logger = logging.getLogger(__name__)


class Strategy(ABC):
    """Abstract base class for all calculation strategies.

    This class defines the interface that all concrete calculation strategies must
    implement. It employs the Strategy design pattern, allowing the algorithm
    used by a CalculationNode to be selected at runtime.

    Each concrete strategy encapsulates a specific method for calculating a
    financial value based on a list of input nodes and a given time period.
    """

    @abstractmethod
    def calculate(self, inputs: list[Node], period: str) -> float:
        """Calculate a value based on the input nodes for a specific period.

        This abstract method must be implemented by all concrete strategy classes.
        It defines the core calculation logic for the strategy.

        Args:
            inputs: A list of input Node objects whose values will be used in
                the calculation.
            period: The time period string (e.g., "2023Q1") for which the
                calculation should be performed.

        Returns:
            The calculated numerical value as a float.

        Raises:
            NotImplementedError: If the method is not implemented by a subclass.
            ValueError: If the inputs are invalid for the specific strategy
                (e.g., wrong number of inputs, incompatible types).
            ZeroDivisionError: If the strategy involves division and a divisor is zero.
            Exception: Potentially other exceptions depending on the specific
                calculation logic.
        """
        # pragma: no cover

    @property
    def description(self) -> str:
        """Provides a human-readable description of the calculation strategy.

        This is useful for documentation, debugging, and potentially for user
        interfaces that need to explain how a value is derived.

        Returns:
            A string describing the strategy.
        """
        # Default implementation returns the class name. Subclasses should override
        # for more specific descriptions.
        class_name = self.__class__.__name__  # pragma: no cover
        return class_name


class AdditionStrategy(Strategy):
    """Implements an addition strategy, summing values from multiple input nodes.

    This strategy calculates the total sum of the values obtained from calling
    the `calculate` method on each of the provided input nodes for a given period.
    """

    def calculate(self, inputs: list[Node], period: str) -> float:
        """Sums the calculated values from all input nodes for the specified period.

        Args:
            inputs: A list of Node objects.
            period: The time period string (e.g., "2023Q4") for the calculation.

        Returns:
            The total sum of the values calculated from the input nodes. Returns
            0.0 if the input list is empty.

        Examples:
            >>> class MockNode:
            ...     def __init__(self, value): self._value = value
            ...     def calculate(self, period): return self._value
            >>> strategy = AdditionStrategy()
            >>> nodes = [MockNode(10), MockNode(20), MockNode(5)]
            >>> strategy.calculate(nodes, "2023")
            35.0
            >>> strategy.calculate([], "2023")
            0.0
        """
        logger.debug(f"Applying addition strategy for period {period}")
        # Using a generator expression for potentially better memory efficiency
        return sum(input_node.calculate(period) for input_node in inputs)

    @property
    def description(self) -> str:
        """Returns a description of the addition strategy."""
        return "Addition (sum of all inputs)"


class SubtractionStrategy(Strategy):
    """Implements a subtraction strategy: first input minus the sum of the rest.

    This strategy takes the calculated value of the first node in the input list
    and subtracts the sum of the calculated values of all subsequent nodes for
    a specific period.
    """

    def calculate(self, inputs: list[Node], period: str) -> float:
        """Calculates the difference: value of the first input minus the sum of others.

        Args:
            inputs: A list of Node objects. Must contain at least one node.
            period: The time period string (e.g., "2024Q1") for the calculation.

        Returns:
            The result of the subtraction. If only one input node is provided,
            its value is returned.

        Raises:
            ValueError: If the `inputs` list is empty.

        Examples:
            >>> class MockNode:
            ...     def __init__(self, value): self._value = value
            ...     def calculate(self, period): return self._value
            >>> strategy = SubtractionStrategy()
            >>> nodes = [MockNode(100), MockNode(20), MockNode(30)]
            >>> strategy.calculate(nodes, "2023")
            50.0
            >>> nodes_single = [MockNode(100)]
            >>> strategy.calculate(nodes_single, "2023")
            100.0
        """
        if not inputs:
            raise ValueError("Subtraction strategy requires at least one input node")

        logger.debug(f"Applying subtraction strategy for period {period}")
        # Calculate values first to avoid multiple calls if nodes are complex
        values = [node.calculate(period) for node in inputs]
        return values[0] - sum(values[1:])

    @property
    def description(self) -> str:
        """Returns a description of the subtraction strategy."""
        return "Subtraction (first input minus sum of subsequent inputs)"


class MultiplicationStrategy(Strategy):
    """Implements a multiplication strategy, calculating the product of input values.

    This strategy multiplies the calculated values of all provided input nodes
    for a given period.
    """

    def calculate(self, inputs: list[Node], period: str) -> float:
        """Calculates the product of the values from all input nodes.

        Args:
            inputs: A list of Node objects.
            period: The time period string (e.g., "2023FY") for the calculation.

        Returns:
            The product of all input values. Returns 1.0 (multiplicative identity)
            if the input list is empty.

        Examples:
            >>> class MockNode:
            ...     def __init__(self, value): self._value = value
            ...     def calculate(self, period): return self._value
            >>> strategy = MultiplicationStrategy()
            >>> nodes = [MockNode(2), MockNode(3), MockNode(4)]
            >>> strategy.calculate(nodes, "2023")
            24.0
            >>> strategy.calculate([], "2023")
            1.0
        """
        # Multiplication strategy should ideally return 1.0 for empty inputs.
        # Raising error if empty seems less conventional for multiplication.
        if not inputs:
            logger.warning("Multiplication strategy called with empty inputs, returning 1.0")
            return 1.0

        logger.debug(f"Applying multiplication strategy for period {period}")
        result = 1.0
        for input_node in inputs:
            result *= input_node.calculate(period)
        return result

    @property
    def description(self) -> str:
        """Returns a description of the multiplication strategy."""
        return "Multiplication (product of all inputs)"


class DivisionStrategy(Strategy):
    """Implements a division strategy: first input divided by the product of the rest.

    This strategy takes the calculated value of the first node (numerator) and
    divides it by the product of the calculated values of all subsequent nodes
    (denominator) for a specific period.
    """

    def calculate(self, inputs: list[Node], period: str) -> float:
        """Calculates the division: first input / (product of subsequent inputs).

        Args:
            inputs: A list of Node objects. Must contain at least two nodes.
            period: The time period string (e.g., "2024Q2") for the calculation.

        Returns:
            The result of the division.

        Raises:
            ValueError: If `inputs` list contains fewer than two nodes.
            ZeroDivisionError: If the calculated product of the subsequent nodes
                (denominator) is zero.

        Examples:
            >>> class MockNode:
            ...     def __init__(self, value): self._value = value
            ...     def calculate(self, period): return self._value
            >>> strategy = DivisionStrategy()
            >>> nodes = [MockNode(100), MockNode(5), MockNode(2)]
            >>> strategy.calculate(nodes, "2023")
            10.0
            >>> nodes_zero_denom = [MockNode(100), MockNode(5), MockNode(0)]
            >>> try:
            ...     strategy.calculate(nodes_zero_denom, "2023")
            ... except ZeroDivisionError as e:
            ...     print(e)
            Division by zero: Denominator product is zero
        """
        if len(inputs) < 2:
            raise ValueError("Division strategy requires at least two input nodes")

        logger.debug(f"Applying division strategy for period {period}")

        values = [node.calculate(period) for node in inputs]
        numerator = values[0]

        denominator = 1.0
        for val in values[1:]:
            denominator *= val

        if denominator == 0.0:
            raise ZeroDivisionError("Division by zero: Denominator product is zero")

        return numerator / denominator

    @property
    def description(self) -> str:
        """Returns a description of the division strategy."""
        return "Division (first input / product of subsequent inputs)"


class WeightedAverageStrategy(Strategy):
    """Calculates the weighted average of input node values.

    This strategy computes the average of the values from input nodes, where each
    node's contribution is weighted. If no weights are provided during
    initialization, it defaults to an equal weighting (simple average).
    """

    def __init__(self, weights: Optional[list[float]] = None):
        """Initializes the WeightedAverageStrategy.

        Args:
            weights: An optional list of floats representing the weight for each
                corresponding input node. The length of this list must match the
                number of input nodes provided to the `calculate` method. If None,
                equal weights are assumed.
        """
        # Validate weights if provided immediately? No, validation happens in calculate
        # as the number of inputs isn't known here.
        self.weights = weights
        logger.info(f"Initialized WeightedAverageStrategy with weights: {weights}")

    def calculate(self, inputs: list[Node], period: str) -> float:
        """Computes the weighted average of the input node values for the period.

        Args:
            inputs: A list of Node objects.
            period: The time period string (e.g., "2023H1") for the calculation.

        Returns:
            The calculated weighted average as a float.

        Raises:
            ValueError: If the `inputs` list is empty.
            ValueError: If `weights` were provided during initialization and their
                count does not match the number of `inputs`.
            ValueError: If the sum of weights is zero (to prevent division by zero
                if normalization were implemented differently).

        Examples:
            >>> class MockNode:
            ...     def __init__(self, value): self._value = value
            ...     def calculate(self, period): return self._value
            >>> # Equal weights (simple average)
            >>> strategy_equal = WeightedAverageStrategy()
            >>> nodes = [MockNode(10), MockNode(20), MockNode(30)]
            >>> strategy_equal.calculate(nodes, "2023")
            20.0
            >>> # Custom weights
            >>> strategy_custom = WeightedAverageStrategy(weights=[0.5, 0.3, 0.2])
            >>> strategy_custom.calculate(nodes, "2023")
            17.0
            >>> # Mismatched weights
            >>> strategy_mismatch = WeightedAverageStrategy(weights=[0.5, 0.5])
            >>> try:
            ...     strategy_mismatch.calculate(nodes, "2023")
            ... except ValueError as e:
            ...     print(e)
            Number of weights (2) must match number of inputs (3)
        """
        if not inputs:
            raise ValueError("Weighted average strategy requires at least one input node")

        num_inputs = len(inputs)
        effective_weights: list[float]

        if self.weights is None:
            # Use equal weights if none provided
            if num_inputs == 0:  # Should be caught by the check above, but defensive
                return 0.0
            equal_weight = 1.0 / num_inputs
            effective_weights = [equal_weight] * num_inputs
            logger.debug("Using equal weights for weighted average.")
        elif len(self.weights) == num_inputs:
            effective_weights = self.weights
            logger.debug(f"Using provided weights: {effective_weights}")
        else:
            raise ValueError(
                f"Number of weights ({len(self.weights)}) must match "
                f"number of inputs ({num_inputs})"
            )

        logger.debug(f"Applying weighted average strategy for period {period}")
        weighted_sum = 0.0
        total_weight = sum(effective_weights)
        input_values = [node.calculate(period) for node in inputs]

        if total_weight == 0.0:
            # Avoid division by zero. If weights are all zero, the concept is ill-defined.
            # Returning 0 might be a reasonable default, or raising an error.
            # Let's raise ValueError for clarity.
            raise ValueError("Total weight for weighted average cannot be zero.")

        for value, weight in zip(input_values, effective_weights):
            weighted_sum += value * weight

        # If weights don't sum to 1, this isn't a standard weighted average.
        # Decide whether to normalize or return the weighted sum directly.
        # Normalize by total weight for a true weighted average.
        return weighted_sum / total_weight

    @property
    def description(self) -> str:
        """Returns a description of the weighted average strategy."""
        if self.weights:
            return f"Weighted Average (using provided weights: {self.weights})"
        else:
            return "Weighted Average (using equal weights)"


# Type alias for the custom formula function
FormulaFunc = Callable[[dict[str, float]], float]


class CustomFormulaStrategy(Strategy):
    """Executes a user-defined Python function to calculate a value.

    This strategy provides maximum flexibility by allowing any custom Python
    function to be used for calculation. The function receives a dictionary
    mapping input node names (or fallback names) to their calculated values
    for the period and should return a single float result.
    """

    def __init__(self, formula_function: FormulaFunc):
        """Initializes the CustomFormulaStrategy with a calculation function.

        Args:
            formula_function: A callable (function, lambda, etc.) that accepts
                a single argument: a dictionary mapping string keys (input node
                names or `input_<i>`) to their float values for the period.
                It must return a float.

        Raises:
            TypeError: If `formula_function` is not callable.
        """
        if not callable(formula_function):
            raise TypeError("formula_function must be callable")
        self.formula_function = formula_function
        logger.info(f"Initialized CustomFormulaStrategy with function: {formula_function.__name__}")

    def calculate(self, inputs: list[Node], period: str) -> float:
        """Applies the custom formula function to the calculated input values.

        Args:
            inputs: A list of Node objects.
            period: The time period string (e.g., "2025M1") for the calculation.

        Returns:
            The float result returned by the `formula_function`.

        Raises:
            ValueError: If the `formula_function` encounters an error during execution
                (e.g., incorrect input keys, calculation errors). Wraps the original
                exception.

        Examples:
            >>> class MockNode:
            ...     def __init__(self, name, value): self.name = name; self._value = value
            ...     def calculate(self, period): return self._value
            >>> def my_formula(data):
            ...     # Example: Gross Profit Margin
            ...     return (data['revenue'] - data['cogs']) / data['revenue'] * 100
            >>> strategy = CustomFormulaStrategy(my_formula)
            >>> nodes = [MockNode('revenue', 1000), MockNode('cogs', 600)]
            >>> strategy.calculate(nodes, "2023")
            40.0
            >>> # Example with unnamed nodes
            >>> def simple_sum(data):
            ...     return data['input_0'] + data['input_1']
            >>> strategy_unnamed = CustomFormulaStrategy(simple_sum)
            >>> nodes_unnamed = [MockNode(None, 10), MockNode(None, 20)] # No names
            >>> strategy_unnamed.calculate(nodes_unnamed, "2023")
            30.0
        """
        # Prepare input values dictionary, using names if available
        input_values: dict[str, float] = {}
        for i, node in enumerate(inputs):
            # Prefer node.name if it exists and is a non-empty string
            key = getattr(node, "name", None)
            if not isinstance(key, str) or not key:
                key = f"input_{i}"
            input_values[key] = node.calculate(period)

        logger.debug(
            f"Applying custom formula strategy for period {period} with inputs: {input_values}"
        )
        try:
            # Execute the user-provided function
            result = self.formula_function(input_values)
            if not isinstance(result, (int, float)):
                logger.warning(
                    f"Custom formula function {self.formula_function.__name__} "
                    f"returned non-numeric type: {type(result)}. Attempting cast."
                )
                # Attempt conversion, but be aware this might fail or be lossy
                try:
                    return float(result)
                except (ValueError, TypeError) as cast_err:
                    raise ValueError(
                        f"Custom formula {self.formula_function.__name__} result "
                        f"({result!r}) could not be cast to float."
                    ) from cast_err
            return float(result)  # Ensure result is float
        except Exception as e:
            # Catch any exception from the custom function and wrap it
            logger.error(
                f"Error executing custom formula '{self.formula_function.__name__}': {e}",
                exc_info=True,
            )
            raise ValueError(
                f"Error in custom formula '{self.formula_function.__name__}': {e}"
            ) from e

    @property
    def description(self) -> str:
        """Returns a description of the custom formula strategy."""
        func_name = getattr(self.formula_function, "__name__", "[anonymous function]")
        return f"Custom Formula (using function: {func_name})"

# --- END FILE: fin_statement_model/core/strategies/strategy.py ---

# --- START FILE: fin_statement_model/core/node_factory.py ---
"""Node Factory for the Financial Statement Model.

This module provides a factory for creating different types of nodes used in the financial statement model.
It centralizes node creation logic and ensures consistent node initialization.
"""

import logging
from typing import Callable, Any, Union, Optional, ClassVar

# Force import of strategies package to ensure registration happens

from .nodes import (
    Node,
    FinancialStatementItemNode,
    StrategyCalculationNode,
    MetricCalculationNode,
    CustomCalculationNode,
)
from .nodes.forecast_nodes import (
    FixedGrowthForecastNode,
    CurveGrowthForecastNode,
    StatisticalGrowthForecastNode,
    AverageValueForecastNode,
    AverageHistoricalGrowthForecastNode,
)

# Use absolute import for Registry to ensure consistency
# from .strategies import Registry, Strategy
from fin_statement_model.core.strategies import Registry, Strategy

# Configure logging
logger = logging.getLogger(__name__)


class NodeFactory:
    """Factory class for creating nodes in the financial statement model.

    This class centralizes the creation of all types of nodes, ensuring consistent
    initialization and simplifying the creation process. It provides methods
    for creating financial statement items, calculation nodes (via strategies,
    metrics, or custom functions).

    Attributes:
        _calculation_strategies: Maps simple string keys (e.g., 'addition') to
            the class names of Strategy implementations registered in the
            `Registry`. This allows creating StrategyCalculationNodes without
            directly importing Strategy classes.
    """

    # Mapping of calculation type strings to strategy names (keys in the Registry)
    _calculation_strategies: ClassVar[dict[str, str]] = {
        "addition": "AdditionStrategy",
        "subtraction": "SubtractionStrategy",
        "multiplication": "MultiplicationStrategy",
        "division": "DivisionStrategy",
        "weighted_average": "WeightedAverageStrategy",
        "custom_formula": "CustomFormulaStrategy",
    }

    # Mapping from node type names to Node classes
    _node_types: ClassVar[dict[str, type[Node]]] = {
        "financial_statement_item": FinancialStatementItemNode,
        "metric_calculation": MetricCalculationNode,
    }

    @classmethod
    def create_financial_statement_item(
        cls, name: str, values: dict[str, float]
    ) -> FinancialStatementItemNode:
        """Creates a FinancialStatementItemNode representing a base financial item.

        This node typically holds historical or projected values for a specific
        line item (e.g., Revenue, COGS) over different periods.

        Args:
            name: The unique identifier for the node (e.g., "Revenue").
            values: A dictionary where keys are period identifiers (e.g., "2023Q1")
                and values are the corresponding numerical values for that period.

        Returns:
            An initialized FinancialStatementItemNode.

        Raises:
            ValueError: If the provided name is empty or not a string.

        Example:
            >>> revenue_node = NodeFactory.create_financial_statement_item(
            ...     name="Revenue",
            ...     values={"2023": 1000.0, "2024": 1100.0}
            ... )
            >>> revenue_node.name
            'Revenue'
            >>> revenue_node.get_value("2023")
            1000.0
        """
        if not name or not isinstance(name, str):
            raise ValueError("Node name must be a non-empty string")

        logger.debug(f"Creating financial statement item node: {name}")
        return FinancialStatementItemNode(name, values)

    @classmethod
    def create_calculation_node(
        cls,
        name: str,
        inputs: list[Node],
        calculation_type: str,
        **strategy_kwargs: Any,
    ) -> StrategyCalculationNode:
        """Creates a StrategyCalculationNode using a pre-defined calculation strategy.

        This method looks up the calculation strategy based on the `calculation_type`
        string (e.g., 'addition', 'division') in the `_calculation_strategies`
        map, retrieves the corresponding Strategy class from the `Registry`,
        instantiates it (passing `strategy_kwargs`), and creates the node.

        Args:
            name: The unique identifier for the calculation node (e.g., "GrossProfit").
            inputs: A list of Node objects that serve as inputs to the calculation.
            calculation_type: A string key representing the desired calculation
                (e.g., 'addition', 'subtraction', 'custom_formula'). Must match a
                key in `_calculation_strategies`.
            **strategy_kwargs: Additional keyword arguments required by the specific
                Strategy's constructor. For example, 'CustomFormulaStrategy' might
                require a 'formula_string' kwarg.

        Returns:
            An initialized StrategyCalculationNode configured with the specified strategy.

        Raises:
            ValueError: If `name` is invalid, `inputs` is empty, `calculation_type`
                is not found in `_calculation_strategies`, or the corresponding
                strategy name is not registered in the `Registry`.
            TypeError: If the resolved strategy class cannot be instantiated with
                the provided `strategy_kwargs`.

        Example:
            Assuming 'revenue_node' and 'cogs_node' exist:
            >>> gross_profit_node = NodeFactory.create_calculation_node(
            ...     name="GrossProfit",
            ...     inputs=[revenue_node, cogs_node],
            ...     calculation_type="subtraction"
            ... )

            Using a strategy that requires extra arguments:
            >>> weighted_cost_node = NodeFactory.create_calculation_node(
            ...     name="WeightedCost",
            ...     inputs=[cost_node1, cost_node2],
            ...     calculation_type="weighted_average",
            ...     weights=[0.6, 0.4] # Passed as strategy_kwargs
            ... )

            Using a custom formula string (assuming 'CustomFormulaStrategy' exists):
            >>> ratio_node = NodeFactory.create_calculation_node(
            ...     name="DebtEquityRatio",
            ...     inputs=[debt_node, equity_node],
            ...     calculation_type="custom_formula",
            ...     formula_string="debt / equity" # Passed as strategy_kwargs
            ... )
        """
        # Validate inputs
        if not name or not isinstance(name, str):
            raise ValueError("Node name must be a non-empty string")

        if not inputs:
            raise ValueError("Calculation node must have at least one input")

        # Check if the calculation type maps to a known strategy name
        if calculation_type not in cls._calculation_strategies:
            valid_types = list(cls._calculation_strategies.keys())
            raise ValueError(
                f"Invalid calculation type: '{calculation_type}'. Valid types are: {valid_types}"
            )

        # Get the strategy name and resolve the strategy class from the registry
        strategy_name = cls._calculation_strategies[calculation_type]
        try:
            # Assuming Registry.get returns the strategy class
            strategy_cls: type[Strategy] = Registry.get(strategy_name)
        except KeyError:
            raise ValueError(
                f"Strategy '{strategy_name}' not found in Registry for type '{calculation_type}'"
            )

        # Instantiate the strategy, passing any extra kwargs
        try:
            strategy_instance = strategy_cls(**strategy_kwargs)
        except TypeError as e:
            logger.exception(
                f"Failed to instantiate strategy '{strategy_name}' with kwargs {strategy_kwargs}"
            )
            raise TypeError(
                f"Could not instantiate strategy '{strategy_name}' for node '{name}'. "
                f"Check required arguments for {strategy_cls.__name__}. Provided kwargs: {strategy_kwargs}"
            ) from e

        # Create and return a StrategyCalculationNode with the instantiated strategy
        logger.debug(
            f"Creating strategy calculation node '{name}' with '{strategy_name}' strategy."
        )
        return StrategyCalculationNode(name, inputs, strategy_instance)

    @classmethod
    def create_metric_node(
        cls, name: str, metric_name: str, input_nodes: dict[str, Node]
    ) -> MetricCalculationNode:
        """Creates a MetricCalculationNode based on a pre-defined metric definition.

        This node represents a standard financial metric (e.g., "current_ratio")
        whose calculation logic (inputs, formula) is defined elsewhere, typically
        loaded from configuration (like YAML files) and managed by the
        `MetricCalculationNode` itself or a metric registry.

        Args:
            name: The unique identifier for this specific instance of the metric node
                (e.g., "CompanyCurrentRatio").
            metric_name: The key identifying the metric definition (e.g.,
                "current_ratio"). This key is used by `MetricCalculationNode`
                to look up the definition (inputs, formula, description).
            input_nodes: A dictionary mapping the *required input names* defined
                in the metric definition (e.g., "total_current_assets") to the
                actual `Node` objects providing those values (e.g.,
                `{"total_current_assets": assets_node, "total_current_liabilities": liab_node}`).

        Returns:
            An initialized MetricCalculationNode instance, ready to calculate the metric.

        Raises:
            ValueError: If `name` is invalid, `metric_name` does not correspond to a
                valid metric definition, the definition is incomplete, or the
                provided `input_nodes` do not match the required inputs specified
                in the metric definition (missing keys, extra keys, wrong types).
            TypeError: If `input_nodes` is not a dictionary.

        Example:
            Assuming 'assets_node' and 'liabilities_node' exist, and a metric
            definition for "current_ratio" exists requiring inputs named
            "current_assets" and "current_liabilities":
            >>> current_ratio_node = NodeFactory.create_metric_node(
            ...     name="CompanyCurrentRatio",
            ...     metric_name="current_ratio",
            ...     input_nodes={
            ...         "current_assets": assets_node,
            ...         "current_liabilities": liabilities_node
            ...     }
            ... )
        """
        logger.debug(f"Attempting to create metric node '{name}' for metric '{metric_name}'")

        # Basic input validation
        if not name or not isinstance(name, str):
            raise ValueError("Node name must be a non-empty string")
        if not isinstance(input_nodes, dict):
            raise TypeError("input_nodes must be a dictionary of Node objects.")

        # The MetricCalculationNode constructor now handles definition loading,
        # validation of the definition, and validation of input_nodes.
        try:
            node = MetricCalculationNode(
                name=name, metric_name=metric_name, input_nodes=input_nodes
            )
            logger.info(
                f"Successfully created MetricCalculationNode '{name}' for metric '{metric_name}'"
            )
            return node
        except (ValueError, TypeError):
            logger.exception(
                f"Failed to create MetricCalculationNode '{name}' for metric '{metric_name}'"
            )
            # Re-raise the specific error from the constructor
            raise
        else:
            return node

    @classmethod
    def create_forecast_node(
        cls,
        name: str,
        base_node: Node,
        base_period: str,
        forecast_periods: list[str],
        forecast_type: str,
        growth_params: Union[float, list[float], Callable[[], float]],
    ) -> Node:
        """Create a forecast node of the specified type using core forecast classes."""
        if forecast_type == "fixed":
            return FixedGrowthForecastNode(base_node, base_period, forecast_periods, growth_params)
        elif forecast_type == "curve":
            return CurveGrowthForecastNode(base_node, base_period, forecast_periods, growth_params)
        elif forecast_type == "statistical":
            return StatisticalGrowthForecastNode(
                base_node, base_period, forecast_periods, growth_params
            )
        elif forecast_type == "average":
            return AverageValueForecastNode(base_node, base_period, forecast_periods, growth_params)
        elif forecast_type == "historical_growth":
            return AverageHistoricalGrowthForecastNode(
                base_node, base_period, forecast_periods, growth_params
            )
        else:
            raise ValueError(f"Invalid forecast type: {forecast_type}")

    @classmethod
    def _create_custom_node_from_callable(
        cls,
        name: str,
        inputs: list[Node],
        formula: Callable,
        description: Optional[str] = None,
    ) -> CustomCalculationNode:
        """Creates a CustomCalculationNode using a Python callable for the calculation logic.

        This is suitable for ad-hoc or complex calculations that are not covered by
        standard strategies or pre-defined metrics. The provided `formula` function
        will be executed during the calculation phase.

        Note:
            Previously named `create_metric_node`, renamed to avoid confusion with
            `MetricCalculationNode` which relies on defined metric specifications.

        Args:
            name: The unique identifier for the custom calculation node.
            inputs: A list of Node objects whose values will be passed as arguments
                to the `formula` function during calculation. The order matters if
                the formula expects positional arguments.
            formula: A Python callable (function, lambda, method) that performs the
                calculation. It should accept arguments corresponding to the values
                of the `inputs` nodes for a given period and return the calculated value.
            description: An optional string describing the purpose of the calculation.

        Returns:
            An initialized CustomCalculationNode.

        Raises:
            ValueError: If `name` is invalid.
            TypeError: If `formula` is not a callable or if any item in `inputs`
                is not a `Node` instance.

        Example:
            >>> def complex_tax_logic(revenue, expenses, tax_rate_node):
            ...     profit = revenue - expenses
            ...     if profit <= 0:
            ...         return 0.0
            ...     # Assume tax_rate_node.get_value(period) returns the rate
            ...     # (Actual implementation details depend on how CalculationEngine passes values)
            ...     # This example assumes values are passed directly
            ...     tax_rate = tax_rate_node # Or the value extracted by the engine
            ...     return profit * tax_rate
            ...
            >>> tax_node = NodeFactory._create_custom_node_from_callable(
            ...     name="CalculatedTaxes",
            ...     inputs=[revenue_node, expenses_node, tax_rate_schedule_node],
            ...     formula=complex_tax_logic,
            ...     description="Calculates income tax based on profit and a variable rate."
            ... )

            Using a lambda for a simple ratio:
            >>> quick_ratio_node = NodeFactory._create_custom_node_from_callable(
            ...    name="QuickRatioCustom",
            ...    inputs=[cash_node, receivables_node, current_liabilities_node],
            ...    formula=lambda cash, rec, liab: (cash + rec) / liab if liab else 0
            ... )
        """
        # Validate inputs
        if not name or not isinstance(name, str):
            raise ValueError("Node name must be a non-empty string")

        if not inputs:
            # Allowing no inputs might be valid for some custom functions (e.g., constants)
            # Reconsider if this check is always needed here.
            logger.warning(f"Creating CustomCalculationNode '{name}' with no inputs.")
            # raise ValueError("Custom node must have at least one input")

        if not callable(formula):
            raise TypeError("Formula must be a callable function")
        if not all(isinstance(i, Node) for i in inputs):
            raise TypeError("All items in inputs must be Node instances.")

        # Use the imported CustomCalculationNode
        logger.debug(f"Creating CustomCalculationNode: {name} using provided callable.")
        return CustomCalculationNode(name, inputs, formula_func=formula, description=description)

    # Consider adding a method for creating FormulaCalculationNode if needed directly
    # @classmethod
    # def create_formula_node(cls, name: str, inputs: Dict[str, Node], formula: str) -> FormulaCalculationNode:
    #     ...

# --- END FILE: fin_statement_model/core/node_factory.py ---

# --- START FILE: fin_statement_model/core/graph/manipulation.py ---
"""Provides graph manipulation capabilities as a mixin class.

This mixin is intended to be used by the main `Graph` class. It encapsulates
operations related to adding, removing, retrieving, and modifying nodes within
the graph structure. It assumes the presence of a `nodes` dictionary and
potentially a `_calculation_engine` and `_periods` list in the class it's mixed into.
"""

import logging
from typing import TYPE_CHECKING, Optional

# Import Node for runtime isinstance checks. Other heavy imports are limited to TYPE_CHECKING to
# prevent unnecessary circular dependencies at runtime.
from fin_statement_model.core.nodes import Node

if TYPE_CHECKING:
    from fin_statement_model.core.calculation_engine import CalculationEngine
    from fin_statement_model.core.data_manager import DataManager

from fin_statement_model.core.errors import NodeError

logger = logging.getLogger(__name__)


class GraphManipulationMixin:
    """Mixin class providing methods for manipulating the graph's nodes.

    Includes operations like adding, removing, replacing, and retrieving nodes,
    as well as setting node values and clearing caches. Relies on the main class
    (e.g., `Graph`) to provide the `nodes` dictionary and potentially other
    attributes like `_calculation_engine` and `_periods`.
    """

    # Type hints for attributes assumed to exist in the main Graph class
    _nodes: dict[str, "Node"]
    _calculation_engine: "CalculationEngine"
    _data_manager: "DataManager"
    _periods: list[str]

    def set_calculation_engine(self, engine: "CalculationEngine") -> None:
        """Assigns a calculation engine instance to the graph.

        Validates that the provided engine object has the expected methods
        (`calculate`, `set_graph`) before assigning it.

        Args:
            engine: The calculation engine instance to associate with this graph.
                    Expected to conform to the CalculationEngine interface.

        Raises:
            TypeError: If the provided `engine` object does not have the required
                       methods (`calculate` and `set_graph`).
        """
        # Raise TypeError if required methods are missing
        if not hasattr(engine, "calculate"):
            raise TypeError("Calculation engine instance must have a 'calculate' method.")
        if not hasattr(engine, "set_graph"):
            raise TypeError("Calculation engine instance must have a 'set_graph' method.")

        self._calculation_engine = engine
        # Assuming set_graph exists now due to the checks above
        self._calculation_engine.set_graph(self)

    def add_node(self, node: "Node") -> None:
        """Adds a node to the graph's node registry, replacing if name exists.

        Also informs the DataManager and CalculationEngine about the new node.

        Args:
            node: The Node object to add.

        Raises:
            TypeError: If the provided object is not a Node instance.
        """
        if not isinstance(node, Node):
            raise TypeError(f"Object {node} is not a valid Node instance.")
        if self.has_node(node.name):
            self.remove_node(node.name)

        self._nodes[node.name] = node

        if hasattr(self._data_manager, "_register_node"):
            self._data_manager._register_node(node)
        if hasattr(self._calculation_engine, "_register_node"):
            self._calculation_engine._register_node(node)

    def _update_calculation_nodes(self) -> None:
        """Refreshes input references for all calculation nodes.

        Iterates through all nodes. If a node is a calculation node
        (has `has_calculation()` and `input_names`), it re-resolves its input
        nodes based on their names from the current graph state and updates
        the node's `inputs` attribute. Clears the node's cache if applicable.
        This is crucial after adding, removing, or replacing nodes to maintain
        graph integrity.

        Logs errors if input nodes cannot be found or if a node lacks the
        expected 'inputs' attribute.
        """
        for nd in self._nodes.values():
            if nd.has_calculation() and hasattr(nd, "input_names") and nd.input_names:
                try:
                    resolved_inputs = []
                    for name in nd.input_names:
                        input_node = self.get_node(name)
                        if input_node is None:
                            raise NodeError(
                                f"Input node '{name}' not found for calculation node '{nd.name}'"
                            )
                        resolved_inputs.append(input_node)
                    nd.inputs = resolved_inputs
                    if hasattr(nd, "clear_cache"):
                        nd.clear_cache()
                except NodeError:
                    logger.exception(f"Error updating inputs for node '{nd.name}'")
                except AttributeError:
                    logger.warning(
                        f"Node '{nd.name}' has input_names but no 'inputs' attribute to update."
                    )

    def get_node(self, name: str) -> Optional["Node"]:
        """Retrieves a node from the graph by its unique name.

        Args:
            name: The string name of the node to retrieve.

        Returns:
            The `Node` object if found, otherwise `None`.

        Example:
            >>> class MockGraph(GraphManipulationMixin):
            ...     def __init__(self): self.nodes = {}
            ...     # Simplified methods needed by mixin
            ...     _nodes: Dict[str, Node] = {}
            ...     _calculation_engine: Optional[Any] = None
            ...     _periods: List[str] = []
            ...     def _update_calculation_nodes(self): pass
            ...     def get_node(self, name: str) -> Optional[Node]: return self.nodes.get(name)
            >>> from fin_statement_model.core.nodes import FinancialStatementItemNode # Assume import
            >>> graph = MockGraph()
            >>> graph.nodes["COGS"] = FinancialStatementItemNode("COGS", {"2023": 50})
            >>> cogs_node = graph.get_node("COGS")
            >>> print(cogs_node.name)
            COGS
            >>> non_existent = graph.get_node("NonExistent")
            >>> print(non_existent)
            None
        """
        return self._nodes.get(name)

    def replace_node(self, node_name: str, new_node: "Node") -> None:
        """Replaces an existing node with a new one, ensuring consistency."""
        if not self.has_node(node_name):
            raise NodeError(f"Node '{node_name}' not found, cannot replace.")
        if node_name != new_node.name:
            raise ValueError("New node name must match the name of the node being replaced.")

        self.remove_node(node_name)
        self.add_node(new_node)

    def has_node(self, node_id: str) -> bool:
        """Checks if a node with the given ID (name) exists in the graph.

        Args:
            node_id: The string ID (name) of the node to check for.

        Returns:
            True if a node with the specified ID exists, False otherwise.

        Example:
            >>> class MockGraph(GraphManipulationMixin):
            ...     def __init__(self): self.nodes = {}
            ...     # Simplified methods needed by mixin
            ...     _nodes: Dict[str, Node] = {}
            ...     _calculation_engine: Optional[Any] = None
            ...     _periods: List[str] = []
            ...     def _update_calculation_nodes(self): pass
            ...     def get_node(self, name: str) -> Optional[Node]: return self.nodes.get(name)
            >>> from fin_statement_model.core.nodes import FinancialStatementItemNode # Assume import
            >>> graph = MockGraph()
            >>> graph.nodes["Assets"] = FinancialStatementItemNode("Assets", {"2023": 1000})
            >>> print(graph.has_node("Assets"))
            True
            >>> print(graph.has_node("Liabilities"))
            False
        """
        return node_id in self._nodes

    def remove_node(self, node_name: str) -> None:
        """Removes a node from the graph and updates dependencies."""
        if not self.has_node(node_name):
            return

        removed_node = self._nodes.pop(node_name, None)

        if hasattr(self._data_manager, "_unregister_node") and removed_node:
            self._data_manager._unregister_node(removed_node)
        if hasattr(self._calculation_engine, "_unregister_node") and removed_node:
            self._calculation_engine._unregister_node(removed_node)

        self._update_calculation_nodes()
        if self._calculation_engine:
            try:
                self._calculation_engine.clear_cache()
            except Exception:
                logger.exception("Error clearing calculation engine cache")

    def clear(self) -> None:
        """Removes all nodes and periods from the graph, resetting its state.

        Clears the internal node registry (`nodes`) and the list of periods
        (`_periods`). If a calculation engine is attached, it attempts to
        reset the engine as well.

        Example:
            >>> class MockGraph(GraphManipulationMixin):
            ...     def __init__(self):
            ...         self.nodes = {"Node1": None, "Node2": None} # Assume Nodes
            ...         self._nodes = self.nodes # Link for mixin
            ...         self._periods = ["2023", "2024"]
            ...         self._calculation_engine = None # Mock engine
            >>> graph = MockGraph()
            >>> print(len(graph.nodes))
            2
            >>> print(len(graph._periods))
            2
            >>> graph.clear()
            >>> print(len(graph.nodes))
            0
            >>> print(len(graph._periods))
            0
        """
        self._nodes = {}
        self._periods = []
        if self._calculation_engine:
            try:
                self._calculation_engine.reset()
            except Exception:
                logger.exception("Error resetting calculation engine")

    def set_value(self, node_id: str, period: str, value: float) -> None:
        """Sets the value for a specific node and period, clearing caches.

        This method is typically used for nodes representing input data
        (like `FinancialStatementItemNode`). It finds the node, verifies the
        period exists, and calls the node's `set_value` method.
        Requires the target node to implement a `set_value` method.
        Clears relevant caches after setting the value.

        Args:
            node_id: The string ID (name) of the node to modify.
            period: The string representation of the time period.
            value: The float value to assign to the node for the given period.

        Raises:
            ValueError: If the specified `period` is not found in the graph's
                        list of periods (`self._periods`).
            NodeError: If no node with the specified `node_id` exists.
            TypeError: If the found node does not have a `set_value` method.

        Example:
            >>> class MockGraph(GraphManipulationMixin):
            ...     def __init__(self):
            ...         self.nodes = {}
            ...         self._nodes = self.nodes
            ...         self._periods = ["2023"]
            ...         self._calculation_engine = None
            ...     def get_node(self, name: str) -> Optional[Node]: return self.nodes.get(name)
            ...     def clear_all_caches(self): pass # No-op
            >>> from fin_statement_model.core.nodes import FinancialStatementItemNode
            >>> from fin_statement_model.core.errors import NodeError
            >>> graph = MockGraph()
            >>> item_node = FinancialStatementItemNode("Sales", {"2023": 500})
            >>> graph.nodes["Sales"] = item_node
            >>> graph.set_value("Sales", "2023", 600)
            >>> print(item_node.get_value("2023"))
            600
            >>> try:
            ...     graph.set_value("Sales", "2024", 700) # Invalid period
            ... except ValueError as e:
            ...     print(e)
            Period '2024' not in graph periods
            >>> try:
            ...     graph.set_value("NonExistent", "2023", 100)
            ... except NodeError as e:
            ...     print(e.message)
            Node 'NonExistent' does not exist
        """
        if period not in self._periods:
            raise ValueError(f"Period '{period}' not in graph periods")
        nd = self.get_node(node_id)
        if not nd:
            raise NodeError(message=f"Node '{node_id}' does not exist", node_id=node_id)
        if not hasattr(nd, "set_value"):
            raise TypeError(
                f"Node '{node_id}' of type {type(nd).__name__} does not support set_value."
            )
        nd.set_value(period, value)
        if self._calculation_engine:
            try:
                self._calculation_engine.clear_cache()
            except Exception:
                logger.exception("Error clearing calculation engine cache")
        else:
            self.clear_all_caches()

    def clear_all_caches(self) -> None:
        """Clears caches associated with individual nodes in the graph.

        Iterates through all nodes in the registry and calls the `clear_cache`
        method on each node if it exists. This primarily affects nodes that
        cache their own computed values (e.g., calculation strategies).

        Note:
            This method clears node-level caches. The main `Graph` class might
            have a similar method that also clears the central `CalculationEngine` cache.

        Example:
            >>> class MockNode:
            ...     def __init__(self):
            ...         self.cache_cleared = False
            ...     def clear_cache(self):
            ...         self.cache_cleared = True
            >>> class MockGraph(GraphManipulationMixin):
            ...     def __init__(self):
            ...         self.node1 = MockNode()
            ...         self.node2 = FinancialStatementItemNode("Item", {}) # No cache
            ...         self.node3 = MockNode()
            ...         self.nodes = {"N1": self.node1, "N2": self.node2, "N3": self.node3}
            ...         self._nodes = self.nodes # Link for mixin
            >>> graph = MockGraph()
            >>> print(graph.node1.cache_cleared, graph.node3.cache_cleared)
            False False
            >>> graph.clear_all_caches()
            >>> print(graph.node1.cache_cleared, graph.node3.cache_cleared)
            True True
        """
        for nd in self._nodes.values():
            if hasattr(nd, "clear_cache"):
                nd.clear_cache()

# --- END FILE: fin_statement_model/core/graph/manipulation.py ---

# --- START FILE: fin_statement_model/core/graph/traversal.py ---
"""Provides graph traversal and validation capabilities as a mixin class.

This mixin is intended to be used by the main `Graph` class. It encapsulates
operations related to traversing the graph, such as finding dependencies,
performing topological sorts, and detecting cycles. It assumes the presence of
a `nodes` dictionary and methods like `get_node` and `has_node` in the class
it's mixed into.
"""

import logging
from typing import Optional, TYPE_CHECKING
from fin_statement_model.core.errors import NodeError
from collections import deque

if TYPE_CHECKING:
    from fin_statement_model.core.nodes import Node

logger = logging.getLogger(__name__)


class GraphTraversalMixin:
    """Mixin class providing methods for traversing and validating the graph.

    Includes operations like topological sorting, dependency retrieval,
    cycle detection, and general graph validation. Relies on the main class
    (e.g., `Graph`) to provide the `nodes` dictionary and node access methods
    like `get_node` and `has_node`.
    """

    # Type hints for self attributes/methods expected from the main Graph class
    _nodes: dict[str, "Node"]

    def get_node(self, name: str) -> Optional["Node"]:
        """Retrieve a node from the graph by its name.

        Args:
            name: The name of the node to retrieve.

        Returns:
            The `Node` instance if found; otherwise, `None`.
        """

    def has_node(self, node_id: str) -> bool:
        """Check whether a node exists in the graph.

        Args:
            node_id: The name of the node to check.

        Returns:
            `True` if the node exists in the registry; otherwise, `False`.
        """

    def get_direct_successors(self, node_id: str) -> list[str]:
        """Get immediate successor node IDs for a given node.

        Args:
            node_id: The name of the node whose successors are requested.

        Returns:
            A list of names of nodes that directly depend on the given node.
        """

    def get_direct_predecessors(self, node_id: str) -> list[str]:
        """Get immediate predecessor node IDs (dependencies) for a given node.

        Args:
            node_id: The name of the node whose predecessors are requested.

        Returns:
            A list of names of nodes that the given node depends on directly.
        """

    def nodes(self) -> dict[str, "Node"]:
        """Access the full node registry dictionary.

        Returns:
            A mapping of node names to their corresponding `Node` instances.
        """

    def topological_sort(self) -> list[str]:
        """Performs a topological sort of the nodes based on dependencies.

        Uses Kahn's algorithm to determine a linear ordering of nodes such that for
        every directed edge from node `u` to node `v`, `u` comes before `v` in the
        ordering. This is essential for determining the correct calculation order.

        Returns:
            A list of node names (strings) in a valid topological order.

        Raises:
            ValueError: If a cycle is detected in the graph, as topological sort
                        is only possible on Directed Acyclic Graphs (DAGs).
        """
        in_degree: dict[str, int] = {n: 0 for n in self.nodes}
        adjacency: dict[str, list[str]] = {n: [] for n in self.nodes}
        for name, node in self.nodes.items():
            if hasattr(node, "inputs"):
                for inp in node.inputs:
                    adjacency[inp.name].append(name)
                    in_degree[name] += 1
        queue: list[str] = [n for n, d in in_degree.items() if d == 0]
        topo_order: list[str] = []
        while queue:
            current = queue.pop()
            topo_order.append(current)
            for nbr in adjacency[current]:
                in_degree[nbr] -= 1
                if in_degree[nbr] == 0:
                    queue.append(nbr)
        if len(topo_order) != len(self.nodes):
            raise ValueError("Cycle detected in graph, can't do a valid topological sort.")
        return topo_order

    def get_calculation_nodes(self) -> list[str]:
        """Identifies all nodes in the graph that represent calculations.

        Filters the graph's nodes based on the `has_calculation()` method
        of each node.

        Returns:
            A list of strings, where each string is the name (ID) of a node
            that performs a calculation.
        """
        return [node_id for node_id, node in self.nodes.items() if node.has_calculation()]

    def get_dependencies(self, node_id: str) -> list[str]:
        """Retrieves the direct dependencies (inputs) of a specific node.

        Args:
            node_id: The unique string identifier (name) of the node whose
                     dependencies are requested.

        Returns:
            A list of strings, where each string is the name (ID) of a node
            that the specified `node_id` directly depends on. Returns an empty
            list if the node has no dependencies or doesn't support inputs.

        Raises:
            NodeError: If no node with the specified `node_id` exists in the graph.
        """
        node = self.get_node(node_id)
        if not node:
            raise NodeError(message=f"Node '{node_id}' does not exist", node_id=node_id)
        if hasattr(node, "inputs"):
            return [inp.name for inp in node.inputs]
        return []

    def get_dependency_graph(self) -> dict[str, list[str]]:
        """Constructs a representation of the full dependency graph.

        Iterates through all nodes and maps each node's ID to a list of its
        direct dependencies (input node IDs).

        Returns:
            A dictionary where keys are node IDs (str) and values are lists
            of node IDs (str) representing the direct dependencies of the key node.
        """
        dependencies: dict[str, list[str]] = {}
        for node_id, node in self.nodes.items():
            try:
                if hasattr(node, "inputs"):
                    dependencies[node_id] = [inp.name for inp in node.inputs]
                else:
                    dependencies[node_id] = []
            except NodeError:
                dependencies[node_id] = []
        return dependencies

    def detect_cycles(self) -> list[list[str]]:
        """Detects all cycles present in the graph's dependency structure.

        Uses a depth-first search (DFS) based algorithm to traverse the graph
        and identify back-edges, which indicate cycles.

        Returns:
            A list of lists, where each inner list contains the sequence of
            node names (IDs) forming a detected cycle. If no cycles are found,
            returns an empty list.
        """
        dependency_graph = self.get_dependency_graph()
        visited: set[str] = set()
        rec_stack: set[str] = set()
        cycles: list[list[str]] = []

        def dfs_detect_cycles(node_id: str, path: Optional[list[str]] = None) -> None:
            """Helper function for cycle detection using DFS.

            Keeps track of visited nodes and the recursion stack to identify
            back edges.

            Args:
                node_id: The ID of the current node being visited.
                path: The list of nodes visited in the current DFS path.
            """
            if path is None:
                path = []
            if node_id in rec_stack:
                cycle_start = path.index(node_id)
                cycle = path[cycle_start:] + [node_id]
                if cycle not in cycles:
                    cycles.append(cycle)
                return
            if node_id in visited:
                return
            visited.add(node_id)
            rec_stack.add(node_id)
            path.append(node_id)
            for dep_id in dependency_graph.get(node_id, []):
                dfs_detect_cycles(dep_id, path[:])
            rec_stack.remove(node_id)

        for node_id in self.nodes:
            if node_id not in visited:
                dfs_detect_cycles(node_id)
        return cycles

    def validate(self) -> list[str]:
        """Performs validation checks on the graph structure.

        Checks for two main types of issues:
        1. Circular dependencies (cycles) using `detect_cycles`.
        2. Missing dependencies (nodes that depend on non-existent nodes).

        Returns:
            A list of strings, where each string describes a validation error
            found. If the graph is valid, returns an empty list.
        """
        errors: list[str] = [
            f"Circular dependency detected: {' -> '.join(cycle)}" for cycle in self.detect_cycles()
        ]

        errors.extend(
            f"Node '{node_id}' depends on non-existent node '{inp.name}'"
            for node_id, node in self.nodes.items()
            if hasattr(node, "inputs")
            for inp in node.inputs
            if not self.has_node(inp.name)
        )

        return errors

    def breadth_first_search(self, start_node: str, direction: str = "successors") -> list[str]:
        """Performs a breadth-first search (BFS) traversal of the graph.

        Args:
            start_node: The ID of the node to start the traversal from.
            direction: The direction of traversal. Can be "successors" or "predecessors".

        Returns:
            A list of node IDs (strings) visited during the traversal.
        """
        if direction not in ["successors", "predecessors"]:
            raise ValueError("Invalid direction. Use 'successors' or 'predecessors'.")

        visited = set()
        queue = deque([start_node])
        visited.add(start_node)
        traversal_order = []

        while queue:
            level_size = len(queue)
            current_level = []
            new_level_nodes = set()

            for _ in range(level_size):
                node_id = queue.popleft()
                current_level.append(node_id)

                # Find neighbors based on direction
                neighbors = (
                    self.get_direct_successors(node_id)
                    if direction == "successors"
                    else self.get_direct_predecessors(node_id)
                )
                # Use extend and list comprehension for PERF401
                new_level_nodes.update(n for n in neighbors if n not in visited)

            # Add new unique neighbors to the queue and visited set
            for neighbor in new_level_nodes:
                if neighbor not in visited:
                    visited.add(neighbor)
                    queue.append(neighbor)

            if current_level:
                traversal_order.extend(current_level)

        return traversal_order

# --- END FILE: fin_statement_model/core/graph/traversal.py ---

# --- START FILE: fin_statement_model/core/graph/graph.py ---
"""Graph module for core graph operations.

This module provides the `Graph` class that combines manipulation, traversal,
forecasting, and calculation capabilities for building and evaluating financial
statement models.
"""

from __future__ import annotations
import logging
from typing import Any

from .manipulation import GraphManipulationMixin
from .traversal import GraphTraversalMixin
from .forecast_mixin import ForecastOperationsMixin
from fin_statement_model.core.data_manager import DataManager
from fin_statement_model.core.calculation_engine import CalculationEngine
from fin_statement_model.core.nodes import Node

# Configure logging
logger = logging.getLogger(__name__)


class Graph(
    GraphManipulationMixin,
    GraphTraversalMixin,
    ForecastOperationsMixin,
):
    """Represents the financial statement model as a directed graph.

    This class integrates graph manipulation (adding/removing nodes and edges)
    and traversal capabilities. It serves as the central orchestrator, owning
    the shared registry of nodes and managing core components like the
    `DataManager` and `CalculationEngine`.

    Nodes in the graph represent financial items or calculations, and edges
    represent dependencies between them. The `DataManager` handles the storage
    and retrieval of time-series data associated with nodes, while the
    `CalculationEngine` manages the execution of calculations defined by
    calculation nodes.

    Attributes:
        _nodes: A dictionary storing all nodes in the graph, keyed by node name.
                This serves as the single source of truth shared with managers.
        _data_manager: An instance of `DataManager` responsible for handling
                       time-series data (items and periods).
        _calculation_engine: An instance of `CalculationEngine` responsible for
                             managing and executing calculations.
    """

    def __init__(self, periods: list[str] | None = None):
        """Initializes the Graph instance.

        Sets up the core components: the node registry, `DataManager`, and
        `CalculationEngine`. Optionally initializes the graph with a list of
        time periods.

        Args:
            periods: An optional list of strings representing the initial time
                     periods for the financial model (e.g., ["2023", "2024"]).
                     The `DataManager` will handle sorting and ensuring uniqueness.

        Raises:
            TypeError: If `periods` is provided but is not a list.

        Example:
            >>> graph_no_periods = Graph()
            >>> print(graph_no_periods.periods)
            []
            >>> graph_with_periods = Graph(periods=["2023", "2022"])
            >>> print(graph_with_periods.periods) # Periods are sorted
            ['2022', '2023']
            >>> try:
            ...     Graph(periods="2023") # Invalid type
            ... except TypeError as e:
            ...     print(e)
            Initial periods must be a list
        """
        # No super().__init__() needed as mixins don't have __init__
        # and GraphCore is removed.

        # Create the single source of truth for nodes
        self._nodes: dict[str, Node] = {}

        # Instantiate managers, passing the shared node registry
        # These managers handle their own initialization logic.
        self._data_manager = DataManager(nodes_registry=self._nodes)
        self._calculation_engine = CalculationEngine(nodes_registry=self._nodes)

        # Handle initial periods by adding them via the DataManager
        if periods:
            # Basic validation before passing to manager
            if not isinstance(periods, list):
                raise TypeError("Initial periods must be a list")
            # DataManager.add_periods handles sorting and uniqueness
            self._data_manager.add_periods(periods)

    @property
    def nodes(self) -> dict[str, Node]:
        """Provides access to the dictionary of all nodes in the graph.

        Returns:
            A dictionary where keys are node names (str) and values are
            `Node` objects. This dictionary represents the shared node registry.

        Example:
            >>> graph = Graph()
            >>> item_node = graph.add_financial_statement_item("Revenue", {"2023": 100})
            >>> print(list(graph.nodes.keys()))
            ['Revenue']
            >>> print(graph.nodes["Revenue"] == item_node)
            True
        """
        return self._nodes

    @property
    def periods(self) -> list[str]:
        """Retrieves the list of time periods currently managed by the graph.

        Delegates to the `DataManager` to get the sorted list of unique periods.

        Returns:
            A list of strings representing the time periods in the model.

        Example:
            >>> graph = Graph(periods=["2024", "2023"])
            >>> print(graph.periods)
            ['2023', '2024']
            >>> graph.add_periods(["2025"])
            >>> print(graph.periods)
            ['2023', '2024', '2025']
        """
        return self._data_manager.periods

    def add_periods(self, periods: list[str]) -> None:
        """Adds new time periods to the graph's `DataManager`.

        The `DataManager` ensures that periods are sorted and unique.

        Args:
            periods: A list of strings representing the time periods to add.

        Raises:
            TypeError: If `periods` is not a list.
            ValueError: If any period format is invalid (handled by DataManager).

        Example:
            >>> graph = Graph(periods=["2022"])
            >>> graph.add_periods(["2023", "2022", "2024"])
            >>> print(graph.periods)
            ['2022', '2023', '2024']
            >>> try:
            ...     graph.add_periods("2025") # Must be a list
            ... except TypeError as e:
            ...     print(e)
            Periods must be provided as a list.
        """
        self._data_manager.add_periods(periods)

    def add_calculation(
        self,
        name: str,
        input_names: list[str],
        operation_type: str,
        **kwargs: dict[str, Any],
    ) -> Node:
        """Adds a new calculation node to the graph via the `CalculationEngine`.

        The `CalculationEngine` creates the appropriate `CalculationNode` subclass
        based on `operation_type`, resolves input nodes using the shared registry,
        adds the new node to the registry, and establishes dependencies.

        Args:
            name: The unique name for the new calculation node.
            input_names: A list of names of the nodes that serve as inputs to
                         this calculation.
            operation_type: A string identifying the type of calculation
                            (e.g., "addition", "percentage_growth"). This maps
                            to a specific calculation strategy.
            **kwargs: Additional keyword arguments required by the specific
                      calculation strategy identified by `operation_type`.

        Returns:
            The newly created `Node` object representing the calculation.

        Raises:
            NodeNotFoundError: If any node specified in `input_names` does not
                              exist in the graph's node registry.
            ValueError: If the `name` is invalid, already exists, or if the
                        `operation_type` is not recognized or fails validation.
            TypeError: If the provided `kwargs` do not match the signature
                       required by the chosen calculation strategy.
            CalculationError: For issues during calculation node setup within
                              the engine.

        Example (assuming 'addition' strategy is registered):
            >>> graph = Graph(periods=["2023"])
            >>> rev_node = graph.add_financial_statement_item("Revenue", {"2023": 100})
            >>> cost_node = graph.add_financial_statement_item("Costs", {"2023": 60})
            >>> # Note: The default CalculationEngine uses FormulaCalculationNode for simple ops
            >>> # This example assumes a more sophisticated engine or pre-registration
            >>> # gross_profit = graph.add_calculation(
            >>> #    "GrossProfit", ["Revenue", "Costs"], "subtraction"
            >>> # )
            >>> # Let's assume a simple formula node is created instead for demonstration
            >>> from fin_statement_model.core.nodes import FormulaCalculationNode
            >>> gp_node = FormulaCalculationNode("GrossProfit", {"r": rev_node, "c": cost_node}, "r - c")
            >>> graph.add_node(gp_node) # Add directly for this example
            >>> print("GrossProfit" in graph.nodes)
            True
            >>> print(graph.calculate("GrossProfit", "2023")) # Calculation depends on engine
            40.0
        """
        node = self._calculation_engine.add_calculation(name, input_names, operation_type, **kwargs)
        return node

    def calculate(self, node_name: str, period: str) -> float:
        """Calculates the value of a specific node for a given period.

        Delegates the calculation request to the `CalculationEngine`, which
        handles dependency resolution, execution, and caching.

        Args:
            node_name: The name of the node whose value is to be calculated.
            period: The specific time period for which to calculate the value.

        Returns:
            The calculated float value of the node for the specified period.

        Raises:
            NodeNotFoundError: If the node `node_name` does not exist.
            PeriodNotFoundError: If the `period` does not exist in the `DataManager`.
            CalculationError: If the calculation fails due to missing inputs,
                              cyclic dependencies, or errors within the node's
                              calculation logic.

        Example:
            >>> graph = Graph(periods=["2023"])
            >>> rev_node = graph.add_financial_statement_item("Revenue", {"2023": 100})
            >>> print(graph.calculate("Revenue", "2023"))
            100.0
            >>> cost_node = graph.add_financial_statement_item("Costs", {"2023": 60})
            >>> from fin_statement_model.core.nodes import FormulaCalculationNode
            >>> gp_node = FormulaCalculationNode("GrossProfit", {"r": rev_node, "c": cost_node}, "r - c")
            >>> graph.add_node(gp_node)
            >>> print(graph.calculate("GrossProfit", "2023"))
            40.0
            >>> try:
            ...     graph.calculate("NonExistent", "2023")
            ... except Exception as e: # Actual exception type depends on engine
            ...     print(f"Error: {e}") # Example: Node 'NonExistent' not found
            Error: Node 'NonExistent' not found in registry.
            >>> try:
            ...     graph.calculate("Revenue", "2024")
            ... except Exception as e:
            ...     print(f"Error: {e}") # Example: Period '2024' not found
            Error: Period '2024' not found.
        """
        return self._calculation_engine.calculate(node_name, period)

    def recalculate_all(self, periods: list[str] | None = None) -> None:
        """Triggers a recalculation of all calculation nodes for specified periods.

        Clears existing calculation caches and then instructs the
        `CalculationEngine` to re-evaluate all calculation nodes for the given
        periods (or all managed periods if none are specified). This is useful
        after data updates or changes to the graph structure.

        Args:
            periods: An optional list of periods to recalculate. If None,
                     recalculates for all periods managed by the `DataManager`.
                     Can also be a single period string.

        Example:
            >>> graph = Graph(periods=["2023"])
            >>> rev = graph.add_financial_statement_item("Revenue", {"2023": 100})
            >>> costs = graph.add_financial_statement_item("Costs", {"2023": 50})
            >>> from fin_statement_model.core.nodes import FormulaCalculationNode
            >>> gp = FormulaCalculationNode("GP", {"r": rev, "c": costs}, "r - c")
            >>> graph.add_node(gp)
            >>> # First calculation might populate cache
            >>> val1 = graph.calculate("GP", "2023")
            >>> print(val1)
            50.0
            >>> # Simulate data change
            >>> graph.set_value("Costs", "2023", 60)
            >>> # Value might be stale if cached
            >>> # Recalculate to ensure freshness
            >>> graph.recalculate_all("2023")
            >>> val2 = graph.calculate("GP", "2023")
            >>> print(val2)
            40.0
            >>> # Recalculate all periods (only 2023 here)
            >>> graph.set_value("Revenue", "2023", 110)
            >>> graph.recalculate_all()
            >>> print(graph.calculate("GP", "2023"))
            50.0
        """
        periods_to_use = periods
        if periods_to_use is None:
            periods_to_use = self.periods
        elif isinstance(periods_to_use, str):
            periods_to_use = [periods_to_use]
        elif not isinstance(periods_to_use, list):
            raise TypeError("Periods must be a list of strings, a single string, or None.")

        self.clear_all_caches()
        self._calculation_engine.recalculate_all(periods_to_use)

    def clear_all_caches(self) -> None:
        """Clears all calculation-related caches within the graph.

        This includes clearing caches possibly held by individual nodes
        (like `StrategyCalculationNode`) and the central cache within the
        `CalculationEngine`. This ensures subsequent calculations start fresh.
        Logs warnings if clearing fails for specific nodes or the engine.

        Example:
            >>> graph = Graph(periods=["2023"])
            >>> # ... add nodes and perform calculations ...
            >>> # Assume some caches might be populated in nodes or engine
            >>> graph.clear_all_caches()
            >>> # Subsequent calls to graph.calculate will recompute from scratch
        """
        logger.debug(f"Clearing caches for {len(self.nodes)} nodes.")
        for node in self.nodes.values():
            if hasattr(node, "clear_cache"):
                try:
                    node.clear_cache()
                except Exception as e:
                    logger.warning(f"Failed to clear cache for node '{node.name}': {e}")

        logger.debug("Clearing calculation engine cache.")
        if hasattr(self._calculation_engine, "clear_cache"):
            try:
                self._calculation_engine.clear_cache()
            except Exception as e:
                logger.warning(f"Could not clear calculation engine cache: {e}", exc_info=True)

    def add_financial_statement_item(self, name: str, values: dict[str, float]) -> Node:
        """Adds a basic financial statement item (data node) to the graph.

        Delegates the creation and storage of the `FinancialStatementItemNode`
        and its associated time-series data to the `DataManager`.

        Args:
            name: The unique name for the financial statement item node.
            values: A dictionary where keys are period strings and values are
                    the corresponding float values for this item.

        Returns:
            The newly created `FinancialStatementItemNode` object.

        Raises:
            NodeError: If a node with the same name already exists.
            PeriodNotFoundError: If any period key in `values` is not recognized
                                by the `DataManager`.
            TypeError: If `values` is not a dictionary or contains invalid types.

        Example:
            >>> graph = Graph(periods=["2023", "2024"])
            >>> item_node = graph.add_financial_statement_item("SG&A", {"2023": 50.0})
            >>> print(item_node.name)
            SG&A
            >>> print(item_node.get_value("2023"))
            50.0
            >>> print("SG&A" in graph.nodes)
            True
            >>> # Add data for another period later
            >>> graph.set_value("SG&A", "2024", 55.0)
            >>> print(item_node.get_value("2024"))
            55.0
            >>> try:
            ...     graph.add_financial_statement_item("Existing", {"2023": 10})
            ...     graph.add_financial_statement_item("Existing", {"2023": 20})
            ... except Exception as e: # Actual exception type depends on DataManager
            ...     print(f"Error: {e}") # Example: Node 'Existing' already exists
            Error: Node 'Existing' already exists.
        """
        node = self._data_manager.add_item(name, values)
        return node

    def get_financial_statement_items(self) -> list[Node]:
        """Retrieves all nodes that represent basic financial statement items.

        Filters the main node registry to return only instances of
        `FinancialStatementItemNode`.

        Returns:
            A list containing all `FinancialStatementItemNode` objects
            currently in the graph.

        Example:
            >>> graph = Graph(periods=["2023"])
            >>> item1 = graph.add_financial_statement_item("Item1", {"2023": 1})
            >>> item2 = graph.add_financial_statement_item("Item2", {"2023": 2})
            >>> # Add a non-item node (example)
            >>> from fin_statement_model.core.nodes import Node
            >>> graph.add_node(Node("CalcNode"))
            >>> fs_items = graph.get_financial_statement_items()
            >>> print(len(fs_items))
            2
            >>> print(sorted([item.name for item in fs_items]))
            ['Item1', 'Item2']
        """
        from fin_statement_model.core.nodes import (
            FinancialStatementItemNode,
        )  # Keep import local as it's specific

        return [
            node
            for node in self.nodes.values()
            if isinstance(node, FinancialStatementItemNode)
        ]

    def __repr__(self) -> str:
        """Provides a concise, developer-friendly string representation of the graph.

        Summarizes key statistics like the total number of nodes, counts of
        different node types (Financial Statement Items, Calculations), the
        number of dependencies (edges), and the list of managed periods.

        Returns:
            A string summarizing the graph's structure and contents.

        Example:
            >>> graph = Graph(periods=["2023"])
            >>> graph.add_financial_statement_item("Revenue", {"2023": 100})
            >>> graph.add_financial_statement_item("COGS", {"2023": 60})
            >>> # Assume a calculation node 'GP' depends on Revenue, COGS
            >>> from fin_statement_model.core.nodes import FormulaCalculationNode
            >>> gp_node = FormulaCalculationNode("GP", {"r": graph.nodes['Revenue'], "c": graph.nodes['COGS']}, "r - c")
            >>> graph.add_node(gp_node)
            >>> print(repr(graph))
            <Graph(Total Nodes: 3, FS Items: 2, Calculations: 1, Dependencies: 2, Periods: ['2023'])>
            >>> graph_empty = Graph()
            >>> print(repr(graph_empty))
            <Graph(Total Nodes: 0, FS Items: 0, Calculations: 0, Dependencies: 0, Periods: [None])>
        """
        from fin_statement_model.core.nodes import (
            FinancialStatementItemNode,
        )  # Keep import local

        num_nodes = len(self.nodes)
        periods_str = ", ".join(map(repr, self.periods)) if self.periods else "None"

        fs_item_count = 0
        calc_node_count = 0
        other_node_count = 0
        dependencies_count = 0

        for node in self.nodes.values():
            if isinstance(node, FinancialStatementItemNode):
                fs_item_count += 1
            elif node.has_calculation():
                calc_node_count += 1
                # Prioritize get_dependencies if available, otherwise check inputs
                if hasattr(node, "get_dependencies"):
                    try:
                        dependencies_count += len(node.get_dependencies())
                    except Exception as e:
                        logger.warning(
                            f"Error calling get_dependencies for node '{node.name}': {e}"
                        )
                elif hasattr(node, "inputs"):
                    try:
                        if isinstance(node.inputs, list):
                            # Ensure inputs are nodes with names
                            dep_names = [inp.name for inp in node.inputs if hasattr(inp, "name")]
                            dependencies_count += len(dep_names)
                        elif isinstance(node.inputs, dict):
                            # Assume keys are dependency names for dict inputs
                            dependencies_count += len(node.inputs)
                    except Exception as e:
                        logger.warning(f"Error processing inputs for node '{node.name}': {e}")
            else:
                other_node_count += 1

        repr_parts = [
            f"Total Nodes: {num_nodes}",
            f"FS Items: {fs_item_count}",
            f"Calculations: {calc_node_count}",
        ]
        if other_node_count > 0:
            repr_parts.append(f"Other: {other_node_count}")
        repr_parts.append(f"Dependencies: {dependencies_count}")
        repr_parts.append(f"Periods: [{periods_str}]")

        return f"<{type(self).__name__}({', '.join(repr_parts)})>"

    def has_cycle(self, source_node: Node, target_node: Node) -> bool:
        """Checks if there is a cycle in the graph starting from a given source node to a target node.

        This method uses Depth-First Search (DFS) to detect cycles in the graph.

        Args:
            source_node: The starting node of the cycle detection.
            target_node: The target node to which the cycle detection is performed.

        Returns:
            True if there is a cycle in the graph from the source node to the target node, False otherwise.

        Raises:
            NodeNotFoundError: If the source_node or target_node does not exist in the graph.
        """
        if source_node not in self._nodes or target_node not in self._nodes:
            return False  # Or raise error?

        # Simple DFS to detect cycles
        path = {source_node}
        stack = [source_node]
        while stack:
            curr = stack[-1]
            if curr not in path:
                path.add(curr)

            # Add neighbors to stack
            pushed = False
            neighbors = self.get_direct_predecessors(curr)
            # Use list comprehension for PERF401
            unvisited_neighbors = [n for n in neighbors if n not in path]

            for neighbor in unvisited_neighbors:
                if neighbor == target_node:
                    return True
                stack.append(neighbor)
                pushed = True
                break

            if not pushed:
                stack.pop()

        return False

# --- END FILE: fin_statement_model/core/graph/graph.py ---

# --- START FILE: fin_statement_model/core/graph/forecast_mixin.py ---
"""Mixin providing forecasting methods for FinancialStatementGraph.

- create_forecast
- _forecast_node.
"""

from __future__ import annotations

import logging
import numpy as np
from typing import Any, Optional, Union, Callable

# Make sure FinancialStatementItemNode is importable if needed for type checking
from fin_statement_model.core.nodes import Node

# from ..nodes import FinancialStatementItemNode # If specific type check needed
from fin_statement_model.core.node_factory import NodeFactory

logger = logging.getLogger(__name__)


class ForecastOperationsMixin:
    """Graph mixin providing forecasting operations."""

    def create_forecast(
        self,
        forecast_periods: list[str],
        node_configs: Optional[dict[str, dict[str, Any]]] = None,
        historical_periods: Optional[list[str]] = None,
        **kwargs: Any,
    ) -> None:
        """Create forecasts for financial statement items on the graph.

        Args:
            forecast_periods: List of future periods to forecast
            node_configs: Dictionary mapping node names to their forecast configurations.
                         Each configuration should be a dictionary with:
                         - 'method': The forecasting method ('simple', 'curve', 'statistical', 'average', 'historical_growth')
                         - 'config': The configuration specific to the method:
                           - For 'simple': float growth rate
                           - For 'curve': list of growth rates for each period
                           - For 'statistical': dict with 'distribution' and 'params'
                           - For 'average' or 'historical_growth': None
            historical_periods: Optional list of historical periods to use as base
            **kwargs: Additional arguments passed to _forecast_node

        Example:
            fsg.create_forecast(
                forecast_periods=["FY2023", "FY2024", "FY2025"],
                node_configs={
                    "revenue_americas": {
                        "method": "curve",
                        "config": [0.05, 0.06, 0.07]
                    },
                    "revenue_europe": {
                        "method": "statistical",
                        "config": {
                            "distribution": "normal",
                            "params": {"mean": 0.05, "std": 0.02}
                        }
                    },
                    "revenue_apac": {
                        "method": "historical_growth",
                        "config": None
                    }
                }
            )
        """
        try:
            if historical_periods is None:
                # Try to get historical periods from the instance first
                if hasattr(self, "get_historical_periods") and callable(
                    getattr(self, "get_historical_periods")
                ):
                    historical_periods = self.get_historical_periods()
                    logger.debug(
                        f"Using historical periods from get_historical_periods: {historical_periods}"
                    )
                else:
                    # Infer historical periods if the method doesn't exist
                    if not self.periods or not forecast_periods:
                        raise ValueError(
                            "Cannot infer historical periods: graph periods or forecast periods are missing."
                        )
                    first_forecast_period = forecast_periods[0]
                    try:
                        first_forecast_index = self.periods.index(first_forecast_period)
                        historical_periods = self.periods[:first_forecast_index]
                        logger.debug(f"Inferred historical periods: {historical_periods}")
                    except ValueError:
                        # If the first forecast period isn't in the main list, assume all are historical
                        historical_periods = list(self.periods)
                        logger.warning(
                            f"First forecast period {first_forecast_period} not found in graph periods {self.periods}. Assuming all are historical."
                        )

            else:
                logger.debug(f"Using explicitly provided historical periods: {historical_periods}")

            if not historical_periods:
                raise ValueError("No historical periods found for forecasting")

            if not forecast_periods:
                raise ValueError("No forecast periods provided")

            for period in forecast_periods:
                if period not in self.periods:
                    self.add_periods([period])
                    logger.debug(f"Added forecast period to graph: {period}")

            if node_configs is None:
                node_configs = {}

            for node_name, config in node_configs.items():
                node = self.get_node(node_name)
                if node is None:
                    raise ValueError(f"Node {node_name} not found in graph")

                # Ensure we are trying to forecast a node that can store values
                # Typically FinancialStatementItemNode
                if not hasattr(node, "values") or not isinstance(node.values, dict):
                    logger.warning(
                        f"Skipping forecast for node {node_name}: Not a compatible value-storing node (e.g., FinancialStatementItemNode). Type is {type(node).__name__}"
                    )
                    continue

                method = config.get("method", "simple")
                growth_config = config.get("config")

                if method == "simple":
                    if isinstance(growth_config, list):
                        growth_config = growth_config[0]
                elif method == "curve":
                    if not isinstance(growth_config, list):
                        growth_config = [growth_config] * len(forecast_periods)
                elif method == "statistical":
                    if not isinstance(growth_config, dict) or "distribution" not in growth_config:
                        raise ValueError(
                            f"Statistical method requires distribution parameters for {node_name}"
                        )
                elif method in {"average", "historical_growth"}:
                    growth_config = 0.0  # Placeholder, calculated in _forecast_node
                else:
                    raise ValueError(f"Invalid forecasting method: {method}")

                self._forecast_node(
                    node, historical_periods, forecast_periods, growth_config, method
                )

            # Recalculate the graph after forecasting
            # This now relies on the original nodes having updated values
            self.recalculate_all()

            logger.info(
                f"Created forecast for {len(forecast_periods)} periods using {len(node_configs)} nodes"
            )

        except Exception as e:
            logger.error(
                f"Error creating forecast: {e}", exc_info=True
            )  # Add exc_info for better debugging
            raise

    def _forecast_node(
        self,
        node: Node,  # Hint with base Node, but expect FinancialStatementItemNode usually
        historical_periods: list[str],
        forecast_periods: list[str],
        growth_config: Union[float, list[float], Callable[[], float]],
        method: str,
        **kwargs: dict[str, Any],
    ) -> None:
        """Calculate forecast values and update the original node."""
        if not historical_periods:
            raise ValueError(f"No historical periods available for forecasting node {node.name}")

        # Determine base historical period
        base_period = historical_periods[-1]

        # Ensure the node has a 'values' dict and the base period exists
        if not hasattr(node, "values") or not isinstance(node.values, dict):
            logger.error(f"Cannot forecast node {node.name}: Does not have a 'values' dictionary.")
            return  # Or raise error

        if base_period not in node.values:
            logger.warning(
                f"Base period {base_period} not found in node {node.name} values. Available periods: {sorted(node.values.keys())}"
            )
            # Attempt to find the latest available historical period
            available_historical = sorted(
                [p for p in node.values if p in historical_periods], reverse=True
            )
            if available_historical:
                base_period = available_historical[0]
                logger.info(f"Using {base_period} as base period instead for node {node.name}")
            else:
                raise ValueError(
                    f"No valid historical base period found in node {node.name}'s values."
                )

        # Prepare transformation to forecast
        method_to_type = {
            "simple": "fixed",
            "curve": "curve",
            "statistical": "statistical",
            "average": "average",
            "historical_growth": "historical_growth",
        }
        forecast_type = method_to_type.get(method)
        if forecast_type is None:
            raise ValueError(f"Invalid forecasting method: {method}")

        # Determine growth parameters
        growth_params = None
        if method == "simple":
            growth_params = float(growth_config)
        elif method == "curve":
            if not isinstance(growth_config, list) or len(growth_config) != len(forecast_periods):
                raise ValueError(
                    f"Growth rates list for {node.name} ({len(growth_config)}) must match number of forecast periods ({len(forecast_periods)})"
                )
            growth_params = [float(rate) for rate in growth_config]
        elif method == "statistical":
            distribution = growth_config["distribution"]
            params = growth_config["params"]

            def gen() -> float:  # Define generator within scope
                if distribution == "normal":
                    return np.random.normal(params["mean"], params["std"])
                elif distribution == "uniform":
                    return np.random.uniform(params["low"], params["high"])
                else:
                    raise ValueError(f"Unsupported distribution: {distribution}")

            growth_params = gen  # Assign the generator function
        elif method == "average":
            historical_values = [node.calculate(p) for p in historical_periods if p in node.values]
            valid = [v for v in historical_values if v is not None and not np.isnan(v)]
            if not valid:
                raise ValueError(f"No valid historical data to compute average for {node.name}")
            growth_params = sum(valid) / len(valid)
        elif method == "historical_growth":
            # Calculation for historical growth needs base_node and historical_periods
            # This might be better handled inside the specific ForecastNode implementation
            # For now, pass None or a placeholder if the factory/node handles it.
            growth_params = None  # Factory/Node should calculate this
        else:
            # This case should be caught by method_to_type check earlier
            raise ValueError(f"Unhandled forecasting method: {method}")

        # 1. Create a TEMPORARY forecast node instance to calculate values
        try:
            temp_forecast_node = NodeFactory.create_forecast_node(
                name=f"{node.name}_forecast_temp",  # Temporary name
                base_node=node,  # Pass the original node
                base_period=base_period,
                forecast_periods=forecast_periods,
                forecast_type=forecast_type,
                growth_params=growth_params,
            )
        except Exception as e:
            logger.error(
                f"Failed to create temporary forecast node for {node.name}: {e}",
                exc_info=True,
            )
            raise  # Re-raise the error from the factory

        # 2. Calculate the forecast values using the temporary node
        forecast_values: dict[str, float] = {}
        for period in forecast_periods:
            try:
                # Assuming ForecastNode subclasses implement calculate
                value = temp_forecast_node.calculate(period)
                # Handle potential NaN or Inf values from calculations
                if np.isnan(value) or np.isinf(value):
                    logger.warning(
                        f"Forecast for {node.name} period {period} resulted in {value}. Replacing with 0.0."
                    )
                    value = 0.0
                forecast_values[period] = value
            except Exception as e:
                logger.error(
                    f"Error calculating forecast for {node.name} period {period}: {e}",
                    exc_info=True,
                )
                forecast_values[period] = 0.0  # Default to 0 on error

        # 3. Update the ORIGINAL node's values dictionary
        # We already checked hasattr(node, 'values') and isinstance(node.values, dict) above
        original_node_values = node.values
        updated_count = 0
        for period, value in forecast_values.items():
            if period in forecast_periods:  # Ensure we only update forecast periods
                original_node_values[period] = value
                updated_count += 1

        logger.debug(f"Updated {updated_count} forecast values in original node {node.name}")

        # Clear the original node's cache AFTER updating its values
        if hasattr(node, "clear_cache"):
            node.clear_cache()

        # DO NOT REPLACE THE NODE ANYMORE
        # self.replace_node(node.name, forecast_node)
        # logger.debug(f"Forecast applied to node {node.name}")

    def forecast_value(
        self,
        node_name: str,
        forecast_periods: list[str],
        base_period: str | None = None,
        forecast_config: Optional[dict] = None,
        **kwargs: dict[str, Any],
    ) -> dict[str, float]:
        """Forecasts the value of a node for specified future periods.

        Args:
            node_name: The name of the node to forecast
            forecast_periods: List of future periods to forecast
            base_period: The base period to use for forecasting
            forecast_config: The configuration for forecasting
            **kwargs: Additional arguments passed to _forecast_node

        Returns:
            A dictionary mapping forecast periods to their forecast values
        """
        node = self.get_node(node_name)
        if node is None:
            raise ValueError(f"Node {node_name} not found in graph")

        # Ensure we are trying to forecast a node that can store values
        # Typically FinancialStatementItemNode
        if not hasattr(node, "values") or not isinstance(node.values, dict):
            logger.warning(
                f"Skipping forecast for node {node_name}: Not a compatible value-storing node (e.g., FinancialStatementItemNode). Type is {type(node).__name__}"
            )
            return {}

        if base_period is None:
            # Try to get historical periods from the instance first
            if hasattr(self, "get_historical_periods") and callable(
                getattr(self, "get_historical_periods")
            ):
                historical_periods = self.get_historical_periods()
                logger.debug(
                    f"Using historical periods from get_historical_periods: {historical_periods}"
                )
            else:
                # Infer historical periods if the method doesn't exist
                if not self.periods or not forecast_periods:
                    raise ValueError(
                        "Cannot infer historical periods: graph periods or forecast periods are missing."
                    )
                first_forecast_period = forecast_periods[0]
                try:
                    first_forecast_index = self.periods.index(first_forecast_period)
                    historical_periods = self.periods[:first_forecast_index]
                    logger.debug(f"Inferred historical periods: {historical_periods}")
                except ValueError:
                    # If the first forecast period isn't in the main list, assume all are historical
                    historical_periods = list(self.periods)
                    logger.warning(
                        f"First forecast period {first_forecast_period} not found in graph periods {self.periods}. Assuming all are historical."
                    )

        else:
            logger.debug(f"Using explicitly provided historical period: {base_period}")
            historical_periods = [base_period]

        if not historical_periods:
            raise ValueError("No historical periods found for forecasting")

        if not forecast_periods:
            raise ValueError("No forecast periods provided")

        for period in forecast_periods:
            if period not in self.periods:
                self.add_periods([period])
                logger.debug(f"Added forecast period to graph: {period}")

        if forecast_config is None:
            forecast_config = {}

        method = forecast_config.get("method", "simple")
        growth_config = forecast_config.get("config")

        if method == "simple":
            if isinstance(growth_config, list):
                growth_config = growth_config[0]
        elif method == "curve":
            if not isinstance(growth_config, list):
                growth_config = [growth_config] * len(forecast_periods)
        elif method == "statistical":
            if not isinstance(growth_config, dict) or "distribution" not in growth_config:
                raise ValueError(
                    f"Statistical method requires distribution parameters for {node_name}"
                )
        elif method in {"average", "historical_growth"}:
            growth_config = 0.0  # Placeholder, calculated in _forecast_node
        else:
            raise ValueError(f"Invalid forecasting method: {method}")

        forecast_values = self._forecast_node(
            node, historical_periods, forecast_periods, growth_config, method
        )

        # Recalculate the graph after forecasting
        # This now relies on the original nodes having updated values
        self.recalculate_all()

        logger.info(
            f"Created forecast for {len(forecast_periods)} periods using {len(forecast_config)} config"
        )

        return forecast_values

    def _forecast_node(
        self,
        node: Node,  # Hint with base Node, but expect FinancialStatementItemNode usually
        historical_periods: list[str],
        forecast_periods: list[str],
        growth_config: Union[float, list[float], Callable[[], float]],
        method: str,
        **kwargs: dict[str, Any],
    ) -> dict[str, float]:
        """Recursive helper to calculate forecast values, handling dependencies."""
        if not historical_periods:
            raise ValueError(f"No historical periods available for forecasting node {node.name}")

        # Determine base historical period
        base_period = historical_periods[-1]

        # Ensure the node has a 'values' dict and the base period exists
        if not hasattr(node, "values") or not isinstance(node.values, dict):
            logger.error(f"Cannot forecast node {node.name}: Does not have a 'values' dictionary.")
            return {}

        if base_period not in node.values:
            logger.warning(
                f"Base period {base_period} not found in node {node.name} values. Available periods: {sorted(node.values.keys())}"
            )
            # Attempt to find the latest available historical period
            available_historical = sorted(
                [p for p in node.values if p in historical_periods], reverse=True
            )
            if available_historical:
                base_period = available_historical[0]
                logger.info(f"Using {base_period} as base period instead for node {node.name}")
            else:
                raise ValueError(
                    f"No valid historical base period found in node {node.name}'s values."
                )

        # Prepare transformation to forecast
        method_to_type = {
            "simple": "fixed",
            "curve": "curve",
            "statistical": "statistical",
            "average": "average",
            "historical_growth": "historical_growth",
        }
        forecast_type = method_to_type.get(method)
        if forecast_type is None:
            raise ValueError(f"Invalid forecasting method: {method}")

        # Determine growth parameters
        growth_params = None
        if method == "simple":
            growth_params = float(growth_config)
        elif method == "curve":
            if not isinstance(growth_config, list) or len(growth_config) != len(forecast_periods):
                raise ValueError(
                    f"Growth rates list for {node.name} ({len(growth_config)}) must match number of forecast periods ({len(forecast_periods)})"
                )
            growth_params = [float(rate) for rate in growth_config]
        elif method == "statistical":
            distribution = growth_config["distribution"]
            params = growth_config["params"]

            def gen() -> float:  # Define generator within scope
                if distribution == "normal":
                    return np.random.normal(params["mean"], params["std"])
                elif distribution == "uniform":
                    return np.random.uniform(params["low"], params["high"])
                else:
                    raise ValueError(f"Unsupported distribution: {distribution}")

            growth_params = gen  # Assign the generator function
        elif method == "average":
            historical_values = [node.calculate(p) for p in historical_periods if p in node.values]
            valid = [v for v in historical_values if v is not None and not np.isnan(v)]
            if not valid:
                raise ValueError(f"No valid historical data to compute average for {node.name}")
            growth_params = sum(valid) / len(valid)
        elif method == "historical_growth":
            # Calculation for historical growth needs base_node and historical_periods
            # This might be better handled inside the specific ForecastNode implementation
            # For now, pass None or a placeholder if the factory/node handles it.
            growth_params = None  # Factory/Node should calculate this
        else:
            # This case should be caught by method_to_type check earlier
            raise ValueError(f"Unhandled forecasting method: {method}")

        # 1. Create a TEMPORARY forecast node instance to calculate values
        try:
            temp_forecast_node = NodeFactory.create_forecast_node(
                name=f"{node.name}_forecast_temp",  # Temporary name
                base_node=node,  # Pass the original node
                base_period=base_period,
                forecast_periods=forecast_periods,
                forecast_type=forecast_type,
                growth_params=growth_params,
            )
        except Exception as e:
            logger.error(
                f"Failed to create temporary forecast node for {node.name}: {e}",
                exc_info=True,
            )
            raise  # Re-raise the error from the factory

        # 2. Calculate the forecast values using the temporary node
        forecast_values: dict[str, float] = {}
        for period in forecast_periods:
            try:
                # Assuming ForecastNode subclasses implement calculate
                value = temp_forecast_node.calculate(period)
                # Handle potential NaN or Inf values from calculations
                if np.isnan(value) or np.isinf(value):
                    logger.warning(
                        f"Forecast for {node.name} period {period} resulted in {value}. Replacing with 0.0."
                    )
                    value = 0.0
                forecast_values[period] = value
            except Exception as e:
                logger.error(
                    f"Error calculating forecast for {node.name} period {period}: {e}",
                    exc_info=True,
                )
                forecast_values[period] = 0.0  # Default to 0 on error

        # 3. Update the ORIGINAL node's values dictionary
        # We already checked hasattr(node, 'values') and isinstance(node.values, dict) above
        original_node_values = node.values
        updated_count = 0
        for period, value in forecast_values.items():
            if period in forecast_periods:  # Ensure we only update forecast periods
                original_node_values[period] = value
                updated_count += 1

        logger.debug(f"Updated {updated_count} forecast values in original node {node.name}")

        # Clear the original node's cache AFTER updating its values
        if hasattr(node, "clear_cache"):
            node.clear_cache()

        # DO NOT REPLACE THE NODE ANYMORE
        # self.replace_node(node.name, forecast_node)
        # logger.debug(f"Forecast applied to node {node.name}")

        return forecast_values

# --- END FILE: fin_statement_model/core/graph/forecast_mixin.py ---

# --- START FILE: fin_statement_model/core/graph/__init__.py ---
"""Graph core components package.

This package contains the core `Graph` class along with mixins for
graph manipulation and traversal operations. It defines the fundamental
structure and operations for the financial model's dependency graph.
"""

from __future__ import annotations
from .graph import Graph
from .manipulation import GraphManipulationMixin
from .traversal import GraphTraversalMixin

__all__ = ["Graph", "GraphManipulationMixin", "GraphTraversalMixin"]

# --- END FILE: fin_statement_model/core/graph/__init__.py ---

# --- START FILE: fin_statement_model/core/__init__.py ---
"""Core components for the Financial Statement Model.

This package forms the foundation of the library, providing the core infrastructure
for building, calculating, and managing financial models. It includes:

- Graph engine (`core.graph`): For representing financial relationships.
- Base node hierarchy (`core.nodes`): Abstract and concrete node types.
- Calculation engine (`calculation_engine.py`): For evaluating the graph.
- Metric registry and definitions (`core.metrics`): For managing financial metrics.
- Data management (`data_manager.py`): For handling financial data.
- Calculation strategies (`core.strategies`): Reusable calculation logic.
- Core utilities and exceptions (`errors.py`, `node_factory.py`).

This `core` package is designed to be self-contained and does not depend on
other higher-level packages like `statements`, `io`, or `forecasting`.
"""

from .data_manager import DataManager
from .calculation_engine import CalculationEngine
from .node_factory import NodeFactory
from .graph import Graph
from .nodes import (
    Node,
    FinancialStatementItemNode,
    MetricCalculationNode,
    StrategyCalculationNode,
    YoYGrowthNode,
    MultiPeriodStatNode,
    FormulaCalculationNode,
    CustomCalculationNode,
    TwoPeriodAverageNode,
)
from .strategies import (
    AdditionStrategy,
    SubtractionStrategy,
    MultiplicationStrategy,
    DivisionStrategy,
)
from .errors import (
    FinancialModelError,
    ConfigurationError,
    CalculationError,
    NodeError,
    GraphError,
    DataValidationError,
    CircularDependencyError,
    PeriodError,
    StatementError,
    StrategyError,
    ImportError,
    ExportError,
    TransformationError,
)

__all__ = [
    "AdditionStrategy",
    "CalculationEngine",
    "CalculationError",
    "CircularDependencyError",
    "ConfigurationError",
    "CustomCalculationNode",
    "DataManager",
    "DataValidationError",
    "DivisionStrategy",
    "ExportError",
    "FinancialModelError",
    "FinancialStatementItemNode",
    "FinancialStatementItemNode",
    "FormulaCalculationNode",
    "Graph",
    "GraphError",
    "ImportError",
    "MetricCalculationNode",
    "MultiPeriodStatNode",
    "MultiplicationStrategy",
    "Node",
    "NodeError",
    "NodeFactory",
    "PeriodError",
    "StatementError",
    "StrategyCalculationNode",
    "StrategyError",
    "SubtractionStrategy",
    "TransformationError",
    "TwoPeriodAverageNode",
    "YoYGrowthNode",
]

# --- END FILE: fin_statement_model/core/__init__.py ---

# --- START FILE: fin_statement_model/core/calculation_engine.py ---
"""Calculation engine for financial statement calculations.

This module provides the CalculationEngine class which is responsible for managing
calculation nodes and performing calculations on the financial data graph.
"""

from typing import Optional, Any, Callable
import logging

from .node_factory import NodeFactory
from .nodes import (
    Node,
    StrategyCalculationNode,
    MetricCalculationNode,
)

# Remove direct import of METRIC_DEFINITIONS
# from .metrics import METRIC_DEFINITIONS
# Import the registry instance instead
from .metrics import metric_registry
from .errors import (
    ConfigurationError,
    NodeError,
    CalculationError,
)

# Configure logging
logger = logging.getLogger(__name__)


class CalculationEngine:
    """Manages calculation nodes and performs calculations using a shared node registry.

    Handles adding calculation and metric nodes, performing calculations,
    managing calculation strategies, and caching results. This engine operates
    on a node registry that is shared with other components, like a Graph object,
    allowing for integrated graph management and calculation.

    Attributes:
        _node_factory: An instance of NodeFactory used to create nodes.
        _nodes: A dictionary representing the shared registry of nodes.
        _cache: A dictionary used for caching calculation results.
        _metric_names: A set storing the names of nodes added as metrics.
    """

    def __init__(self, nodes_registry: dict[str, Node]):
        """Initialize the CalculationEngine with a shared node registry.

        Args:
            nodes_registry: The dictionary instance shared across graph components
                            to store all nodes (e.g., from a Graph object).

        Example:
            >>> shared_nodes = {}
            >>> engine = CalculationEngine(shared_nodes)
            >>> # The engine now operates on the 'shared_nodes' dictionary.
        """
        self._node_factory = NodeFactory()  # Keep its own factory
        self._nodes = nodes_registry  # Use the shared registry
        self._cache: dict[str, dict[str, float]] = {}  # Keep internal cache for calc results
        # Metrics are just nodes, store their names if needed for specific logic,
        # but the node itself lives in the shared self._nodes registry.
        self._metric_names: set[str] = set()

    def add_calculation(
        self,
        name: str,
        input_names: list[str],
        operation_type: str,
        **kwargs: dict[str, Any],
    ) -> Node:
        """Add a strategy-based calculation node to the shared registry.

        Resolves input node names from the shared registry, creates the node
        using the internal NodeFactory, and adds it to the shared registry.

        Args:
            name: Name of the calculation node to create.
            input_names: List of names of input nodes required for the calculation.
                         These nodes must already exist in the shared registry.
            operation_type: Key identifying the calculation strategy (e.g., 'addition')
                            registered with the NodeFactory.
            **kwargs: Additional arguments passed to the calculation strategy
                      constructor via the NodeFactory.

        Returns:
            The created StrategyCalculationNode, now stored in the shared registry.

        Raises:
            NodeError: If any input node name is not found in the shared registry.
            ValueError: If the node name or operation_type is invalid, or if the
                        strategy creation fails within the factory.
            TypeError: If strategy constructor arguments are incorrect.

        Example:
            >>> shared_nodes = {'revenue': RevenueNode('revenue'), 'cogs': CogsNode('cogs')}
            >>> engine = CalculationEngine(shared_nodes)
            >>> try:
            ...     gross_profit_node = engine.add_calculation(
            ...         name='gross_profit',
            ...         input_names=['revenue', 'cogs'],
            ...         operation_type='subtraction'
            ...     )
            ...     print(f"Node '{gross_profit_node.name}' added.")
            ... except NodeError as e:
            ...     print(e)
            Node 'gross_profit' added.
        """
        # 1. Resolve input node names from the shared self._nodes registry
        resolved_inputs: list[Node] = []
        missing_nodes = []
        for node_name in input_names:
            node = self._nodes.get(node_name)
            if node is None:
                missing_nodes.append(node_name)
            else:
                resolved_inputs.append(node)

        if missing_nodes:
            raise NodeError(
                f"Cannot create calculation node '{name}': Missing required input nodes in shared registry: {missing_nodes}"
            )

        # 2. Create the calculation node using the factory with resolved nodes
        try:
            node = self._node_factory.create_calculation_node(
                name=name,
                inputs=resolved_inputs,
                calculation_type=operation_type,
                **kwargs,
            )
        except (NodeError, ValueError, TypeError):
            logger.exception(
                "Failed to create calculation node '%s' for type '%s' via factory.",
                name,
                operation_type,
            )
            raise

        # 3. Add the created node to the shared registry
        if name in self._nodes:
            logger.warning(f"Overwriting existing node in shared registry: '{name}'")
        self._nodes[name] = node  # Add to the shared dict

        logger.info(
            f"Added calculation node '{name}' (type: '{operation_type}') to shared registry."
        )
        return node

    def add_metric(self, metric_name: str, node_name: str) -> MetricCalculationNode:
        """Add a metric calculation node based on a definition to the shared registry.

        Looks up the metric definition, resolves required input nodes from the
        shared registry, creates the MetricCalculationNode using the factory,
        and adds it to the shared registry. Tracks the node name as a metric.

        Args:
            metric_name: The key identifying the metric in the metric registry.
                         Example: 'gross_margin'.
            node_name: The unique name to assign to the newly created metric node
                       within the shared registry. Example: 'calculated_gross_margin'.

        Returns:
            The created MetricCalculationNode, now stored in the shared registry.

        Raises:
            ValueError: If a node with `node_name` already exists in the shared registry.
            NodeError: If a required input node for the metric is not found in the
                       shared registry.
            ConfigurationError: If `metric_name` is not defined in the metric registry
                                or its definition is invalid (e.g., missing 'inputs' or 'formula').
            TypeError: If `node_name` is not a non-empty string.

        Example:
            >>> # Assuming 'gross_margin' is defined in metric_registry and requires
            >>> # 'gross_profit' and 'revenue' nodes, which exist in shared_nodes.
            >>> shared_nodes = {
            ...     'revenue': DataNode('revenue', data={'2023': 1000}),
            ...     'gross_profit': DataNode('gross_profit', data={'2023': 400})
            ... }
            >>> engine = CalculationEngine(shared_nodes)
            >>> try:
            ...     metric_node = engine.add_metric(
            ...         metric_name='gross_margin',
            ...         node_name='calculated_gross_margin'
            ...     )
            ...     print(f"Metric node '{metric_node.name}' added.")
            ... except (NodeError, ConfigurationError, ValueError) as e:
            ...     print(e)
            Metric node 'calculated_gross_margin' added.
            >>> # 'calculated_gross_margin' node is now in shared_nodes.
        """
        if not node_name or not isinstance(node_name, str):
            raise TypeError("Metric node name must be a non-empty string.")
        # Check shared registry for conflicts
        if node_name in self._nodes:
            raise ValueError(
                f"A node with name '{node_name}' already exists in the shared registry."
            )

        # 1. Look up metric definition using the registry
        try:
            metric_def = metric_registry.get(metric_name)
        except KeyError:  # Registry raises KeyError if not found
            # Use ConfigurationError for issues with definitions/config
            raise ConfigurationError(f"Unknown metric definition: '{metric_name}'")

        # metric_def = METRIC_DEFINITIONS[metric_name]
        required_input_names = metric_def.get("inputs")

        # Validate definition structure
        if required_input_names is None or not isinstance(required_input_names, list):
            raise ConfigurationError(
                f"Metric definition for '{metric_name}' is invalid: missing or invalid 'inputs' list."
            )
        if "formula" not in metric_def:
            raise ConfigurationError(
                f"Metric definition for '{metric_name}' is invalid: missing 'formula'."
            )

        # 2. Resolve input nodes from the shared self._nodes registry
        resolved_input_nodes: dict[str, Node] = {}
        missing_nodes = []
        for req_name in required_input_names:
            node = self._nodes.get(req_name)  # Look in shared registry
            if node is None:
                missing_nodes.append(req_name)
            else:
                resolved_input_nodes[req_name] = node

        if missing_nodes:
            raise NodeError(
                f"Cannot create metric '{metric_name}' (node '{node_name}'): Missing required input nodes in shared registry: {missing_nodes}"
            )

        # 3. Create the metric node using the factory
        try:
            node = self._node_factory.create_metric_node(
                name=node_name,
                metric_name=metric_name,
                input_nodes=resolved_input_nodes,
            )
        except (ValueError, TypeError, ConfigurationError, NodeError):
            logger.exception(
                "Failed to create metric node '%s' for metric '%s' via factory.",
                node_name,
                metric_name,
            )
            raise

        # 4. Add the created node to the shared registry
        # No separate _metrics dict needed, it lives in self._nodes
        self._nodes[node_name] = node
        self._metric_names.add(node_name)  # Track that this name corresponds to a metric

        logger.info(f"Added metric '{metric_name}' as node '{node_name}' to shared registry.")
        return node

    def calculate(self, node_name: str, period: str) -> float:
        """Calculate the value of a node for a specific period using the shared registry.

        Checks the internal cache first. If not found, retrieves the node from the
        shared registry, calls its `calculate` method, caches the result, and
        returns it.

        Args:
            node_name: Name of the node (must exist in the shared registry).
            period: The period identifier (e.g., '2023Q1') for which to calculate.

        Returns:
            The calculated value for the node and period.

        Raises:
            NodeError: If the node with `node_name` is not found in the shared registry.
            CalculationError: If an error occurs during the node's calculation method.
                              Wraps the original exception.
            TypeError: If the retrieved node object does not have a callable
                       `calculate` method.

        Example:
            >>> shared_nodes = {
            ...     'revenue': DataNode('revenue', data={'2023Q1': 100}),
            ...     'expenses': DataNode('expenses', data={'2023Q1': 60})
            ... }
            >>> engine = CalculationEngine(shared_nodes)
            >>> engine.add_calculation('profit', ['revenue', 'expenses'], 'subtraction')
            >>> try:
            ...     profit_q1 = engine.calculate('profit', '2023Q1')
            ...     print(f"Profit for 2023Q1: {profit_q1}")
            ... except (NodeError, CalculationError) as e:
            ...     print(e)
            Profit for 2023Q1: 40.0
            >>> # Result is now cached for ('profit', '2023Q1')
        """
        # Check calculation cache first
        if node_name in self._cache and period in self._cache[node_name]:
            logger.debug(f"Cache hit for node '{node_name}', period '{period}'")
            return self._cache[node_name][period]

        # Get the node from the shared registry
        node = self._nodes.get(node_name)

        if node is None:
            # No need to check separate _metrics dict
            raise NodeError(f"Node '{node_name}' not found in shared registry for calculation.")

        logger.debug(f"Calculating value for node '{node_name}', period '{period}'")
        # Calculate the value
        try:
            if not hasattr(node, "calculate") or not callable(node.calculate):
                raise TypeError(
                    f"Node '{node_name}' of type {type(node).__name__} does not have a callable calculate method."
                )

            value = node.calculate(period)

            # Cache the result
            if node_name not in self._cache:
                self._cache[node_name] = {}
            self._cache[node_name][period] = value
            logger.debug(
                f"Calculated value for node '{node_name}', period '{period}': {value}. Stored in cache."
            )
        except (
            NodeError,
            CalculationError,
            ValueError,
            KeyError,
            ZeroDivisionError,
        ) as e:  # Catch specific calculation-related errors
            # Let TypeError propagate as it indicates a programming error (wrong node type)
            logger.error(
                f"Error calculating node '{node_name}' for period '{period}': {e}",
                exc_info=True,
            )
            raise CalculationError(
                message=f"Failed to calculate node '{node_name}'",
                node_id=node_name,
                period=period,
                details={"original_error": str(e)},
            ) from e
        else:
            return value

    def recalculate_all(self, periods: Optional[list[str]] = None) -> None:
        """Recalculate all nodes in the shared registry for the given periods.

        Clears the engine's calculation cache first. Then, if periods are provided,
        iterates through all nodes currently in the shared registry and calls
        `calculate` for each node and period to repopulate the cache. If no
        periods are given, only the cache is cleared, and recalculation happens
        lazily on subsequent `calculate` calls.

        Args:
            periods: An optional list of period identifiers (e.g., ['2023Q1', '2023Q2'])
                     to recalculate for. If None, only clears the cache.

        Example:
            >>> shared_nodes = { ... } # Setup nodes
            >>> engine = CalculationEngine(shared_nodes)
            >>> # Perform initial calculations...
            >>> engine.calculate('profit', '2023Q1')
            >>> engine.calculate('revenue', '2023Q1')
            >>> # ... Data is updated externally ...
            >>> # Force recalculation for Q1 and calculate Q2
            >>> engine.recalculate_all(periods=['2023Q1', '2023Q2'])
            >>> # Cache is repopulated for 'profit' and 'revenue' for these periods.
        """
        # Clear the engine's calculation cache before recalculating
        self.clear_cache()
        logger.info(f"Cleared calculation cache. Recalculating for periods: {periods}")

        # If no periods specified, calculation happens on demand, cache is just cleared.
        if not periods:
            logger.debug("No specific periods provided for recalculate_all. Cache cleared.")
            return

        # Recalculate all nodes in the shared registry for each period
        # We only need to iterate through self._nodes now
        node_names_to_recalculate = list(self._nodes.keys())  # Get names from shared registry
        logger.debug(
            f"Attempting to recalculate {len(node_names_to_recalculate)} nodes for {len(periods)} periods."
        )

        for node_name in node_names_to_recalculate:
            for period in periods:
                try:
                    # This will calculate and fill the cache if not already done
                    self.calculate(node_name, period)
                except Exception as e:
                    # Log specific error but continue recalculating others
                    logger.warning(
                        f"Error recalculating node '{node_name}' for period '{period}': {e}"
                    )

    def get_available_operations(self) -> dict[str, str]:
        """Retrieve the available calculation operations from the NodeFactory.

        Delegates to the internal NodeFactory to get the registered calculation
        strategies (operation types and their descriptions).

        Returns:
            A dictionary mapping operation type keys (e.g., 'addition') to their
            descriptions.

        Example:
            >>> engine = CalculationEngine({})
            >>> ops = engine.get_available_operations()
            >>> print('addition' in ops)
            True
            >>> print(ops['addition']) # doctest: +ELLIPSIS
            Adds...
        """
        # This depends only on the factory, not the nodes registry
        return self._node_factory.get_available_operations()

    def change_calculation_strategy(
        self, node_name: str, new_strategy_name: str, **kwargs: dict[str, Any]
    ) -> None:
        """Change the calculation strategy for an existing strategy-based node.

        Finds the specified node in the shared registry, verifies it's a
        StrategyCalculationNode, and then calls its `change_strategy` method.
        Clears the cache for this specific node after the change.

        Args:
            node_name: Name of the node in the shared registry whose strategy should
                       be changed. Must be an instance of StrategyCalculationNode.
            new_strategy_name: Name of the new calculation strategy to apply, which
                               must be registered in the NodeFactory.
            **kwargs: Additional arguments required by the new strategy's constructor.

        Raises:
            ValueError: If the node with `node_name` is not found in the shared registry,
                        or if it is not an instance of StrategyCalculationNode.
            LookupError: If `new_strategy_name` is not found in the NodeFactory.
            TypeError: If `**kwargs` do not match the new strategy's requirements.

        Example:
            >>> shared_nodes = {'a': DataNode('a'), 'b': DataNode('b')}
            >>> engine = CalculationEngine(shared_nodes)
            >>> calc_node = engine.add_calculation('sum_ab', ['a', 'b'], 'addition')
            >>> print(type(calc_node.strategy).__name__)
            AdditionCalculationStrategy
            >>> # Change to subtraction
            >>> try:
            ...     engine.change_calculation_strategy('sum_ab', 'subtraction')
            ...     print(type(shared_nodes['sum_ab'].strategy).__name__)
            ... except (ValueError, LookupError) as e:
            ...     print(e)
            SubtractionCalculationStrategy
            >>> # Engine cache for 'sum_ab' is cleared.
        """
        # Look up node in shared registry
        node = self._nodes.get(node_name)
        if node is None:
            raise ValueError(
                f"Node '{node_name}' not found in shared registry for changing strategy."
            )

        if not isinstance(node, StrategyCalculationNode):
            raise ValueError(
                f"Node '{node_name}' is not a strategy calculation node (type: {type(node).__name__})"
            )

        # Delegate to the node's method
        node.change_strategy(new_strategy_name, **kwargs)
        logger.info(f"Changed strategy for node '{node_name}' to '{new_strategy_name}'")

        # Clear engine cache for this node as its calculation changed
        if node_name in self._cache:
            del self._cache[node_name]
            logger.debug(f"Cleared engine cache for node '{node_name}' after strategy change.")

    def add_custom_calculation(
        self,
        name: str,
        calculation_func: Callable[..., float],
        inputs: Optional[list[str]] = None,
        description: str = "",
    ) -> Node:
        """Add a custom calculation node defined by a Python function to the registry.

        Resolves input node names from the shared registry, creates a custom
        calculation node (likely via the NodeFactory using the provided function
        as the formula), and adds it to the shared registry.

        Args:
            name: The unique name for the new custom calculation node.
            calculation_func: The Python callable (function or method) that
                              performs the calculation. It signature should match
                              the expected signature of a FormulaNode's formula
                              (e.g., `func(period: str, inputs: Dict[str, float]) -> float`).
            inputs: An optional list of names of input nodes required by the
                    `calculation_func`. These nodes must exist in the shared registry.
            description: An optional description for the custom calculation node.

        Returns:
            The newly created custom calculation node instance (typically a FormulaNode),
            now stored in the shared registry.

        Raises:
            NodeError: If any specified input node name is not found in the shared registry.
            ValueError: If `name` already exists or if the factory encounters an issue.
            TypeError: If `calculation_func` is not suitable or factory fails.

        Example:
            >>> def custom_ratio(period: str, inputs: Dict[str, float]) -> float:
            ...     return inputs['numerator'] / inputs['denominator'] if inputs['denominator'] else 0.0
            >>> shared_nodes = {
            ...     'numerator': DataNode('numerator', data={'2023': 50}),
            ...     'denominator': DataNode('denominator', data={'2023': 100})
            ... }
            >>> engine = CalculationEngine(shared_nodes)
            >>> try:
            ...     ratio_node = engine.add_custom_calculation(
            ...         name='my_ratio',
            ...         calculation_func=custom_ratio,
            ...         inputs=['numerator', 'denominator'],
            ...         description='Custom ratio calculation'
            ...     )
            ...     print(f"Custom node '{ratio_node.name}' added.")
            ...     # Now calculate it
            ...     value = engine.calculate('my_ratio', '2023')
            ...     print(f"Calculated ratio: {value}")
            ... except (NodeError, ValueError, TypeError, CalculationError) as e:
            ...     print(e)
            Custom node 'my_ratio' added.
            Calculated ratio: 0.5
        """
        # Resolve input node names from the shared registry
        resolved_inputs: list[Node] = []
        missing_nodes = []
        input_names = inputs or []  # Ensure it's a list
        for node_name in input_names:
            node = self._nodes.get(node_name)
            if node is None:
                missing_nodes.append(node_name)
            else:
                resolved_inputs.append(node)

        if missing_nodes:
            raise NodeError(
                f"Cannot create custom calculation node '{name}': Missing required input nodes: {missing_nodes}"
            )

        # Create the custom calculation node using the factory with resolved nodes
        # Assuming factory has _create_custom_node_from_callable or similar internal method
        # Let's assume NodeFactory needs update if add_custom_calculation is public
        # Check NodeFactory: it has _create_custom_node_from_callable
        # This engine method should probably use that factory method.
        try:
            # Use the (renamed) factory method
            node = self._node_factory._create_custom_node_from_callable(
                name=name,
                inputs=resolved_inputs,  # Pass resolved nodes
                formula=calculation_func,  # Pass the callable
                description=description,
            )
        except (NodeError, ValueError, TypeError):
            logger.exception(
                "Failed to create custom calculation node '%s' via factory.",
                name,
            )
            raise

        # Add to the shared node registry
        if name in self._nodes:
            logger.warning(f"Overwriting existing node in shared registry: '{name}'")
        self._nodes[name] = node
        logger.info(f"Added custom calculation node '{name}' to shared registry.")

        return node

    def add_calculation_node(self, node: Node):
        """Add an existing, pre-constructed node instance directly to the registry.

        Useful for integrating nodes created outside the engine's factory methods.
        Warns if a node with the same name already exists, overwriting it.

        Args:
            node: The fully instantiated Node object to add to the shared registry.
                  Its `name` attribute will be used as the key.

        Example:
            >>> class MySpecialNode(Node):
            ...    def calculate(self, period): return 42
            ...
            >>> special_node = MySpecialNode(name="special_value")
            >>> shared_nodes = {}
            >>> engine = CalculationEngine(shared_nodes)
            >>> engine.add_calculation_node(special_node)
            >>> print('special_value' in shared_nodes)
            True
            >>> print(engine.calculate('special_value', 'any_period'))
            42.0
        """
        if node.name in self._nodes:
            logger.warning(f"Overwriting existing node in shared registry: '{node.name}'")
        self._nodes[node.name] = node
        logger.info(f"Added pre-constructed node '{node.name}' to shared registry.")

    def get_metric(self, metric_id: str) -> Optional[Node]:
        """Retrieve a metric node by its name (ID) from the shared registry.

        Looks up the `metric_id` in the shared registry and checks if it was
        specifically registered as a metric (via `add_metric`).

        Args:
            metric_id: The name of the node that was registered as a metric.

        Returns:
            The Node instance if found and registered as a metric, otherwise None.

        Example:
            >>> # Assume 'gm_calc' was added via engine.add_metric(...)
            >>> shared_nodes = { ... }
            >>> engine = CalculationEngine(shared_nodes)
            >>> # ... engine.add_metric('gross_margin', 'gm_calc') ...
            >>> metric_node = engine.get_metric('gm_calc')
            >>> if metric_node:
            ...    print(f"Found metric node: {metric_node.name}")
            >>> else:
            ...    print("Metric node not found or not registered as metric.")

        """
        # Metrics are just nodes in the shared registry
        node = self._nodes.get(metric_id)
        if node and metric_id in self._metric_names:
            return node
        # Return None if not found or if the name doesn't correspond to a known metric
        return None

    def get_available_metrics(self) -> list[str]:
        """Get a sorted list of names for all nodes currently registered as metrics.

        Returns:
            A list containing the names of nodes added via `add_metric`.

        Example:
            >>> # Assume 'gm_calc' and 'npm_calc' were added via engine.add_metric(...)
            >>> shared_nodes = { ... }
            >>> engine = CalculationEngine(shared_nodes)
            >>> # ... engine.add_metric('gross_margin', 'gm_calc') ...
            >>> # ... engine.add_metric('net_profit_margin', 'npm_calc') ...
            >>> metric_names = engine.get_available_metrics()
            >>> print(metric_names) # Should be sorted
            ['gm_calc', 'npm_calc']
        """
        # Return the names we tracked when adding metrics
        return sorted(list(self._metric_names))

    def get_metric_info(self, metric_id: str) -> Optional[dict]:
        """Get descriptive information about a specific metric node.

        Retrieves the metric node using `get_metric` and extracts details like
        its name, description, and input dependencies.

        Args:
            metric_id: The name (ID) of the metric node to query.

        Returns:
            A dictionary containing information about the metric ('name',
            'description', 'inputs'), or None if the metric node cannot be found.
            Note: Returns None is deprecated, raises ValueError instead.

        Raises:
            ValueError: If a node with `metric_id` exists but was not registered
                        as a metric, or if no node with `metric_id` is found at all.

        Example:
            >>> # Assume 'gm_calc' was added via engine.add_metric(...)
            >>> # and requires 'gross_profit', 'revenue'.
            >>> shared_nodes = { ... }
            >>> engine = CalculationEngine(shared_nodes)
            >>> # ... engine.add_metric('gross_margin', 'gm_calc', ...) ...
            >>> try:
            ...     info = engine.get_metric_info('gm_calc')
            ...     print(f"Name: {info['name']}")
            ...     print(f"Inputs: {info['inputs']}") # Example output
            ... except ValueError as e:
            ...     print(e)
            Name: gm_calc
            Inputs: ['gross_profit', 'revenue']
        """
        # Get the node (must be a tracked metric name)
        node = self.get_metric(metric_id)
        if node is None:
            # Raise error if the ID is totally unknown or just not a metric?
            # Let's be specific: raise if it's not a known metric ID.
            if metric_id in self._nodes:
                raise ValueError(f"Node '{metric_id}' exists but was not registered as a metric.")
            else:
                raise ValueError(f"Metric with ID '{metric_id}' not found.")

        # Construct info dict - assumes MetricCalculationNode structure or similar
        info = {
            "name": node.name,
            "description": getattr(node, "description", None),  # Handle if no description
        }
        # Get dependencies based on the node type or method
        if hasattr(node, "get_dependencies"):
            try:
                info["inputs"] = node.get_dependencies()  # Assumes returns list of names
            except Exception as e:
                logger.warning(f"Could not get dependencies for metric '{metric_id}': {e}")
                info["inputs"] = []  # Default to empty list on error
        elif (
            hasattr(node, "inputs") and node.inputs is not None
        ):  # Check if inputs attr exists and is not None
            # Fallback: try to get names from inputs attribute if it exists
            if isinstance(node.inputs, list):  # StrategyNode, CustomNode
                info["inputs"] = [inp.name for inp in node.inputs if hasattr(inp, "name")]
            elif isinstance(node.inputs, dict):  # FormulaNode, MetricNode
                # Get the names of the nodes held in the input dictionary values
                info["inputs"] = [inp.name for inp in node.inputs.values() if hasattr(inp, "name")]
            else:
                info["inputs"] = []
        else:
            info["inputs"] = []

        return info

    def clear_cache(self):
        """Clear the engine's internal calculation cache entirely.

        This forces recalculation of values upon the next `calculate` call for
        any node and period.

        Example:
            >>> engine = CalculationEngine({})
            >>> # ... perform some calculations, cache gets populated ...
            >>> engine.clear_cache()
            >>> # Subsequent calls to engine.calculate() will recompute values.
        """
        self._cache.clear()
        logger.info("Calculation engine cache cleared.")

    def reset(self):
        """Reset the calculation engine's state, clearing cache and metric tracking.

        This method clears the internal calculation cache and the set of tracked
        metric names. It **does not** modify the shared `_nodes` registry itself,
        as that is managed externally (e.g., by a Graph instance).

        Example:
            >>> engine = CalculationEngine({})
            >>> # ... add metrics, perform calculations ...
            >>> engine.reset()
            >>> print(engine.get_available_metrics())
            []
            >>> # Cache is also empty, but shared_nodes registry is unaffected.
        """
        # Does NOT clear self._nodes as it's shared and owned by Graph
        self.clear_cache()
        self._metric_names.clear()
        logger.info("Calculation engine reset (cache and metric tracking cleared).")

    def _execute_dependencies(self, node_id: str, period: str, **kwargs: dict[str, Any]) -> dict:
        """Recursively execute dependencies for a node.

        This method is used internally to handle dependencies between nodes.
        It recursively calculates the value of a node based on its dependencies.

        Args:
            node_id: The ID of the node to calculate.
            period: The period for which to calculate the node.
            **kwargs: Additional keyword arguments to pass to the node's calculate method.

        Returns:
            A dictionary containing the calculated value and any errors encountered.
        """
        # Placeholder implementation - needs actual logic
        logger.warning(
            f"_execute_dependencies for {node_id} period {period} is not fully implemented."
        )
        return {"value": None, "errors": ["Not Implemented"]}

# --- END FILE: fin_statement_model/core/calculation_engine.py ---

# --- START FILE: fin_statement_model/core/errors.py ---
"""Custom exceptions for the Financial Statement Model.

This module defines exception classes for specific error cases in the
Financial Statement Model, allowing for more precise error handling
and better error messages.
"""

from typing import Optional, Any


class FinancialModelError(Exception):
    """Base exception class for all Financial Statement Model errors.

    All custom exceptions raised within the library should inherit from this class.

    Args:
        message: A human-readable description of the error.
    """

    def __init__(self, message: str):
        """Initializes the FinancialModelError."""
        self.message = message
        super().__init__(self.message)


class ConfigurationError(FinancialModelError):
    """Exception raised for errors in configuration files or objects.

    This typically occurs when parsing or validating configuration data,
    such as YAML files defining metrics or statement structures.

    Args:
        message: The base error message.
        config_path: Optional path to the configuration file where the error occurred.
        errors: Optional list of specific validation errors found.

    Examples:
        >>> raise ConfigurationError("Invalid syntax", config_path="config.yaml")
        >>> raise ConfigurationError(
        ...     "Missing required fields",
        ...     config_path="metrics.yaml",
        ...     errors=["Missing 'formula' for 'revenue'"]
        ... )
    """

    def __init__(
        self,
        message: str,
        config_path: Optional[str] = None,
        errors: Optional[list[str]] = None,
    ):
        """Initializes the ConfigurationError."""
        self.config_path = config_path
        self.errors = errors or []

        if config_path and errors:
            full_message = f"{message} in {config_path}: {'; '.join(errors)}"
        elif config_path:
            full_message = f"{message} in {config_path}"
        elif errors:
            full_message = f"{message}: {'; '.join(errors)}"
        else:
            full_message = message

        super().__init__(full_message)


class CalculationError(FinancialModelError):
    """Exception raised for errors during calculation operations.

    This indicates a problem while computing the value of a node, often due
    to issues with the calculation logic, input data, or strategy used.

    Args:
        message: The base error message.
        node_id: Optional ID of the node where the calculation failed.
        period: Optional period for which the calculation failed.
        details: Optional dictionary containing additional context about the error.

    Examples:
        >>> raise CalculationError("Division by zero", node_id="profit_margin", period="2023-Q1")
        >>> raise CalculationError(
        ...     "Incompatible input types",
        ...     node_id="total_assets",
        ...     details={"input_a_type": "str", "input_b_type": "int"}
        ... )
    """

    def __init__(
        self,
        message: str,
        node_id: Optional[str] = None,
        period: Optional[str] = None,
        details: Optional[dict[str, Any]] = None,
    ):
        """Initializes the CalculationError."""
        self.node_id = node_id
        self.period = period
        self.details = details or {}

        context = []
        if node_id:
            context.append(f"node '{node_id}'")
        if period:
            context.append(f"period '{period}'")

        full_message = f"{message} for {' and '.join(context)}" if context else message

        # Append details to the message for better context
        if self.details:
            details_str = ", ".join(f'{k}="{v}"' for k, v in self.details.items())
            # Prioritize showing the original underlying error if captured
            original_error_str = self.details.get("original_error")
            if original_error_str:
                full_message = f"{full_message}: {original_error_str}"
            else:
                full_message = f"{full_message} (Details: {details_str})"

        super().__init__(full_message)


class NodeError(FinancialModelError):
    """Exception raised for errors related to graph nodes.

    This covers issues like trying to access a non-existent node,
    invalid node configurations, or type mismatches related to nodes.

    Args:
        message: The base error message.
        node_id: Optional ID of the node related to the error.

    Examples:
        >>> raise NodeError("Node not found", node_id="non_existent_node")
        >>> raise NodeError("Invalid node type for operation", node_id="revenue")
    """

    def __init__(self, message: str, node_id: Optional[str] = None):
        """Initializes the NodeError."""
        self.node_id = node_id

        full_message = f"{message} for node '{node_id}'" if node_id else message

        super().__init__(full_message)


class MissingInputError(FinancialModelError):
    """Exception raised when a required input for a calculation is missing.

    This occurs when a calculation node needs data from another node for a
    specific period, but that data is unavailable.

    Args:
        message: The base error message.
        node_id: Optional ID of the node requiring the input.
        input_name: Optional name or ID of the missing input node.
        period: Optional period for which the input was missing.

    Examples:
        >>> raise MissingInputError(
        ...     "Required input data unavailable",
        ...     node_id="cogs",
        ...     input_name="inventory",
        ...     period="2023-12-31"
        ... )
    """

    def __init__(
        self,
        message: str,
        node_id: Optional[str] = None,
        input_name: Optional[str] = None,
        period: Optional[str] = None,
    ):
        """Initializes the MissingInputError."""
        self.node_id = node_id
        self.input_name = input_name
        self.period = period

        context = []
        if node_id:
            context.append(f"node '{node_id}'")
        if input_name:
            context.append(f"input '{input_name}'")
        if period:
            context.append(f"period '{period}'")

        full_message = f"{message} for {' in '.join(context)}" if context else message

        super().__init__(full_message)


class GraphError(FinancialModelError):
    """Exception raised for errors in the graph structure or operations.

    This covers issues like inconsistencies in the graph (e.g., orphaned nodes),
    problems during graph traversal, or invalid modifications to the graph.

    Args:
        message: The base error message.
        nodes: Optional list of node IDs involved in the graph error.

    Examples:
        >>> raise GraphError("Orphaned node detected", nodes=["unconnected_node"])
        >>> raise GraphError("Failed to add edge due to type mismatch")
    """

    def __init__(self, message: str, nodes: Optional[list[str]] = None):
        """Initializes the GraphError."""
        self.nodes = nodes or []

        full_message = f"{message} involving nodes: {', '.join(nodes)}" if nodes else message

        super().__init__(full_message)


class DataValidationError(FinancialModelError):
    """Exception raised for data validation errors.

    This typically occurs during data import or preprocessing when data
    does not conform to expected formats, types, or constraints.

    Args:
        message: The base error message.
        validation_errors: Optional list of specific validation failures.

    Examples:
        >>> raise DataValidationError(
        ...     "Input data failed validation",
        ...     validation_errors=["Column 'Date' has invalid format", "Value '-100' is not allowed for 'Revenue'"]
        ... )
    """

    def __init__(self, message: str, validation_errors: Optional[list[str]] = None):
        """Initializes the DataValidationError."""
        self.validation_errors = validation_errors or []

        if validation_errors:
            full_message = f"{message}: {'; '.join(validation_errors)}"
        else:
            full_message = message

        super().__init__(full_message)


class ImportError(FinancialModelError):
    """Exception raised for errors during data import operations.

    This signals a problem while reading data from an external source,
    such as a file or an API.

    Args:
        message: The base error message.
        source: Optional identifier for the data source (e.g., file path, URL).
        adapter: Optional name of the adapter or reader used for importing.
        original_error: Optional underlying exception that caused the import failure.

    Examples:
        >>> raise ImportError("File not found", source="data.csv", adapter="csv_reader")
        >>> try:
        ...     # some_api_call()
        ...     pass
        ... except requests.exceptions.RequestException as e:
        ...     raise ImportError("API request failed", source="api.example.com/data", original_error=e)
    """

    def __init__(
        self,
        message: str,
        source: Optional[str] = None,
        adapter: Optional[str] = None,
        original_error: Optional[Exception] = None,
    ):
        """Initializes the ImportError."""
        self.source = source
        self.adapter = adapter
        self.original_error = original_error

        context = []
        if source:
            context.append(f"source '{source}'")
        if adapter:
            context.append(f"adapter '{adapter}'")

        if context:
            if adapter:
                full_message = f"{message} using {' '.join(context)}"
            else:
                full_message = f"{message} from {' '.join(context)}"
        else:
            full_message = message

        if original_error:
            full_message = f"{full_message}: {original_error!s}"

        super().__init__(full_message)


class ExportError(FinancialModelError):
    """Exception raised for errors during data export operations.

    This signals a problem while writing data to an external target,
    such as a file or database.

    Args:
        message: The base error message.
        target: Optional identifier for the export destination (e.g., file path).
        format_type: Optional name of the format being exported to (e.g., 'json', 'xlsx').
        original_error: Optional underlying exception that caused the export failure.

    Examples:
        >>> raise ExportError("Permission denied", target="/path/to/output.xlsx", format_type="excel")
        >>> try:
        ...     # write_to_database()
        ...     pass
        ... except DatabaseError as e:
        ...     raise ExportError("Database write failed", target="db://...", original_error=e)

    """

    def __init__(
        self,
        message: str,
        target: Optional[str] = None,
        format_type: Optional[str] = None,
        original_error: Optional[Exception] = None,
    ):
        """Initializes the ExportError."""
        self.target = target
        self.format_type = format_type
        self.original_error = original_error

        context = []
        if target:
            context.append(f"target '{target}'")
        if format_type:
            context.append(f"format '{format_type}'")

        if context:
            if format_type:
                full_message = f"{message} in {' '.join(context)}"
            else:
                full_message = f"{message} to {' '.join(context)}"
        else:
            full_message = message

        if original_error:
            full_message = f"{full_message}: {original_error!s}"

        super().__init__(full_message)


class CircularDependencyError(FinancialModelError):
    """Exception raised when a circular dependency is detected in calculations.

    This occurs if the calculation graph contains cycles, meaning a node
    directly or indirectly depends on itself.

    Args:
        message: The base error message. Defaults to "Circular dependency detected".
        cycle: Optional list of node IDs forming the detected cycle.

    Examples:
        >>> raise CircularDependencyError(cycle=["node_a", "node_b", "node_c", "node_a"])
    """

    def __init__(
        self,
        message: str = "Circular dependency detected",
        cycle: Optional[list[str]] = None,
    ):
        """Initializes the CircularDependencyError."""
        self.cycle = cycle or []

        if cycle:
            cycle_str = " -> ".join(cycle)
            full_message = f"{message}: {cycle_str}"
        else:
            full_message = message

        super().__init__(full_message)


class PeriodError(FinancialModelError):
    """Exception raised for errors related to periods.

    This covers issues like requesting data for a non-existent period or
    using invalid period formats.

    Args:
        message: The base error message.
        period: Optional specific period involved in the error.
        available_periods: Optional list of valid periods.

    Examples:
        >>> raise PeriodError("Invalid period format", period="2023Q5")
        >>> raise PeriodError("Period not found", period="2024-01-01", available_periods=["2023-12-31"])
    """

    def __init__(
        self,
        message: str,
        period: Optional[str] = None,
        available_periods: Optional[list[str]] = None,
    ):
        """Initializes the PeriodError."""
        self.period = period
        self.available_periods = available_periods or []

        if period and available_periods:
            full_message = f"{message} for period '{period}'. Available periods: {', '.join(available_periods)}"
        elif period:
            full_message = f"{message} for period '{period}'"
        else:
            full_message = message

        super().__init__(full_message)


class StatementError(FinancialModelError):
    """Exception raised for errors related to financial statements.

    This is used for errors specific to the structure, definition, or
    processing of financial statements (e.g., Balance Sheet, P&L).

    Args:
        message: The base error message.
        statement_id: Optional ID or name of the statement involved.

    Examples:
        >>> raise StatementError("Balance sheet does not balance", statement_id="BS_2023")
        >>> raise StatementError("Required account missing from P&L", statement_id="PnL_Q1")
    """

    def __init__(self, message: str, statement_id: Optional[str] = None):
        """Initializes the StatementError."""
        self.statement_id = statement_id

        full_message = f"{message} for statement '{statement_id}'" if statement_id else message

        super().__init__(full_message)


class StrategyError(FinancialModelError):
    """Exception raised for errors related to calculation strategies.

    This indicates a problem with the configuration or execution of a
    specific calculation strategy (e.g., Summation, GrowthRate).

    Args:
        message: The base error message.
        strategy_type: Optional name or type of the strategy involved.
        node_id: Optional ID of the node using the strategy.

    Examples:
        >>> raise StrategyError("Invalid parameter for GrowthRate strategy", strategy_type="GrowthRate", node_id="revenue_forecast")
        >>> raise StrategyError("Strategy not applicable to node type", strategy_type="Summation", node_id="text_description")
    """

    def __init__(
        self,
        message: str,
        strategy_type: Optional[str] = None,
        node_id: Optional[str] = None,
    ):
        """Initializes the StrategyError."""
        self.strategy_type = strategy_type
        self.node_id = node_id

        context = []
        if strategy_type:
            context.append(f"strategy type '{strategy_type}'")
        if node_id:
            context.append(f"node '{node_id}'")

        full_message = f"{message} for {' in '.join(context)}" if context else message

        super().__init__(full_message)


class TransformationError(FinancialModelError):
    """Exception raised for errors during data transformation.

    This occurs during preprocessing steps when a specific transformation
    (e.g., normalization, scaling) fails.

    Args:
        message: The base error message.
        transformer_type: Optional name or type of the transformer involved.
        parameters: Optional dictionary of parameters used by the transformer.

    Examples:
        >>> raise TransformationError("Log transform requires positive values", transformer_type="LogTransformer")
        >>> raise TransformationError(
        ...     "Incompatible data type for scaling",
        ...     transformer_type="MinMaxScaler",
        ...     parameters={"feature_range": (0, 1)}
        ... )
    """

    def __init__(
        self,
        message: str,
        transformer_type: Optional[str] = None,
        parameters: Optional[dict[str, Any]] = None,
    ):
        """Initializes the TransformationError."""
        self.transformer_type = transformer_type
        self.parameters = parameters or {}

        if transformer_type:
            full_message = f"{message} in transformer '{transformer_type}'"
            if parameters:
                params_str = ", ".join(f"{k}={v}" for k, v in parameters.items())
                full_message = f"{full_message} with parameters: {params_str}"
        else:
            full_message = message

        super().__init__(full_message)


class MetricError(FinancialModelError):
    """Exception raised for errors related to metric definitions or registry.

    This covers issues with loading, validating, or accessing financial metrics,
    whether defined in YAML or Python code.

    Args:
        message: The base error message.
        metric_name: Optional name of the metric involved in the error.
        details: Optional dictionary containing additional context about the error.

    Examples:
        >>> raise MetricError("Metric definition not found", metric_name="unknown_ratio")
        >>> raise MetricError(
        ...     "Invalid formula syntax in metric definition",
        ...     metric_name="profitability_index",
        ...     details={"formula": "NPV / Initial Investment)"} # Missing parenthesis
        ... )
    """

    def __init__(
        self,
        message: str,
        metric_name: Optional[str] = None,
        details: Optional[dict[str, Any]] = None,
    ):
        """Initializes the MetricError."""
        self.metric_name = metric_name
        self.details = details or {}

        full_message = f"{message} related to metric '{metric_name}'" if metric_name else message

        super().__init__(full_message)

# --- END FILE: fin_statement_model/core/errors.py ---

# --- START FILE: fin_statement_model/core/data_manager.py ---
"""Data management functionality for the Financial Statement Model.

This module provides the DataManager class which is responsible for managing
financial data in the graph, including adding and updating financial statement items.
"""

from typing import Optional
from .nodes import Node, FinancialStatementItemNode
from .node_factory import NodeFactory
import logging

logger = logging.getLogger(__name__)


class DataManager:
    """Manages financial data within a shared node registry.

    Responsibilities:
        - Adding/updating financial statement item nodes to the shared registry.
        - Managing the list of unique time periods encountered.

    Attributes:
        nodes (Dict[str, Node]): The shared dictionary storing all nodes.
        periods (List[str]): A sorted list of unique time periods encountered.

    Example:
        >>> shared_nodes = {}
        >>> data_manager = DataManager(shared_nodes)
        >>> revenue_node = data_manager.add_item(
        ...     "Revenue", {"2023Q1": 1000, "2023Q2": 1100}
        ... )
        >>> print(data_manager.get_node("Revenue"))
        FinancialStatementItemNode(name='Revenue', ...)
        >>> print(data_manager.periods)
        ['2023Q1', '2023Q2']
    """

    def __init__(self, nodes_registry: dict[str, Node]):
        """Initialize the DataManager with a shared node registry.

        Args:
            nodes_registry: The dictionary instance shared across graph components
                            to store all nodes. This dictionary will be mutated
                            by the DataManager.
        """
        self._node_factory = NodeFactory()
        self._nodes = nodes_registry
        self._periods: list[str] = []

    def add_periods(self, periods: list[str]) -> None:
        """Add unique periods based on data encountered.

        Maintains a sorted list of unique periods seen across all data items.

        Args:
            periods: List of period strings to add. If duplicates exist within
                     the list or compared to existing periods, they are ignored.

        Example:
            >>> shared_nodes = {}
            >>> data_manager = DataManager(shared_nodes)
            >>> data_manager.add_periods(["2023Q1", "2023Q2"])
            >>> data_manager.add_periods(["2023Q2", "2023Q3"])
            >>> print(data_manager.periods)
            ['2023Q1', '2023Q2', '2023Q3']
        """
        # Use a set to handle duplicates within the input list efficiently
        unique_incoming = set(periods)
        new_periods = [p for p in unique_incoming if p not in self._periods]
        if new_periods:
            self._periods.extend(new_periods)
            self._periods.sort()
            logger.debug(f"Added periods: {new_periods}. Current periods: {self._periods}")

    def add_node(self, node: Node) -> Node:
        """Add a node directly to the shared registry.

        This method is for adding any type of node, including custom or
        calculation nodes. For standard financial data items, prefer `add_item`.
        If a node with the same name already exists, it will be overwritten,
        and a warning will be logged.

        Args:
            node: The node instance to add.

        Returns:
            Node: The added node.

        Example:
            >>> from fin_statement_model.core.nodes import CalculationNode
            >>> shared_nodes = {}
            >>> data_manager = DataManager(shared_nodes)
            >>> # Assume GrossProfitNode is a subclass of CalculationNode
            >>> # gp_node = GrossProfitNode(name="GrossProfit", ...)
            >>> # data_manager.add_node(gp_node)
            >>> # print(data_manager.get_node("GrossProfit"))
            # GrossProfitNode(name='GrossProfit', ...)
        """
        if node.name in self._nodes:
            logger.warning(f"Overwriting node '{node.name}' in shared registry.")
        self._nodes[node.name] = node
        logger.debug(f"Added node '{node.name}' directly to shared registry.")
        return node

    def get_node(self, name: str) -> Optional[Node]:
        """Get a node by name from the shared registry.

        Args:
            name: The name of the node to retrieve.

        Returns:
            Optional[Node]: The node instance if found, otherwise None.

        Example:
            >>> shared_nodes = {}
            >>> data_manager = DataManager(shared_nodes)
            >>> data_manager.add_item("COGS", {"2023": 500})
            FinancialStatementItemNode(name='COGS', values={'2023': 500.0})
            >>> cogs_node = data_manager.get_node("COGS")
            >>> print(cogs_node.name if cogs_node else None)
            COGS
            >>> print(data_manager.get_node("NonExistent"))
            None
        """
        return self._nodes.get(name)

    def add_item(self, name: str, values: dict[str, float]) -> FinancialStatementItemNode:
        """Add a financial statement item node to the shared registry.

        Creates a `FinancialStatementItemNode` with the given name and values,
        adds it to the registry, and updates the list of known periods.

        Args:
            name: Name of the financial statement item (e.g., "Revenue", "COGS").
            values: Dictionary mapping period strings (e.g., "2023Q1") to
                    numerical values.

        Returns:
            FinancialStatementItemNode: The created and registered node.

        Raises:
            ValueError: If a node with the same name already exists.

        Example:
            >>> shared_nodes = {}
            >>> data_manager = DataManager(shared_nodes)
            >>> revenue = data_manager.add_item("Revenue", {"2023": 1000, "2024": 1200})
            >>> print(revenue.name)
            Revenue
            >>> print(data_manager.get_node("Revenue").values)
            {'2023': 1000.0, '2024': 1200.0}
            >>> print(data_manager.periods)
            ['2023', '2024']
        """
        if name in self._nodes:
            raise ValueError(f"Node with name '{name}' already exists in the registry.")

        node = FinancialStatementItemNode(name=name, values=values)

        self._nodes[name] = node
        logger.info(f"Added FinancialStatementItemNode '{name}' to shared registry.")

        self.add_periods(list(values.keys()))

        return node

    def update_item(
        self, name: str, values: dict[str, float], replace_existing: bool = False
    ) -> FinancialStatementItemNode:
        """Update values for an existing financial statement item in the shared registry.

        Finds the node by name and updates its `values` dictionary. Can either
        merge new values with existing ones or completely replace them. Also
        updates the list of known periods.

        Args:
            name: Name of the financial statement item to update.
            values: Dictionary mapping periods to new or updated values.
            replace_existing: If True, the existing `values` dictionary is
                              discarded and replaced with the provided `values`.
                              If False (default), the existing `values`
                              dictionary is updated with the new key-value pairs,
                              overwriting values for existing periods if they
                              overlap.

        Returns:
            FinancialStatementItemNode: The updated node.

        Raises:
            ValueError: If the node is not found in the registry.
            TypeError: If the found node is not a `FinancialStatementItemNode`.

        Example:
            >>> shared_nodes = {}
            >>> data_manager = DataManager(shared_nodes)
            >>> item_node = data_manager.add_item("Expenses", {"2023": 500})
            >>> # Merge new/updated values
            >>> updated_node = data_manager.update_item(
            ...     "Expenses", {"2023": 550, "2024": 600}
            ... )
            >>> print(updated_node.values)
            {'2023': 550.0, '2024': 600.0}
            >>> # Replace all values
            >>> replaced_node = data_manager.update_item(
            ...     "Expenses", {"2025": 700}, replace_existing=True
            ... )
            >>> print(replaced_node.values)
            {'2025': 700.0}
            >>> print(data_manager.periods)
            ['2023', '2024', '2025']
        """
        node = self._nodes.get(name)
        if node is None:
            raise ValueError(f"Node '{name}' not found in registry for update.")

        if not isinstance(node, FinancialStatementItemNode):
            raise TypeError(
                f"Cannot update item values for node '{name}', "
                f"it is not a FinancialStatementItemNode "
                f"(type: {type(node).__name__})"
            )

        if replace_existing:
            node.values = values.copy()
            logger.debug(f"Replaced values for item '{name}'.")
        else:
            node.values.update(values)
            logger.debug(f"Updated values for item '{name}'.")

        self.add_periods(list(values.keys()))

        return node

    def delete_item(self, name: str) -> bool:
        """Delete a node (presumably an item) from the shared registry.

        Args:
            name: Name of the node to delete.

        Returns:
            bool: True if the node was found and deleted, False otherwise.

        Example:
            >>> shared_nodes = {}
            >>> data_manager = DataManager(shared_nodes)
            >>> data_manager.add_item("TempData", {"2023": 1})
            FinancialStatementItemNode(name='TempData', values={'2023': 1.0})
            >>> deleted = data_manager.delete_item("TempData")
            >>> print(deleted)
            True
            >>> print(data_manager.get_node("TempData"))
            None
            >>> not_deleted = data_manager.delete_item("NonExistent")
            >>> print(not_deleted)
            False
        """
        if name in self._nodes:
            del self._nodes[name]
            logger.info(f"Deleted node '{name}' from shared registry.")
            return True
        logger.warning(f"Attempted to delete non-existent node '{name}'.")
        return False

    @property
    def periods(self) -> list[str]:
        """Get the sorted list of unique periods encountered across all items.

        Returns:
            List[str]: A sorted list of unique period strings.

        Example:
            >>> shared_nodes = {}
            >>> data_manager = DataManager(shared_nodes)
            >>> data_manager.add_item("A", {"2024": 1, "2022": 2})
            FinancialStatementItemNode(...)
            >>> data_manager.add_item("B", {"2023": 3, "2022": 4})
            FinancialStatementItemNode(...)
            >>> print(data_manager.periods)
            ['2022', '2023', '2024']
        """
        return self._periods

# --- END FILE: fin_statement_model/core/data_manager.py ---

# --- START FILE: fin_statement_model/io/writers/dataframe.py ---
"""Data writer for pandas DataFrames."""

import logging

import pandas as pd
import numpy as np

from fin_statement_model.core.graph import Graph
from fin_statement_model.io.base import DataWriter
from fin_statement_model.io.registry import register_writer
from fin_statement_model.io.exceptions import WriteError

logger = logging.getLogger(__name__)


@register_writer("dataframe")
class DataFrameWriter(DataWriter):
    """Writes graph data to a pandas DataFrame.

    The DataFrame index will be node names, columns will be periods.
    """

    def write(
        self, graph: Graph, target: object = None, **kwargs: dict[str, object]
    ) -> pd.DataFrame:
        """Convert the graph data to a pandas DataFrame.

        Args:
            graph: The Graph instance to export.
            target: Ignored for DataFrameWriter, as it returns the DataFrame.
            **kwargs: Optional keyword arguments:
                recalculate (bool): Recalculate graph before export (default: True).
                include_nodes (list[str]): Optional list of node names to include.

        Returns:
            pd.DataFrame: DataFrame with node names as index and periods as columns.

        Raises:
            WriteError: If an error occurs during conversion.
        """
        recalculate = kwargs.get("recalculate", True)
        include_nodes = kwargs.get("include_nodes")
        logger.info("Exporting graph to DataFrame format.")

        try:
            if recalculate:
                try:
                    if graph.periods:
                        graph.recalculate_all(periods=graph.periods)
                        logger.info("Recalculated graph before exporting to DataFrame.")
                    else:
                        logger.warning("Graph has no periods defined, skipping recalculation.")
                except Exception as e:
                    logger.error(
                        f"Error during recalculation for DataFrame export: {e}",
                        exc_info=True,
                    )
                    logger.warning(
                        "Proceeding to export DataFrame without successful recalculation."
                    )

            periods = sorted(graph.periods) if graph.periods else []
            data: dict[str, dict[str, float]] = {}

            nodes_to_process = include_nodes if include_nodes else graph.nodes.keys()
            if include_nodes:
                missing_nodes = [n for n in include_nodes if n not in graph.nodes]
                if missing_nodes:
                    logger.warning(
                        f"Nodes specified in include_nodes not found in graph: {missing_nodes}"
                    )
                nodes_to_process = [n for n in include_nodes if n in graph.nodes]

            for node_id in nodes_to_process:
                node = graph.nodes[node_id]
                row: dict[str, float] = {}
                for period in periods:
                    value = np.nan
                    try:
                        if hasattr(node, "calculate") and callable(node.calculate):
                            value = node.calculate(period)
                        elif (
                            hasattr(node, "values")
                            and isinstance(node.values, dict)
                            and period in node.values
                        ):
                            value = node.values.get(period, np.nan)

                        if not isinstance(value, (int, float, np.number)) or not np.isfinite(value):
                            value = np.nan
                    except Exception as e:
                        logger.debug(
                            f"Could not get value for node '{node_id}' period '{period}' for DataFrame export: {e}"
                        )
                        value = np.nan
                    row[period] = float(value)
                data[node_id] = row

            df = pd.DataFrame.from_dict(data, orient="index", columns=periods)
            df.index.name = "node_name"

            logger.info(f"Successfully exported {len(df)} nodes to DataFrame.")
        except Exception as e:
            logger.error(f"Failed to export graph to DataFrame: {e}", exc_info=True)
            raise WriteError(
                message=f"Failed to export graph to DataFrame: {e}",
                target="DataFrame",
                writer_type="DataFrameWriter",
                original_error=e,
            ) from e
        else:
            return df

# --- END FILE: fin_statement_model/io/writers/dataframe.py ---

# --- START FILE: fin_statement_model/io/writers/__init__.py ---
"""Data writers for various formats."""

# Import specific writers to ensure they are registered
from . import dict  # noqa: F401
from . import excel  # noqa: F401
from . import dataframe  # noqa: F401

# Note: No CsvWriter was identified/created

__all__ = [
    # Expose writer classes if needed directly
    # "DictWriter",
    # "ExcelWriter",
    # "DataFrameWriter",
]

# --- END FILE: fin_statement_model/io/writers/__init__.py ---

# --- START FILE: fin_statement_model/io/writers/excel.py ---
"""Data writer for Excel files."""

import logging
from pathlib import Path
from typing import Any

import pandas as pd
import numpy as np

from fin_statement_model.core.graph import Graph
from fin_statement_model.io.base import DataWriter
from fin_statement_model.io.registry import register_writer
from fin_statement_model.io.exceptions import WriteError

logger = logging.getLogger(__name__)


@register_writer("excel")
class ExcelWriter(DataWriter):
    """Writes graph data to an Excel file.

    Converts the graph data to a pandas DataFrame first, then writes to Excel.
    """

    def _graph_to_dataframe(self, graph: Graph, recalculate: bool = True) -> pd.DataFrame:
        """Convert the graph data to a pandas DataFrame.

        Internal helper method adapted from exporters.dataframe.

        Args:
            graph: The Graph instance to export.
            recalculate: Whether to recalculate all nodes before conversion.

        Returns:
            pd.DataFrame: DataFrame with node names as index and periods as columns.
        """
        if recalculate:
            try:
                if graph.periods:  # Only recalculate if graph has periods defined
                    graph.recalculate_all(periods=graph.periods)
                    logger.info(
                        "Recalculated graph before converting to DataFrame for Excel export."
                    )
                else:
                    logger.warning("Graph has no periods defined, skipping recalculation.")
            except Exception as e:
                logger.error(f"Error during recalculation for Excel export: {e}", exc_info=True)
                logger.warning("Proceeding to export Excel without successful recalculation.")

        periods = sorted(graph.periods) if graph.periods else []
        data: dict[str, dict[str, float]] = {}

        for node_id, node in graph.nodes.items():
            row: dict[str, float] = {}
            for period in periods:
                value = np.nan  # Default to NaN
                try:
                    # Prioritize calculated value
                    if hasattr(node, "calculate") and callable(node.calculate):
                        value = node.calculate(period)
                    # Fallback to stored values
                    elif (
                        hasattr(node, "values")
                        and isinstance(node.values, dict)
                        and period in node.values
                    ):
                        value = node.values.get(period, np.nan)

                    if not isinstance(value, (int, float, np.number)) or not np.isfinite(value):
                        value = np.nan  # Ensure non-numeric/infinite become NaN

                except Exception as e:
                    logger.debug(
                        f"Could not get value for node '{node_id}' period '{period}' for Excel export: {e}"
                    )
                    value = np.nan
                row[period] = float(value)  # Ensure float type, handles NaN
            data[node_id] = row

        df = pd.DataFrame.from_dict(data, orient="index", columns=periods)
        df.index.name = "node_name"
        return df

    def write(self, graph: Graph, target: str, **kwargs: dict[str, Any]) -> None:
        """Write data from the Graph object to an Excel file.

        Args:
            graph: The Graph object containing the data to write.
            target (str): Path to the target Excel file.
            **kwargs: Optional keyword arguments:
                sheet_name (str): Name of the sheet to write to (default: "Sheet1").
                recalculate (bool): Recalculate graph before export (default: True).
                include_nodes (list[str]): Optional list of node names to include.
                excel_writer_kwargs (dict): Additional kwargs passed directly to
                                            pandas.DataFrame.to_excel().

        Raises:
            WriteError: If an error occurs during the writing process.
        """
        file_path = target
        sheet_name = kwargs.get("sheet_name", "Sheet1")
        recalculate = kwargs.get("recalculate", True)
        include_nodes = kwargs.get("include_nodes")
        excel_writer_options = kwargs.get("excel_writer_kwargs", {})

        logger.info(f"Exporting graph to Excel file: {file_path}, sheet: {sheet_name}")

        try:
            # 1. Convert graph to DataFrame
            df = self._graph_to_dataframe(graph, recalculate=recalculate)

            # 2. Filter nodes if requested
            if include_nodes:
                if not isinstance(include_nodes, list):
                    logger.warning("'include_nodes' provided but is not a list. Ignoring filter.")
                else:
                    missing_nodes = [n for n in include_nodes if n not in df.index]
                    if missing_nodes:
                        logger.warning(
                            f"Nodes specified in include_nodes not found in graph data: {missing_nodes}"
                        )
                    nodes_to_keep = [n for n in include_nodes if n in df.index]
                    if not nodes_to_keep:
                        logger.warning(
                            "No nodes left to export after filtering with include_nodes."
                        )
                        df = pd.DataFrame()  # Write empty DataFrame
                    else:
                        df = df.loc[nodes_to_keep]

            # 3. Write DataFrame to Excel
            output_path = Path(file_path)
            output_path.parent.mkdir(parents=True, exist_ok=True)

            df.to_excel(
                output_path,
                sheet_name=sheet_name,
                index=True,  # Keep node names as index column
                **excel_writer_options,
            )
            logger.info(f"Successfully exported graph to {file_path}, sheet '{sheet_name}'")

        except Exception as e:
            logger.error(
                f"Failed to export graph to Excel file '{file_path}': {e}",
                exc_info=True,
            )
            raise WriteError(
                message=f"Failed to export graph to Excel: {e}",
                target=file_path,
                writer_type="ExcelWriter",
                original_error=e,
            ) from e

# --- END FILE: fin_statement_model/io/writers/excel.py ---

# --- START FILE: fin_statement_model/io/writers/dict.py ---
"""Data writer for Python dictionaries."""

import logging
from typing import Any

from fin_statement_model.core.graph import Graph
from fin_statement_model.core.nodes import (
    FinancialStatementItemNode,
)  # Import specific node if needed
from fin_statement_model.io.base import DataWriter
from fin_statement_model.io.registry import register_writer
from fin_statement_model.io.exceptions import WriteError

logger = logging.getLogger(__name__)


@register_writer("dict")
class DictWriter(DataWriter):
    """Writes graph data to a Python dictionary.

    Specifically extracts data from FinancialStatementItemNode instances.
    """

    def write(
        self, graph: Graph, target: object = None, **kwargs: dict[str, Any]
    ) -> dict[str, dict[str, float]]:
        """Export data from graph nodes with values to a dictionary.

        Args:
            graph: The Graph instance to export data from.
            target: Ignored for DictWriter, as it returns the dictionary directly.
            **kwargs: Ignored for DictWriter.

        Returns:
            Dict[str, Dict[str, float]]: Mapping node names to period-value dicts.
                                         Only includes FinancialStatementItemNode instances
                                         with a 'values' attribute.

        Raises:
            WriteError: If an unexpected error occurs during export.
        """
        logger.info(f"Starting export of graph '{graph}' to dictionary format.")
        result: dict[str, dict[str, float]] = {}
        try:
            for node_id, node in graph.nodes.items():
                # Check if the node is a FinancialStatementItemNode and has 'values'
                # This makes the export specific to data-holding nodes.
                if (
                    isinstance(node, FinancialStatementItemNode)
                    and hasattr(node, "values")
                    and isinstance(node.values, dict)
                ):
                    # Validate and copy values
                    # Ensure values are {str: float | int}
                    validated_values = {
                        str(k): float(v)
                        for k, v in node.values.items()
                        if isinstance(k, str) and isinstance(v, (int, float))
                    }
                    if validated_values:
                        result[node_id] = validated_values
                    else:
                        logger.debug(
                            f"Node '{node_id}' has no valid period-value data to export. Skipping."
                        )
                # else: Not an FSI node or no valid values, skip

            logger.info(f"Successfully exported {len(result)} nodes to dictionary.")
        except Exception as e:
            logger.error(f"Failed to export graph to dictionary: {e}", exc_info=True)
            raise WriteError(
                message="Failed to export graph to dictionary",
                target="dict",
                writer_type="DictWriter",
                original_error=e,
            ) from e
        else:
            return result

# --- END FILE: fin_statement_model/io/writers/dict.py ---

# --- START FILE: fin_statement_model/io/registry.py ---
"""Registry for readers and writers."""

import logging
from typing import TypeVar, Callable, Any

from .base import DataReader, DataWriter
from .exceptions import FormatNotSupportedError

logger = logging.getLogger(__name__)

# Type variables for generic functions
R = TypeVar("R", bound=DataReader)
W = TypeVar("W", bound=DataWriter)

# Internal registries
_readers: dict[str, type[DataReader]] = {}
_writers: dict[str, type[DataWriter]] = {}


def register_reader(format_type: str) -> Callable[[type[R]], type[R]]:
    """Decorator to register a DataReader class for a specific format type.

    Args:
        format_type: The string identifier for the format (e.g., 'excel', 'csv').

    Returns:
        A decorator function that registers the class and returns it unmodified.

    Raises:
        ValueError: If the format_type is already registered for a reader.
    """

    def decorator(cls: type[R]) -> type[R]:
        if format_type in _readers:
            # Allow re-registration if it's the exact same class (e.g., during reload)
            if _readers[format_type] is not cls:
                raise ValueError(
                    f"Reader format type '{format_type}' already registered to {_readers[format_type]}."
                )
            # If same class, just log and allow (idempotent registration)
            logger.debug(f"Re-registering reader format type '{format_type}' to {cls.__name__}")
        else:
            logger.debug(f"Registering reader format type '{format_type}' to {cls.__name__}")
        _readers[format_type] = cls
        return cls

    return decorator


def register_writer(format_type: str) -> Callable[[type[W]], type[W]]:
    """Decorator to register a DataWriter class for a specific format type.

    Args:
        format_type: The string identifier for the format (e.g., 'excel', 'json').

    Returns:
        A decorator function that registers the class and returns it unmodified.

    Raises:
        ValueError: If the format_type is already registered for a writer.
    """

    def decorator(cls: type[W]) -> type[W]:
        if format_type in _writers:
            # Allow re-registration if it's the exact same class
            if _writers[format_type] is not cls:
                raise ValueError(
                    f"Writer format type '{format_type}' already registered to {_writers[format_type]}."
                )
            logger.debug(f"Re-registering writer format type '{format_type}' to {cls.__name__}")
        else:
            logger.debug(f"Registering writer format type '{format_type}' to {cls.__name__}")
        _writers[format_type] = cls
        return cls

    return decorator


def get_reader(format_type: str, **kwargs: Any) -> DataReader:
    """Get an instance of the registered DataReader for the given format type.

    Args:
        format_type: The string identifier for the format.
        **kwargs: Keyword arguments to pass to the reader's constructor.

    Returns:
        An initialized DataReader instance.

    Raises:
        FormatNotSupportedError: If no reader is registered for the format type.
        Exception: Any exception raised during the reader's __init__.
    """
    if format_type not in _readers:
        raise FormatNotSupportedError(format_type=format_type, operation="read")

    reader_class = _readers[format_type]
    try:
        return reader_class(**kwargs)
    except Exception as e:
        logger.error(
            f"Failed to instantiate reader for format '{format_type}' ({reader_class.__name__}): {e}",
            exc_info=True,
        )
        # Re-raise to allow specific handling upstream, but provide context
        raise RuntimeError(f"Failed to initialize reader {reader_class.__name__}: {e}") from e


def get_writer(format_type: str, **kwargs: Any) -> DataWriter:
    """Get an instance of the registered DataWriter for the given format type.

    Args:
        format_type: The string identifier for the format.
        **kwargs: Keyword arguments to pass to the writer's constructor.

    Returns:
        An initialized DataWriter instance.

    Raises:
        FormatNotSupportedError: If no writer is registered for the format type.
        Exception: Any exception raised during the writer's __init__.
    """
    if format_type not in _writers:
        raise FormatNotSupportedError(format_type=format_type, operation="write")

    writer_class = _writers[format_type]
    try:
        return writer_class(**kwargs)
    except Exception as e:
        logger.error(
            f"Failed to instantiate writer for format '{format_type}' ({writer_class.__name__}): {e}",
            exc_info=True,
        )
        # Re-raise
        raise RuntimeError(f"Failed to initialize writer {writer_class.__name__}: {e}") from e


def list_readers() -> dict[str, type[DataReader]]:
    """Return a copy of the registered reader classes."""
    return _readers.copy()


def list_writers() -> dict[str, type[DataWriter]]:
    """Return a copy of the registered writer classes."""
    return _writers.copy()

# --- END FILE: fin_statement_model/io/registry.py ---

# --- START FILE: fin_statement_model/io/__init__.py ---
"""Input/Output components for the Financial Statement Model.

This package provides a unified interface for reading and writing financial model
data from/to various formats using a registry-based approach.
"""

import logging
from typing import Union

from fin_statement_model.core.graph import Graph

from .base import DataReader, DataWriter
from .registry import get_reader, get_writer, list_readers, list_writers
from .exceptions import IOError, ReadError, WriteError, FormatNotSupportedError

# Configure logging for the io package
logger = logging.getLogger(__name__)

# --- Trigger Registration ---
# Import reader/writer modules to ensure their @register decorators run.
# This makes them available in the registry when the io package is imported.
try:
    from . import readers  # noqa: F401
    from . import writers  # noqa: F401
except ImportError:
    # This might happen during setup or if directories are missing
    logger.warning("Could not automatically import readers/writers")


# --- Facade Functions ---

# Define known keyword arguments for reader/writer initialization
# This helps separate config args from read/write specific args
_READER_INIT_KWARGS = {"api_key", "mapping_config"}
_WRITER_INIT_KWARGS = set()  # Currently no common writer init kwargs identified


def read_data(
    format_type: str, source: str, **kwargs: dict[str, Union[str, int, float, bool]]
) -> Graph:
    """Reads data from a source using the specified format.

    Args:
        format_type (str): The format identifier (e.g., 'excel', 'csv', 'fmp', 'dict').
        source (str): The data source (e.g., file path, ticker symbol, dict, DataFrame).
        **kwargs: Additional keyword arguments. Arguments like 'api_key' or
                  'mapping_config' might be used to initialize the reader,
                  while others (e.g., 'sheet_name', 'statement_type') are passed
                  to the reader's `read()` method.

    Returns:
        Graph: A new Graph object populated with the read data.

    Raises:
        ReadError: If reading fails.
        FormatNotSupportedError: If the format_type is not registered.
        Exception: Other errors during reader initialization or reading.
    """
    logger.info(
        f"Attempting to read data using format '{format_type}' from source type '{type(source).__name__}'"
    )

    # Separate kwargs for init vs read
    init_kwargs = {k: v for k, v in kwargs.items() if k in _READER_INIT_KWARGS}
    read_kwargs = {k: v for k, v in kwargs.items() if k not in _READER_INIT_KWARGS}

    try:
        reader = get_reader(format_type, **init_kwargs)  # Pass only init kwargs
        return reader.read(source, **read_kwargs)  # Pass remaining kwargs to read
    except (IOError, FormatNotSupportedError):
        logger.exception("IO Error reading data")
        raise  # Re-raise specific IO errors
    except Exception as e:
        logger.exception(f"Unexpected error reading data with format '{format_type}'")
        # Wrap unexpected errors in ReadError for consistency?
        raise ReadError(
            "Unexpected error during read",
            source=str(source),
            reader_type=format_type,
            original_error=e,
        ) from e


def write_data(
    format_type: str,
    graph: Graph,
    target: object,
    **kwargs: dict[str, Union[str, int, float, bool]],
) -> object:
    """Writes graph data to a target using the specified format.

    Args:
        format_type (str): The format identifier (e.g., 'excel', 'dataframe', 'dict').
        graph (Graph): The graph object containing data to write.
        target (object): The destination target (e.g., file path). Specific writers
                          might ignore this if they return data (like DataFrameWriter).
        **kwargs: Additional keyword arguments passed to the specific writer's
                  `write()` method (e.g., `sheet_name` for excel).

    Returns:
        object: The result of the write operation. For writers like DataFrameWriter
                or DictWriter, this is the created object. For file writers, it's None.

    Raises:
        WriteError: If writing fails.
        FormatNotSupportedError: If the format_type is not registered.
        Exception: Other errors during writer initialization or writing.
    """
    logger.info(
        f"Attempting to write graph data using format '{format_type}' to target type '{type(target).__name__}'"
    )

    # Separate kwargs for init vs write
    init_kwargs = {k: v for k, v in kwargs.items() if k in _WRITER_INIT_KWARGS}
    write_kwargs = {k: v for k, v in kwargs.items() if k not in _WRITER_INIT_KWARGS}

    try:
        writer = get_writer(format_type, **init_kwargs)  # Pass only init kwargs
        # Pass remaining kwargs to the write method
        return writer.write(graph, target, **write_kwargs)
    except (IOError, FormatNotSupportedError):
        logger.exception("IO Error writing data")
        raise  # Re-raise specific IO errors
    except Exception as e:
        logger.exception(f"Unexpected error writing data with format '{format_type}'")
        # Wrap unexpected errors
        raise WriteError(
            "Unexpected error during write",
            target=str(target),
            writer_type=format_type,
            original_error=e,
        ) from e


# --- Public API ---

__all__ = [
    # "get_reader", # Probably don't expose getters directly
    # "get_writer",
    # Base classes (optional exposure)
    "DataReader",
    "DataWriter",
    "FormatNotSupportedError",
    # Exceptions
    "IOError",
    "ReadError",
    "WriteError",
    # Registry functions (optional exposure)
    "list_readers",
    "list_writers",
    # Facade functions
    "read_data",
    "write_data",
]

# --- END FILE: fin_statement_model/io/__init__.py ---

# --- START FILE: fin_statement_model/io/utils.py ---
"""Utility functions for the IO package."""

# Currently no generic utility functions remain after refactoring.
# Retain file for potential future additions.

# Removed functions:
# - export_graph_to_dict (moved to writers.dict.DictWriter)
# - import_data_from_dict (logic adapted into readers.dict.DictReader)

# Use absolute import instead of relative
from fin_statement_model.core.graph import Graph

# Import Node type if needed for type checking or instanceof checks
# from ...core.nodes import Node


def export_graph_to_dict(graph: Graph) -> dict[str, dict[str, float]]:
    """Export data from the graph nodes that have values.

    Args:
        graph: The Graph instance to export data from.

    Returns:
        Dict[str, Dict[str, float]]: Mapping node names to period-value dicts.
                                     Only includes nodes with a 'values' attribute.
    """
    result: dict[str, dict[str, float]] = {}
    for node_id, node in graph.nodes.items():
        # Check if the node has a 'values' attribute containing the data
        if hasattr(node, "values") and isinstance(node.values, dict):
            # Ensure values are appropriate type (e.g., filter out non-numeric if necessary)
            # For now, assume node.values contains the {period: value} mapping directly
            result[node_id] = node.values.copy()
            # Note: Original mixin didn't explicitly filter node types (like FinancialStatementItemNode)
            # It just checked for 'values'. Keep this behavior for now.
    return result


def import_data_from_dict(
    graph: Graph, data: dict[str, dict[str, float]], create_nodes: bool = True
) -> None:
    """Import data from a dictionary into the graph.

    Updates existing FinancialStatementItemNodes or creates new ones.

    Args:
        graph: The Graph instance to import data into.
        data: Dictionary mapping node names to period-value dictionaries.
              Format: {node_name: {period: value, ...}, ...}
        create_nodes: If True, create FinancialStatementItemNode if a node_name
                      from the data dict doesn't exist in the graph.
                      Defaults to True.

    Raises:
        ValueError: If the data format is invalid or periods mismatch.
        TypeError: If a node exists but is not a FinancialStatementItemNode
                 and create_nodes is False (or if modification is not supported).
    """
    # Validate data structure first
    all_periods = set()
    for node_name, period_values in data.items():
        if not isinstance(period_values, dict):
            raise TypeError(
                f"Invalid data format for node '{node_name}': expected dict, got {type(period_values)}"
            )
        for period, value in period_values.items():
            if not isinstance(value, (int, float)):
                raise TypeError(
                    f"Invalid value for node '{node_name}' period '{period}': expected number, got {type(value)}"
                )
            all_periods.add(period)

    # Add any new periods to the graph
    # Note: The original mixin checked if graph periods were empty or if data periods
    # were a subset. Here, we'll just add any missing periods found in the data.
    new_periods = sorted(list(all_periods - set(graph.periods)))
    if new_periods:
        graph.add_periods(new_periods)

    # Import data into nodes
    # Import FinancialStatementItemNode locally to avoid potential circular imports
    # and keep this specific to this function's purpose.
    from fin_statement_model.core.nodes import FinancialStatementItemNode

    for node_name, period_values in data.items():
        node = graph.get_node(node_name)

        if node is None:
            if create_nodes:
                # Create and add a new FinancialStatementItemNode
                new_node = FinancialStatementItemNode(name=node_name, values=period_values.copy())
                graph.add_node(new_node)
            else:
                # Node doesn't exist, and we shouldn't create it
                # Log a warning or raise an error, depending on desired behavior.
                # For now, let's just skip it.
                pass  # Or raise ValueError(f"Node '{node_name}' not found and create_nodes is False")
        elif isinstance(node, FinancialStatementItemNode):
            # Node exists and is the expected type, update its values
            if hasattr(node, "values") and isinstance(node.values, dict):
                node.values.update(period_values)
                # Optionally, clear cache for this node if values change
                if hasattr(node, "clear_cache"):
                    node.clear_cache()
            else:
                # This case should theoretically not happen if it's an FSItemNode
                # but handle defensively
                raise TypeError(
                    f"Node '{node_name}' is a FinancialStatementItemNode but lacks a 'values' dict."
                )
        else:
            # Node exists but is not a FinancialStatementItemNode
            # Decide how to handle this - raise error? log warning? skip?
            # Raising an error seems safest to avoid incorrect data overwrites.
            raise TypeError(
                f"Node '{node_name}' exists but is not a FinancialStatementItemNode. Cannot import dictionary data."
            )

# --- END FILE: fin_statement_model/io/utils.py ---

# --- START FILE: fin_statement_model/io/exceptions.py ---
"""IO specific exceptions."""

from typing import Optional

# Use absolute import based on project structure
from fin_statement_model.core.errors import FinancialModelError


class IOError(FinancialModelError):
    """Base exception for all Input/Output errors in the IO package."""

    def __init__(
        self,
        message: str,
        source_or_target: Optional[str] = None,
        format_type: Optional[str] = None,
        original_error: Optional[Exception] = None,
    ):
        """Initializes the IOError.

        Args:
            message: The base error message.
            source_or_target: Optional identifier for the source (read) or target (write).
            format_type: Optional name of the format or handler involved.
            original_error: Optional underlying exception that caused the failure.
        """
        self.source_or_target = source_or_target
        self.format_type = format_type
        self.original_error = original_error

        context = []
        if source_or_target:
            context.append(f"source/target '{source_or_target}'")
        if format_type:
            context.append(f"format '{format_type}'")

        full_message = f"{message} involving {' and '.join(context)}" if context else message

        if original_error:
            full_message = f"{full_message}: {original_error!s}"

        super().__init__(full_message)


class ReadError(IOError):
    """Exception raised specifically for errors during data read/import operations."""

    def __init__(
        self,
        message: str,
        source: Optional[str] = None,
        reader_type: Optional[str] = None,
        original_error: Optional[Exception] = None,
    ):
        """Initializes the ReadError.

        Args:
            message: The base error message.
            source: Optional identifier for the data source (e.g., file path, URL).
            reader_type: Optional name of the reader class used for importing.
            original_error: Optional underlying exception that caused the import failure.
        """
        super().__init__(
            message=message,
            source_or_target=source,
            format_type=reader_type,
            original_error=original_error,
        )


class WriteError(IOError):
    """Exception raised specifically for errors during data write/export operations."""

    def __init__(
        self,
        message: str,
        target: Optional[str] = None,
        writer_type: Optional[str] = None,
        original_error: Optional[Exception] = None,
    ):
        """Initializes the WriteError.

        Args:
            message: The base error message.
            target: Optional identifier for the export destination (e.g., file path).
            writer_type: Optional name of the writer class being used.
            original_error: Optional underlying exception that caused the export failure.
        """
        super().__init__(
            message=message,
            source_or_target=target,
            format_type=writer_type,
            original_error=original_error,
        )


class FormatNotSupportedError(IOError):
    """Exception raised when a requested IO format is not registered or supported."""

    def __init__(self, format_type: str, operation: str = "read/write"):
        """Initializes the FormatNotSupportedError.

        Args:
            format_type: The requested format identifier (e.g., 'excel', 'json').
            operation: The operation being attempted ('read' or 'write').
        """
        message = f"Format '{format_type}' is not supported for {operation} operations."
        super().__init__(message=message, format_type=format_type)

# --- END FILE: fin_statement_model/io/exceptions.py ---

# --- START FILE: fin_statement_model/io/readers/fmp.py ---
"""Data reader for the Financial Modeling Prep (FMP) API."""

import logging
import os
import requests
from typing import Optional, ClassVar, Any
import numpy as np

from fin_statement_model.core.graph import Graph
from fin_statement_model.core.nodes import FinancialStatementItemNode
from fin_statement_model.io.base import DataReader
from fin_statement_model.io.registry import register_reader
from fin_statement_model.io.exceptions import ReadError

logger = logging.getLogger(__name__)


@register_reader("fmp")
class FmpReader(DataReader):
    """Reads financial statement data from the FMP API into a Graph.

    Fetches data for a specific ticker and statement type.
    Requires an API key, either passed directly or via the FMP_API_KEY env var.
    """

    BASE_URL = "https://financialmodelingprep.com/api/v3"

    # Default field mappings (can be overridden in __init__)
    # Extracted from FMPAdapter - consider loading from config/shared location?
    DEFAULT_INCOME_STATEMENT_MAPPING: ClassVar[dict[str, str]] = {
        "revenue": "revenue",
        "costOfRevenue": "cost_of_goods_sold",
        "grossProfit": "gross_profit",
        # ... include all relevant default mappings
        "incomeTaxExpense": "tax_expense",
        "netIncome": "net_income",
        "depreciationAndAmortization": "depreciation_and_amortization",  # Often in CF too
        "ebitda": "ebitda",
        "eps": "eps",
        "epsDiluted": "eps_diluted",
    }
    DEFAULT_BALANCE_SHEET_MAPPING: ClassVar[dict[str, str]] = {
        "cashAndCashEquivalents": "cash_and_cash_equivalents",
        # ...
        "totalLiabilitiesAndStockholdersEquity": "total_liabilities_and_stockholders_equity",
        "inventory": "inventory",
        "accountPayables": "account_payables",
    }
    DEFAULT_CASH_FLOW_MAPPING: ClassVar[dict[str, str]] = {
        "netIncome": "net_income",
        "depreciationAndAmortization": "depreciation_and_amortization",
        # ...
        "netCashProvidedByOperatingActivities": "operating_cash_flow",
        "capitalExpenditure": "capital_expenditure",
        "freeCashFlow": "free_cash_flow",
    }

    # Default statement types requested from FMP API
    _STATEMENT_TYPES: ClassVar[dict[str, str]] = {
        "income_statement": "income-statement",
        "balance_sheet": "balance-sheet-statement",
        "cash_flow": "cash-flow-statement",
    }
    # Mapping from API field names to standard node names
    _API_ENDPOINTS: ClassVar[dict[str, str]] = {
        "income_statement": "income-statement",
        "balance_sheet": "balance-sheet-statement",
        "cash_flow": "cash-flow-statement",
    }
    # Default required parameters for the API
    _REQUIRED_PARAMS: ClassVar[list[str]] = ["apikey"]

    def __init__(
        self,
        api_key: Optional[str] = None,
        mapping_config: Optional[dict[str, dict[str, str]]] = None,
    ):
        """Initialize the FmpReader.

        Args:
            api_key: FMP API key. If None, attempts to use FMP_API_KEY env var.
            mapping_config: Optional nested dictionary to override default API field mappings.
                           Format: {'statement_type': {'api_field': 'canonical_name', ...}}
        """
        self.api_key = api_key or os.environ.get("FMP_API_KEY")
        if not self.api_key:
            # Delay raising error until read() is called, maybe key isn't needed for some usage?
            logger.warning("FMP API key not provided via init or FMP_API_KEY env var.")

        self.mapping_config = mapping_config or {}

    def _get_mapping(self, statement_type: Optional[str]) -> dict[str, str]:
        """Get the appropriate mapping based on statement type."""
        mapping = {}
        if statement_type == "income_statement":
            mapping.update(self.DEFAULT_INCOME_STATEMENT_MAPPING)
        elif statement_type == "balance_sheet":
            mapping.update(self.DEFAULT_BALANCE_SHEET_MAPPING)
        elif statement_type == "cash_flow":
            mapping.update(self.DEFAULT_CASH_FLOW_MAPPING)

        # Layer user-provided config
        if statement_type and statement_type in self.mapping_config:
            mapping.update(self.mapping_config[statement_type])
        elif None in self.mapping_config:  # Allow default user mapping
            mapping.update(self.mapping_config[None])

        return mapping

    def _validate_api_key(self):
        """Perform a simple check if the API key seems valid."""
        if not self.api_key:
            raise ReadError(
                "FMP API key is required for reading.",
                source="FMP API",
                reader_type="FmpReader",
            )
        try:
            # Use a cheap endpoint for validation
            test_url = f"{self.BASE_URL}/profile/AAPL?apikey={self.api_key}"  # Example
            response = requests.get(test_url, timeout=10)
            response.raise_for_status()  # Raises HTTPError for bad responses (4xx or 5xx)
            # Basic check on response content if needed
            if not response.json():
                raise ReadError(
                    "API key validation returned empty response.",
                    source="FMP API",
                    reader_type="FmpReader",
                )
            logger.debug("FMP API key validated successfully.")
        except requests.exceptions.RequestException as e:
            logger.error(f"FMP API key validation failed: {e}", exc_info=True)
            raise ReadError(
                f"FMP API key validation failed: {e}",
                source="FMP API",
                reader_type="FmpReader",
                original_error=e,
            )

    def read(self, source: str, **kwargs: dict[str, Any]) -> Graph:
        """Fetch data from FMP API and return a Graph.

        Args:
            source (str): The stock ticker symbol (e.g., "AAPL").
            **kwargs: Required keyword arguments:
                statement_type (str): Type of statement ('income_statement', 'balance_sheet', 'cash_flow').
            Optional keyword arguments:
                period_type (str): 'FY' for annual (default) or 'QTR' for quarterly.
                limit (int): Number of past periods to fetch (default: 50).
                mapping_config (dict): Overrides the mapping config provided at init.
                api_key (str): Overrides the API key provided at init.

        Returns:
            A new Graph instance populated with FinancialStatementItemNodes.

        Raises:
            ReadError: If API key is missing/invalid, API request fails, or data format is unexpected.
        """
        ticker = source
        statement_type = kwargs.get("statement_type")
        period_type_arg = kwargs.get("period_type", "FY")
        limit = kwargs.get("limit", 50)
        self.api_key = kwargs.get("api_key", self.api_key)

        # --- Validate Inputs ---
        if not ticker or not isinstance(ticker, str):
            raise ReadError(
                "Invalid source (ticker) provided. Expected a non-empty string.",
                source=ticker,
                reader_type="FmpReader",
            )
        if statement_type not in ["income_statement", "balance_sheet", "cash_flow"]:
            raise ReadError(
                "Missing or invalid required argument: 'statement_type'. Must be one of: income_statement, balance_sheet, cash_flow.",
                source=ticker,
                reader_type="FmpReader",
            )
        if period_type_arg not in ["FY", "QTR"]:
            raise ReadError(
                "Invalid 'period_type'. Must be 'FY' or 'QTR'.",
                source=ticker,
                reader_type="FmpReader",
            )

        self._validate_api_key()  # Ensure API key is usable

        # Override mapping config if provided in kwargs
        current_mapping_config = kwargs.get("mapping_config", self.mapping_config)
        if not isinstance(current_mapping_config, dict):
            raise ReadError(
                "Invalid mapping_config provided.",
                source=ticker,
                reader_type="FmpReader",
            )
        self.mapping_config = current_mapping_config
        mapping = self._get_mapping(statement_type)
        logger.debug(f"Using mapping for {ticker} {statement_type}: {mapping}")

        # --- Fetch API Data ---
        # Correct endpoint construction based on FMP v3 docs
        # e.g., /income-statement/AAPL, not /income_statement-statement/AAPL
        endpoint_path = statement_type.replace("_", "-")
        endpoint = f"{self.BASE_URL}/{endpoint_path}/{ticker}"
        params = {"apikey": self.api_key, "limit": limit}
        if period_type_arg == "QTR":
            params["period"] = "quarter"

        try:
            logger.info(
                f"Fetching {period_type_arg} {statement_type} for {ticker} from FMP API (limit={limit})."
            )
            response = requests.get(endpoint, params=params, timeout=30)  # Increased timeout
            response.raise_for_status()  # Check for HTTP errors
            api_data = response.json()

            if not isinstance(api_data, list):
                raise ReadError(
                    f"Unexpected API response format. Expected list, got {type(api_data)}. Response: {str(api_data)[:100]}...",
                    source=f"FMP API ({ticker})",
                    reader_type="FmpReader",
                )
            if not api_data:
                logger.warning(f"FMP API returned empty list for {ticker} {statement_type}.")
                # Return empty graph or raise? Returning empty for now.
                return Graph(periods=[])

        except requests.exceptions.RequestException as e:
            logger.error(
                f"FMP API request failed for {ticker} {statement_type}: {e}",
                exc_info=True,
            )
            raise ReadError(
                f"FMP API request failed: {e}",
                source=f"FMP API ({ticker})",
                reader_type="FmpReader",
                original_error=e,
            )
        except Exception as e:
            logger.error(f"Failed to process FMP API response: {e}", exc_info=True)
            raise ReadError(
                f"Failed to process FMP API response: {e}",
                source=f"FMP API ({ticker})",
                reader_type="FmpReader",
                original_error=e,
            )

        # --- Process Data and Populate Graph ---
        try:
            # FMP data is usually newest first, reverse to process chronologically
            api_data.reverse()

            # Extract periods (e.g., 'date' or 'fillingDate')
            # Using 'date' as it usually represents the period end date
            periods = [item.get("date") for item in api_data if item.get("date")]
            if not periods:
                raise ReadError(
                    "Could not extract periods ('date' field) from FMP API response.",
                    source=f"FMP API ({ticker})",
                    reader_type="FmpReader",
                )

            graph = Graph(periods=periods)
            all_item_data: dict[str, dict[str, float]] = {}

            # Collect data for all items across all periods
            for period_data in api_data:
                period = period_data.get("date")
                if not period:
                    continue  # Skip records without a date

                for api_field, value in period_data.items():
                    node_name = mapping.get(api_field, api_field)  # Use mapping or fallback

                    # Initialize node data dict if first time seeing this node
                    if node_name not in all_item_data:
                        all_item_data[node_name] = {p: np.nan for p in periods}  # Pre-fill with NaN

                    # Store value for this period
                    if isinstance(value, (int, float)):
                        all_item_data[node_name][period] = float(value)

            # Create nodes from collected data
            nodes_added = 0
            for node_name, period_values in all_item_data.items():
                # Filter out periods that only have NaN
                valid_period_values = {p: v for p, v in period_values.items() if not np.isnan(v)}
                if valid_period_values:
                    new_node = FinancialStatementItemNode(
                        name=node_name, values=valid_period_values
                    )
                    graph.add_node(new_node)
                    nodes_added += 1

            logger.info(
                f"Successfully created graph with {nodes_added} nodes from FMP API for {ticker} {statement_type}."
            )
            return graph

        except Exception as e:
            logger.error(f"Failed to parse FMP data and build graph: {e}", exc_info=True)
            raise ReadError(
                message=f"Failed to parse FMP data: {e}",
                source=f"FMP API ({ticker})",
                reader_type="FmpReader",
                original_error=e,
            ) from e

# --- END FILE: fin_statement_model/io/readers/fmp.py ---

# --- START FILE: fin_statement_model/io/readers/dataframe.py ---
"""Data reader for pandas DataFrames."""

import logging
from typing import Optional, Any

import pandas as pd
import numpy as np

from fin_statement_model.core.graph import Graph
from fin_statement_model.core.nodes import FinancialStatementItemNode
from fin_statement_model.io.base import DataReader
from fin_statement_model.io.registry import register_reader
from fin_statement_model.io.exceptions import ReadError

logger = logging.getLogger(__name__)


@register_reader("dataframe")
class DataFrameReader(DataReader):
    """Reads data from a pandas DataFrame into a Graph.

    Assumes the DataFrame index contains node names and columns contain periods.
    Values should be numeric.
    """

    def __init__(self, mapping_config: Optional[dict[str, str]] = None):
        """Initialize the DataFrameReader.

        Args:
            mapping_config: Optional dictionary to map index names from the
                DataFrame to canonical node names. Format: {'DF Index Name': 'canonical_name'}
                Currently not implemented, index names are used directly.
        """
        # Mapping config is not used in this implementation, index names are used directly
        # Could be added later for renaming nodes during import
        self.mapping = mapping_config or {}
        if self.mapping:
            logger.warning("mapping_config is not currently used by DataFrameReader.")

    def read(self, source: pd.DataFrame, **kwargs: dict[str, Any]) -> Graph:
        """Read data from a pandas DataFrame into a new Graph.

        Assumes DataFrame index = node names, columns = periods.

        Args:
            source (pd.DataFrame): The DataFrame to read data from.
            **kwargs: Optional keyword arguments:
                 periods (list[str]): Explicit list of periods (columns) to include.
                                      If None, all columns are assumed to be periods.
                 mapping_config (dict): Overrides the mapping config (currently unused).

        Returns:
            A new Graph instance populated with FinancialStatementItemNodes.

        Raises:
            ReadError: If the source is not a DataFrame or has invalid structure.
        """
        df = source
        logger.info("Starting import from DataFrame.")

        # --- Validate Inputs ---
        if not isinstance(df, pd.DataFrame):
            raise ReadError(
                "Source is not a pandas DataFrame.",
                source="DataFrame",
                reader_type="DataFrameReader",
            )

        if df.index.name is None and df.index.empty:
            logger.warning(
                "DataFrame index is unnamed and empty, assuming columns are nodes if periods kwarg is provided."
            )
            # Handle case where DF might be oriented differently if periods kwarg is present?
            # For now, stick to index=nodes assumption.

        # Determine periods: use explicit list or infer from columns
        graph_periods_arg = kwargs.get("periods")
        if graph_periods_arg:
            if not isinstance(graph_periods_arg, list):
                raise ReadError("'periods' argument must be a list of column names.")
            missing_cols = [p for p in graph_periods_arg if p not in df.columns]
            if missing_cols:
                raise ReadError(
                    f"Specified periods (columns) not found in DataFrame: {missing_cols}"
                )
            graph_periods = sorted(graph_periods_arg)
            df_subset = df[graph_periods]  # Select only specified period columns
        else:
            # Assume all columns are periods
            graph_periods = sorted(df.columns.astype(str).tolist())
            df_subset = df

        if not graph_periods:
            raise ReadError(
                "No periods identified in DataFrame columns.",
                source="DataFrame",
                reader_type="DataFrameReader",
            )

        logger.info(f"Using periods (columns): {graph_periods}")
        graph = Graph(periods=graph_periods)

        # --- Populate Graph ---
        validation_errors = []
        nodes_added = 0
        for node_name_df, row in df_subset.iterrows():
            if pd.isna(node_name_df) or not node_name_df:
                logger.debug("Skipping row with empty index name.")
                continue

            node_name = str(node_name_df).strip()
            # Apply mapping here if implemented: node_name = self.mapping.get(node_name, node_name)

            period_values: dict[str, float] = {}
            for period in graph_periods:
                value = row[period]
                if pd.isna(value):
                    continue  # Skip NaN values

                if not isinstance(value, (int, float, np.number)):
                    try:
                        value = float(value)
                        logger.warning(
                            f"Converted non-numeric value '{row[period]}' to float for node '{node_name}' period '{period}'"
                        )
                    except (ValueError, TypeError):
                        validation_errors.append(
                            f"Node '{node_name}': Non-numeric value '{value}' for period '{period}'"
                        )
                        continue  # Skip invalid value

                period_values[period] = float(value)

            if period_values:
                if graph.has_node(node_name):
                    logger.warning(
                        f"Node '{node_name}' already exists. Overwriting data is not standard for readers."
                    )
                    # Update existing? Log for now.
                else:
                    new_node = FinancialStatementItemNode(name=node_name, values=period_values)
                    graph.add_node(new_node)
                    nodes_added += 1

        if validation_errors:
            raise ReadError(
                f"Validation errors occurred while reading DataFrame: {'; '.join(validation_errors)}",
                source="DataFrame",
                reader_type="DataFrameReader",
            )

        logger.info(f"Successfully created graph with {nodes_added} nodes from DataFrame.")
        return graph

        # No specific file operations, so less need for broad Exception catch
        # Specific errors handled above (TypeError, ValueError from float conversion)

# --- END FILE: fin_statement_model/io/readers/dataframe.py ---

# --- START FILE: fin_statement_model/io/readers/__init__.py ---
"""Data readers for various formats."""

# Import specific readers to ensure they are registered
from . import dict  # noqa: F401
from . import excel  # noqa: F401
from . import csv  # noqa: F401
from . import dataframe  # noqa: F401
from . import fmp  # noqa: F401

__all__ = [
    # Expose reader classes if needed directly, though using the facade is preferred
    # "DictReader",
    # "ExcelReader",
    # "CsvReader",
    # "DataFrameReader",
    # "FmpReader",
]

# --- END FILE: fin_statement_model/io/readers/__init__.py ---

# --- START FILE: fin_statement_model/io/readers/excel.py ---
"""Data reader for Excel files."""

import logging
import os
from typing import Optional, ClassVar, Any

import pandas as pd

from fin_statement_model.core.graph import Graph
from fin_statement_model.core.nodes import FinancialStatementItemNode
from fin_statement_model.io.base import DataReader
from fin_statement_model.io.registry import register_reader
from fin_statement_model.io.exceptions import ReadError

logger = logging.getLogger(__name__)


@register_reader("excel")
class ExcelReader(DataReader):
    """Reads financial statement data from an Excel file into a Graph.

    Expects data in a tabular format where rows typically represent items
    and columns represent periods, or vice-versa.
    Requires specifying sheet name, period identification, and item identification.
    """

    # Default field mappings (can be overridden in __init__)
    DEFAULT_INCOME_STATEMENT_MAPPING: ClassVar[dict[str, str]] = {
        "Revenue": "revenue",
        "Cost of Revenue": "cost_of_goods_sold",
        "Gross Profit": "gross_profit",
        # ... (Add other defaults as needed)
    }
    DEFAULT_BALANCE_SHEET_MAPPING: ClassVar[dict[str, str]] = {
        "Cash & Cash Equivalents": "cash_and_cash_equivalents",
        # ... (Add other defaults as needed)
    }
    DEFAULT_CASH_FLOW_MAPPING: ClassVar[dict[str, str]] = {
        "Net Income": "net_income",
        # ... (Add other defaults as needed)
    }

    # Default mappings from expected columns to potential Excel column names
    _REQUIRED_COLUMNS: ClassVar[dict[str, list[str]]] = {
        "item": ["Item", "Metric", "Account", "Financial Statement Line Item"],
    }
    # Optional config: mapping periods in file to standard internal names
    _OPTIONAL_COLUMNS: ClassVar[dict[str, list[str]]] = {
        "description": ["Description"],
    }
    # Default item name mapping
    _DEFAULT_MAPPING: ClassVar[dict[str, str]] = {}

    def __init__(self, column_mapping: Optional[dict[str, str]] = None, **kwargs: dict[str, Any]):
        """Initialize the ExcelReader.

        Args:
            column_mapping: Optional dictionary to map item names from the
                Excel file to canonical node names within the graph.
                Format: {'statement_type': {'Excel Name': 'canonical_name', ...}}
                Example: {'income_statement': {'Total Revenue': 'revenue'}}
                If None, default mappings might be applied based on statement_type
                kwarg in read().
            **kwargs: Additional keyword arguments forwarded to the base
                `DataReader` initializer. These may include reader-specific
                configuration options or metadata required by parent classes.
        """
        super().__init__(**kwargs)
        self.mapping_config = column_mapping or {}
        # Combine provided config with defaults if needed, or handle defaults in read()

    def _get_mapping(self, statement_type: Optional[str]) -> dict[str, str]:
        """Get the appropriate mapping based on statement type."""
        mapping = {}
        # Start with defaults based on type
        if statement_type == "income_statement":
            mapping.update(self.DEFAULT_INCOME_STATEMENT_MAPPING)
        elif statement_type == "balance_sheet":
            mapping.update(self.DEFAULT_BALANCE_SHEET_MAPPING)
        elif statement_type == "cash_flow":
            mapping.update(self.DEFAULT_CASH_FLOW_MAPPING)

        # Layer user-provided config on top
        if statement_type and statement_type in self.mapping_config:
            mapping.update(self.mapping_config[statement_type])
        elif None in self.mapping_config:  # Allow a default user mapping
            mapping.update(self.mapping_config[None])

        return mapping

    def read(self, source: str, **kwargs: dict[str, Any]) -> Graph:
        """Read data from an Excel file sheet into a new Graph.

        Args:
            source (str): Path to the Excel file.
            **kwargs: Required keyword arguments:
                sheet_name (str): Name of the sheet containing the data.
                periods_row (int): 1-based index of the row containing period headers.
                items_col (int): 1-based index of the column containing item names.
            Optional keyword arguments:
                statement_type (str): Type of statement ('income_statement', 'balance_sheet', 'cash_flow')
                                     Used to select default mappings if mapping_config is not exhaustive.
                header_row (int): 1-based index for pandas header reading (defaults to periods_row).
                                  Use if data headers differ from period headers.
                nrows (int): Number of rows to read from the sheet.
                skiprows (int): Number of rows to skip at the beginning.
                mapping_config (dict): Overrides the mapping config provided at init.

        Returns:
            A new Graph instance populated with FinancialStatementItemNodes.

        Raises:
            ReadError: If the file cannot be read, sheet/row/col are invalid, or required kwargs missing.
        """
        file_path = source
        logger.info(f"Starting import from Excel file: {file_path}")

        # --- Validate Inputs ---
        if not os.path.exists(file_path):
            raise ReadError(
                f"File not found: {file_path}",
                source=file_path,
                reader_type="ExcelReader",
            )
        if not file_path.endswith((".xls", ".xlsx", ".xlsm")):
            raise ReadError(
                f"Not a valid Excel file extension: {file_path}",
                source=file_path,
                reader_type="ExcelReader",
            )

        sheet_name = kwargs.get("sheet_name")
        periods_row_0idx = (
            kwargs.get("periods_row") - 1 if kwargs.get("periods_row") else None
        )  # 0-based for pandas
        items_col_0idx = (
            kwargs.get("items_col") - 1 if kwargs.get("items_col") else None
        )  # 0-based for pandas
        header_row_0idx = (
            kwargs.get("header_row") - 1 if kwargs.get("header_row") else periods_row_0idx
        )

        if sheet_name is None or periods_row_0idx is None or items_col_0idx is None:
            raise ReadError(
                "Missing required arguments: 'sheet_name', 'periods_row', 'items_col' must be provided.",
                source=file_path,
                reader_type="ExcelReader",
            )

        statement_type = kwargs.get("statement_type")
        nrows = kwargs.get("nrows")
        skiprows = kwargs.get("skiprows")

        # Override mapping config if provided in kwargs
        current_mapping_config = kwargs.get("mapping_config", self.mapping_config)
        if not isinstance(current_mapping_config, dict):
            raise ReadError(
                "Invalid mapping_config provided.",
                source=file_path,
                reader_type="ExcelReader",
            )
        self.mapping_config = current_mapping_config  # Update instance mapping if overridden
        mapping = self._get_mapping(statement_type)
        logger.debug(f"Using mapping for statement type '{statement_type}': {mapping}")

        # --- Read Excel Data ---
        try:
            # Read the sheet, potentially skipping rows and limiting rows read
            # Use header_row_0idx to correctly identify column headers
            df = pd.read_excel(
                file_path,
                sheet_name=sheet_name,
                header=header_row_0idx,
                skiprows=skiprows,  # skiprows is applied *before* header selection
                nrows=nrows,
            )

            # Identify the actual period columns based on the periods_row
            # Read the periods row separately if header is different
            if header_row_0idx != periods_row_0idx:
                periods_df = pd.read_excel(
                    file_path,
                    sheet_name=sheet_name,
                    header=None,
                    skiprows=periods_row_0idx,
                    nrows=1,
                )
                period_headers = periods_df.iloc[0].astype(str).tolist()
            else:
                # Periods are in the main header row read by pandas
                period_headers = df.columns.astype(str).tolist()

            # Find the item column name from the initial read
            if items_col_0idx >= len(df.columns):
                raise ReadError(
                    f"items_col index ({items_col_0idx + 1}) is out of bounds for sheet '{sheet_name}'. Found columns: {df.columns.tolist()}",
                    source=file_path,
                    reader_type="ExcelReader",
                )
            # item_column_name = df.columns[items_col_0idx] # This variable is assigned but never used.

            # Filter period headers: exclude the item column header itself
            # Assuming periods start *after* the item column typically
            graph_periods = [p for i, p in enumerate(period_headers) if i > items_col_0idx and p]
            if not graph_periods:
                raise ReadError(
                    f"Could not identify period columns in row {periods_row_0idx + 1} after column {items_col_0idx + 1} in sheet '{sheet_name}'. Headers found: {period_headers}",
                    source=file_path,
                    reader_type="ExcelReader",
                )
            logger.info(f"Identified periods: {graph_periods}")

            # Create graph
            graph = Graph(periods=graph_periods)

            # --- Populate Graph ---
            validation_errors = []
            nodes_added = 0
            for index, row in df.iterrows():
                item_name_excel = row.iloc[
                    items_col_0idx
                ]  # Get item name using the identified column
                if pd.isna(item_name_excel) or not item_name_excel:
                    # logger.debug(f"Skipping row {index + (skiprows or 0) + (header_row_0idx or 0) + 1}: Empty item name.")
                    continue

                item_name_excel = str(item_name_excel).strip()
                node_name = mapping.get(
                    item_name_excel, item_name_excel
                )  # Use mapping or fallback to original name

                # Get values for the identified periods
                period_values: dict[str, float] = {}
                for period in graph_periods:
                    try:
                        # Find the corresponding column in the DataFrame using the period header
                        # This assumes the period headers read initially match the df columns
                        if period in df.columns:
                            value = row[period]
                            if pd.isna(value):
                                # Keep NaN or skip? For now, skip. Could represent as None or NaN later.
                                # logger.debug(f"NaN value for {node_name} period {period}")
                                continue
                            elif isinstance(value, (int, float)):
                                period_values[period] = float(value)
                            else:
                                # Attempt conversion, log warning if fails
                                try:
                                    period_values[period] = float(value)
                                    logger.warning(
                                        f"Converted non-numeric value '{value}' to float for node '{node_name}' period '{period}'"
                                    )
                                except (ValueError, TypeError):
                                    validation_errors.append(
                                        f"Row {index}: Non-numeric value '{value}' for node '{node_name}' (from '{item_name_excel}') period '{period}'"
                                    )
                        else:
                            # This shouldn't happen if period_headers came from df.columns
                            logger.warning(
                                f"Period header '{period}' not found in DataFrame columns for row {index}."
                            )
                    except KeyError:
                        validation_errors.append(
                            f"Row {index}: Column for period '{period}' not found for node '{node_name}'"
                        )
                    except Exception as e:
                        validation_errors.append(
                            f"Row {index}: Error processing value for node '{node_name}' period '{period}': {e}"
                        )

                if period_values:
                    if graph.has_node(node_name):
                        logger.warning(
                            f"Node '{node_name}' (from Excel item '{item_name_excel}') already exists. Overwriting data is not standard for readers. Consider unique names or merging logic."
                        )
                        # Get existing node and update? Or raise error? For now, log warning.
                        # existing_node = graph.get_node(node_name)
                        # if isinstance(existing_node, FinancialStatementItemNode):
                        #     existing_node.values.update(period_values)
                    else:
                        # Create and add new node
                        new_node = FinancialStatementItemNode(name=node_name, values=period_values)
                        graph.add_node(new_node)
                        nodes_added += 1
                # else: No valid values for this item in the specified periods

            if validation_errors:
                raise ReadError(
                    f"Validation errors occurred while reading {file_path} sheet '{sheet_name}': {'; '.join(validation_errors)}",
                    source=file_path,
                    reader_type="ExcelReader",
                )

            logger.info(
                f"Successfully created graph with {nodes_added} nodes from {file_path} sheet '{sheet_name}'."
            )
            return graph

        except FileNotFoundError:
            raise ReadError(
                f"File not found: {file_path}",
                source=file_path,
                reader_type="ExcelReader",
            )
        except ValueError as ve:
            # Pandas raises ValueError for bad sheet names etc.
            raise ReadError(
                f"Error reading Excel file: {ve}",
                source=file_path,
                reader_type="ExcelReader",
                original_error=ve,
            )
        except KeyError as ke:
            # Raised if essential columns (like item column after mapping) are missing
            raise ReadError(
                f"Missing expected column/item: {ke}. Check items_col ({items_col_0idx + 1}) and sheet structure.",
                source=file_path,
                reader_type="ExcelReader",
                original_error=ke,
            )
        except Exception as e:
            logger.error(
                f"Failed to read Excel file {file_path} sheet '{sheet_name}': {e}",
                exc_info=True,
            )
            raise ReadError(
                message=f"Failed to process Excel file: {e}",
                source=file_path,
                reader_type="ExcelReader",
                original_error=e,
            ) from e

# --- END FILE: fin_statement_model/io/readers/excel.py ---

# --- START FILE: fin_statement_model/io/readers/csv.py ---
"""Data reader for CSV files."""

import logging
import os
from typing import Optional, Any

import pandas as pd

from fin_statement_model.core.graph import Graph
from fin_statement_model.core.nodes import FinancialStatementItemNode
from fin_statement_model.io.base import DataReader
from fin_statement_model.io.registry import register_reader
from fin_statement_model.io.exceptions import ReadError

logger = logging.getLogger(__name__)


@register_reader("csv")
class CsvReader(DataReader):
    """Reads financial statement data from a CSV file into a Graph.

    Assumes a 'long' format where each row represents a single data point
    (item, period, value).
    Requires specifying the columns containing item names, period identifiers,
    and values.
    """

    def __init__(self, mapping_config: Optional[dict[str, str]] = None):
        """Initialize the CsvReader.

        Args:
            mapping_config: Optional dictionary to map item names from the
                CSV file to canonical node names. Format: {'CSV Name': 'canonical_name'}
        """
        # Simple 1-level mapping {csv_item_name: canonical_node_name}
        self.mapping = mapping_config or {}

    def read(self, source: str, **kwargs: dict[str, Any]) -> Graph:
        """Read data from a CSV file into a new Graph.

        Args:
            source (str): Path to the CSV file.
            **kwargs: Required keyword arguments:
                item_col (str): Name of the column containing item identifiers.
                period_col (str): Name of the column containing period identifiers.
                value_col (str): Name of the column containing numeric values.
            Optional keyword arguments:
                mapping_config (dict): Overrides the mapping config provided at init.
                pandas_read_csv_kwargs (dict): Additional kwargs passed directly to
                                                pandas.read_csv().

        Returns:
            A new Graph instance populated with FinancialStatementItemNodes.

        Raises:
            ReadError: If the file cannot be read or required columns are missing.
        """
        file_path = source
        logger.info(f"Starting import from CSV file: {file_path}")

        # --- Validate Inputs ---
        if not os.path.exists(file_path):
            raise ReadError(
                f"File not found: {file_path}",
                source=file_path,
                reader_type="CsvReader",
            )

        item_col = kwargs.get("item_col")
        period_col = kwargs.get("period_col")
        value_col = kwargs.get("value_col")
        read_csv_options = kwargs.get("pandas_read_csv_kwargs", {})

        if not item_col or not period_col or not value_col:
            raise ReadError(
                "Missing required arguments: 'item_col', 'period_col', 'value_col' must be provided.",
                source=file_path,
                reader_type="CsvReader",
            )

        # Override mapping config if provided in kwargs
        current_mapping_config = kwargs.get("mapping_config", self.mapping)
        if not isinstance(current_mapping_config, dict):
            raise ReadError(
                "Invalid mapping_config provided.",
                source=file_path,
                reader_type="CsvReader",
            )
        self.mapping = current_mapping_config
        logger.debug(f"Using mapping: {self.mapping}")

        # --- Read CSV Data ---
        try:
            df = pd.read_csv(file_path, **read_csv_options)

            # Validate required columns exist
            required_cols = {item_col, period_col, value_col}
            missing_cols = required_cols - set(df.columns)
            if missing_cols:
                raise ReadError(
                    f"Missing required columns in CSV: {missing_cols}",
                    source=file_path,
                    reader_type="CsvReader",
                )

            # Convert period column to string
            df[period_col] = df[period_col].astype(str)
            all_periods = sorted(df[period_col].unique().tolist())
            if not all_periods:
                raise ReadError(
                    "No periods found in the specified period column.",
                    source=file_path,
                    reader_type="CsvReader",
                )

            logger.info(f"Identified periods: {all_periods}")
            graph = Graph(periods=all_periods)

            # --- Populate Graph ---
            # Group data by item name
            grouped = df.groupby(item_col)
            validation_errors = []
            nodes_added = 0

            for item_name_csv, group in grouped:
                if pd.isna(item_name_csv) or not item_name_csv:
                    logger.debug("Skipping group with empty item name.")
                    continue

                item_name_csv_str = str(item_name_csv).strip()
                node_name = self.mapping.get(item_name_csv_str, item_name_csv_str)

                period_values: dict[str, float] = {}
                for _, row in group.iterrows():
                    period = row[period_col]
                    value = row[value_col]

                    if pd.isna(value):
                        continue  # Skip missing values

                    if not isinstance(value, (int, float)):
                        try:
                            value = float(value)
                            logger.warning(
                                f"Converted non-numeric value '{row[value_col]}' to float for node '{node_name}' period '{period}'"
                            )
                        except (ValueError, TypeError):
                            validation_errors.append(
                                f"Item '{item_name_csv_str}': Non-numeric value '{value}' for period '{period}'"
                            )
                            continue  # Skip this invalid value

                    if period in period_values:
                        logger.warning(
                            f"Duplicate value found for node '{node_name}' (from CSV item '{item_name_csv_str}') period '{period}'. Using the last one found."
                        )

                    period_values[period] = float(value)

                if period_values:
                    if graph.has_node(node_name):
                        logger.warning(
                            f"Node '{node_name}' (from CSV item '{item_name_csv_str}') already exists. Overwriting data is not standard for readers."
                        )
                        # Potentially update existing node? For now, log.
                    else:
                        new_node = FinancialStatementItemNode(name=node_name, values=period_values)
                        graph.add_node(new_node)
                        nodes_added += 1

            if validation_errors:
                raise ReadError(
                    f"Validation errors occurred while reading {file_path}: {'; '.join(validation_errors)}",
                    source=file_path,
                    reader_type="CsvReader",
                )

            logger.info(f"Successfully created graph with {nodes_added} nodes from {file_path}.")
            return graph

        except FileNotFoundError:
            raise ReadError(
                f"File not found: {file_path}",
                source=file_path,
                reader_type="CsvReader",
            )
        except ValueError as ve:
            raise ReadError(
                f"Error reading CSV file: {ve}",
                source=file_path,
                reader_type="CsvReader",
                original_error=ve,
            )
        except KeyError as ke:
            raise ReadError(
                f"Column not found error (check item/period/value_col names): {ke}",
                source=file_path,
                reader_type="CsvReader",
                original_error=ke,
            )
        except Exception as e:
            logger.error(f"Failed to read CSV file {file_path}: {e}", exc_info=True)
            raise ReadError(
                message=f"Failed to process CSV file: {e}",
                source=file_path,
                reader_type="CsvReader",
                original_error=e,
            ) from e

# --- END FILE: fin_statement_model/io/readers/csv.py ---

# --- START FILE: fin_statement_model/io/readers/dict.py ---
"""Data reader for Python dictionaries."""

import logging
from typing import Any

from fin_statement_model.core.graph import Graph
from fin_statement_model.core.nodes import FinancialStatementItemNode
from fin_statement_model.io.base import DataReader
from fin_statement_model.io.registry import register_reader
from fin_statement_model.io.exceptions import ReadError  # Removed DataValidationError

logger = logging.getLogger(__name__)


@register_reader("dict")
class DictReader(DataReader):
    """Reads data from a Python dictionary to create a new Graph.

    Expects a dictionary format: {node_name: {period: value, ...}, ...}
    Creates FinancialStatementItemNode instances for each entry.
    """

    def read(self, source: dict[str, dict[str, float]], **kwargs: dict[str, Any]) -> Graph:
        """Create a new Graph from a dictionary.

        Args:
            source: Dictionary mapping node names to period-value dictionaries.
                    Format: {node_name: {period: value, ...}, ...}
            **kwargs: Optional arguments:
                periods (list[str]): Explicit list of periods for the new graph.
                                     If None, inferred from data keys.

        Returns:
            A new Graph instance populated with FinancialStatementItemNodes.

        Raises:
            ReadError: If the source data format is invalid or processing fails.
            # DataValidationError: If data values are not numeric.
        """
        logger.info("Starting import from dictionary to create a new graph.")

        if not isinstance(source, dict):
            raise ReadError(
                message="Invalid source type for DictReader. Expected dict.",
                source="dict_input",
                reader_type="DictReader",
            )

        # Validate data structure and collect all periods
        all_periods = set()
        validation_errors = []
        try:
            for node_name, period_values in source.items():
                if not isinstance(period_values, dict):
                    validation_errors.append(
                        f"Node '{node_name}': Invalid format - expected dict, got {type(period_values).__name__}"
                    )
                    continue  # Skip further checks for this node
                for period, value in period_values.items():
                    # Basic type checks - can be expanded
                    if not isinstance(period, str):
                        validation_errors.append(
                            f"Node '{node_name}': Invalid period format '{period}' - expected string."
                        )
                    if not isinstance(value, (int, float)):
                        validation_errors.append(
                            f"Node '{node_name}' period '{period}': Invalid value type {type(value).__name__} - expected number."
                        )
                    all_periods.add(str(period))

            if validation_errors:
                # Use core DataValidationError if it exists and is suitable
                # Otherwise, stick to ReadError or a specific IOValidationError
                # raise DataValidationError(
                #     message="Input dictionary failed validation",
                #     validation_errors=validation_errors
                # )
                raise ReadError(
                    f"Input dictionary failed validation: {'; '.join(validation_errors)}",
                    source="dict_input",
                    reader_type="DictReader",
                )

        except Exception as e:
            # Catch unexpected validation errors
            raise ReadError(
                message=f"Error validating input dictionary: {e}",
                source="dict_input",
                reader_type="DictReader",
                original_error=e,
            ) from e

        # Determine graph periods
        graph_periods = kwargs.get("periods")
        if graph_periods is None:
            graph_periods = sorted(list(all_periods))
            logger.debug(f"Inferred graph periods from data: {graph_periods}")
        # Optional: Validate if all data periods are within the provided list
        elif not all_periods.issubset(set(graph_periods)):
            missing = all_periods - set(graph_periods)
            logger.warning(f"Data contains periods not in specified graph periods: {missing}")
            # Decide whether to error or just ignore extra data

        # Create graph and add nodes
        try:
            graph = Graph(periods=graph_periods)
            for node_name, period_values in source.items():
                # Filter values to only include those matching graph_periods
                filtered_values = {p: v for p, v in period_values.items() if p in graph_periods}
                if filtered_values:
                    # Create FinancialStatementItemNode directly
                    # Assumes FinancialStatementItemNode takes name and values dict
                    new_node = FinancialStatementItemNode(
                        name=node_name, values=filtered_values.copy()
                    )
                    graph.add_node(new_node)
                else:
                    logger.debug(
                        f"Node '{node_name}' has no data for specified graph periods. Skipping."
                    )

            logger.info(
                f"Successfully created graph with {len(graph.nodes)} nodes from dictionary."
            )
            return graph

        except Exception as e:
            # Catch errors during graph/node creation
            logger.error(f"Failed to create graph from dictionary: {e}", exc_info=True)
            raise ReadError(
                message="Failed to build graph from dictionary data",
                source="dict_input",
                reader_type="DictReader",
                original_error=e,
            ) from e

# --- END FILE: fin_statement_model/io/readers/dict.py ---

# --- START FILE: fin_statement_model/io/base.py ---
"""Base classes for data readers and writers."""

from abc import ABC, abstractmethod
from typing import Any

# Use absolute import based on project structure
from fin_statement_model.core.graph import Graph


class DataReader(ABC):
    """Abstract base class for all data readers.

    Defines the interface for classes that read data from various sources
    and typically populate or return a Graph object.
    """

    @abstractmethod
    def read(self, source: str, **kwargs: dict[str, Any]) -> Graph:
        """Read data from the specified source and return a Graph.

        Args:
            source: The data source (e.g., file path, API endpoint, dict).
            **kwargs: Additional format-specific options for reading.

        Returns:
            A Graph object populated with the data from the source.

        Raises:
            ReadError: If an error occurs during the reading process.
            NotImplementedError: If the method is not implemented by a subclass.
        """
        raise NotImplementedError


class DataWriter(ABC):
    """Abstract base class for all data writers.

    Defines the interface for classes that write graph data to various targets.
    """

    @abstractmethod
    def write(self, graph: Graph, target: object, **kwargs: dict[str, Any]) -> object:
        """Write data from the Graph object to the specified target.

        Args:
            graph: The Graph object containing the data to write.
            target: The destination target (e.g., file path, database connection).
            **kwargs: Additional format-specific options for writing.

        Raises:
            WriteError: If an error occurs during the writing process.
            NotImplementedError: If the method is not implemented by a subclass.
        """
        raise NotImplementedError

# --- END FILE: fin_statement_model/io/base.py ---

# --- START FILE: fin_statement_model/__init__.py ---
"""finlib - A Python library for financial statement analysis and forecasting."""

__all__ = [
    "CurveGrowthForecastNode",
    "CustomGrowthForecastNode",
    "FinancialStatementGraph",
    "FinancialStatementItemNode",
    "FixedGrowthForecastNode",
    "ForecastNode",
    "Graph",
    "LLMClient",
    "LLMConfig",
    "MetricCalculationNode",
    "MultiPeriodStatNode",
    "Node",
    "StatisticalGrowthForecastNode",
    "StrategyCalculationNode",
    "YoYGrowthNode",
    "create_financial_statement",
]

from .extensions.llm.llm_client import LLMClient, LLMConfig
from .core.graph import Graph
from .core.nodes import (
    Node,
    FinancialStatementItemNode,
    StrategyCalculationNode,
    MetricCalculationNode,
    YoYGrowthNode,
    MultiPeriodStatNode,
    ForecastNode,
    FixedGrowthForecastNode,
    CurveGrowthForecastNode,
    StatisticalGrowthForecastNode,
    CustomGrowthForecastNode,
)
from .statements import FinancialStatementGraph
from .statements.importer.cell_importer import (
    import_from_cells as create_financial_statement,
)

# ensure our library-wide logging policy is applied immediately
from . import logging_config  # noqa: F401

# --------------------------------------------------------------------------
# Optional Extensions (via entry points / importlib.metadata)
# --------------------------------------------------------------------------
# Extensions are optional modules that add functionality without modifying
# the core library. They might depend on heavy libraries (e.g., LLMs,
# ML frameworks) and should be lazy-loaded.
# Example entry point group: 'fin_statement_model.extensions.reporting'
# Expected interface: TBD (e.g., a class with specific methods)
# Note: Avoid hard imports from extensions into core/statements/io.
# Goal: Keep core library lean, allow users to install extras like:
# pip install fin-statement-model[openai]
# pip install fin-statement-model[reporting-tools]
# --------------------------------------------------------------------------


# Core API Exports (ensure essential classes/functions are accessible)
# Example:
# from .core.graph import Graph
# from .core.nodes import Node, FinancialStatementItemNode
# from .core.calculation_engine import CalculationEngine
# from .statements.manager import StatementManager

# Placeholder: Explicitly list key public API components later.
# For now, just rely on sub-package __init__ files if they exist.

__version__ = "0.1.0"  # Central version definition

# --- END FILE: fin_statement_model/__init__.py ---

# --- START FILE: fin_statement_model/extensions/llm/__init__.py ---
"""LLM extension subpackage for fin_statement_model.

Provides built-in OpenAI-based LLM client extension for generating and injecting content.
"""

# --- END FILE: fin_statement_model/extensions/llm/__init__.py ---

# --- START FILE: fin_statement_model/extensions/llm/llm_client.py ---
"""LLM client module for OpenAI and backoff integration.

This module provides `LLMConfig` for client configuration and `LLMClient` for
asynchronous interactions with OpenAI's ChatCompletion API, including retry logic.
"""

import logging
import openai
import backoff
from dataclasses import dataclass
from typing import Optional, Any
from types import TracebackType

logger = logging.getLogger(__name__)


@dataclass
class LLMConfig:
    """Configuration data for LLMClient.

    Attributes:
        api_key: API key for OpenAI authentication.
        model_name: Model to use (e.g., 'gpt-4o').
        temperature: Sampling temperature setting.
        max_tokens: Maximum tokens to generate.
        timeout: Request timeout in seconds.
        max_retries: Number of retries on failure.
    """

    api_key: str
    model_name: str = "gpt-4o"
    temperature: float = 0.7
    max_tokens: int = 1500
    timeout: int = 30
    max_retries: int = 3
    # base_url is no longer needed as the openai library handles the endpoint configuration.


class LLMClientError(Exception):
    """Base exception for LLM client errors."""


class LLMTimeoutError(LLMClientError):
    """Exception for timeout errors."""


class LLMClient:
    """Asynchronous client for OpenAI ChatCompletion API with retry logic.

    Utilizes `LLMConfig` and supports retries on rate limits and timeouts.

    Methods:
        _make_api_call: Internal method for performing the API call with retry logic.
        get_completion: High-level method to obtain chat completions.
    """

    def __init__(self, config: Optional[LLMConfig] = None):
        """Initialize the async LLM client with configuration."""
        self.config = config or LLMConfig(api_key="")
        openai.api_key = self.config.api_key

    @backoff.on_exception(
        backoff.expo,
        (Exception, LLMTimeoutError),
        max_tries=3,
        giveup=lambda e: isinstance(e, LLMTimeoutError),
    )
    @backoff.on_exception(backoff.expo, openai.RateLimitError, max_tries=8)
    async def _make_api_call(self, messages: list[dict[str, str]]) -> dict[str, Any]:
        """Make the async API call to OpenAI with retry logic.

        Args:
            messages: List of message dicts for the ChatCompletion API

        Returns:
            Dict containing the API response

        Raises:
            LLMClientError: For any client-related errors, including timeout if applicable
        """
        try:
            logger.debug(f"Sending async request to OpenAI API with model {self.config.model_name}")
            response = await openai.ChatCompletion.acreate(
                model=self.config.model_name,
                messages=messages,
                temperature=self.config.temperature,
                max_tokens=self.config.max_tokens,
                timeout=self.config.timeout,
            )

            if not response.get("choices"):
                logger.error("No suggestions received from OpenAI API")
                raise LLMClientError("No suggestions received from API")

            return response
        except Exception as e:
            if "timeout" in str(e).lower():
                logger.exception("Async request timed out")
                raise LLMTimeoutError("Request timed out") from e
            logger.exception("OpenAI async API request failed")
            raise LLMClientError(f"API request failed: {e!s}") from e

    async def get_completion(self, messages: list[dict[str, str]]) -> str:
        """Get a completion result from the LLM using async API.

        Args:
            messages: List of message dictionaries for the ChatCompletion API

        Returns:
            str: The suggested completion from the LLM

        Raises:
            LLMClientError: For any client-related errors
        """
        try:
            logger.info("Requesting completion from OpenAI async API")
            response = await self._make_api_call(messages)
            completion = response["choices"][0]["message"]["content"].strip()
            logger.info("Successfully received completion")
            return completion
        except Exception as e:
            logger.exception("Error getting completion")
            raise LLMClientError(f"Failed to get completion: {e!s}") from e

    async def __aenter__(self) -> "LLMClient":
        """Enter the asynchronous context manager, returning the client."""
        return self

    async def __aexit__(
        self,
        exc_type: Optional[type[BaseException]],
        exc: Optional[BaseException],
        tb: Optional[TracebackType],
    ) -> None:
        """Exit the asynchronous context manager, performing cleanup."""
        # Ensure method has a body

# --- END FILE: fin_statement_model/extensions/llm/llm_client.py ---

# --- START FILE: fin_statement_model/extensions/__init__.py ---
"""Extensions package for fin_statement_model.

This package hosts optional in-repo extensions and third-party plugins discovered via entry-points under
`fin_statement_model.extensions`.
"""

# --- END FILE: fin_statement_model/extensions/__init__.py ---

# --- START FILE: fin_statement_model/statements/formatter.py ---
"""Statement formatter for Financial Statement Model.

This module provides utilities for formatting financial statement data,
including converting statements to DataFrames or HTML.
"""

import logging
from typing import Any, Union, Optional
import pandas as pd

from fin_statement_model.core.errors import DataValidationError
from .structure import (
    StatementStructure,
    Section,
    LineItem,
    CalculatedLineItem,
    SubtotalLineItem,
    StatementItem,
)

# Configure logging
logger = logging.getLogger(__name__)


class StatementFormatter:
    """Formats financial statement data into various representations.

    This class handles the conversion of financial statement data into
    DataFrames, HTML, and other formats. It also provides utilities for
    validating calculations and checking dependencies.
    """

    def __init__(self, statement: StatementStructure):
        """Initialize a statement formatter.

        Args:
            statement: The statement structure to format
        """
        self.statement = statement

    def generate_dataframe(
        self,
        data: dict[str, dict[str, float]],
        apply_sign_convention: bool = True,
        include_empty_items: bool = False,
    ) -> pd.DataFrame:
        """Generate a DataFrame representation of the statement.

        Args:
            data: Dictionary mapping node IDs to period values
            apply_sign_convention: Whether to apply sign conventions
            include_empty_items: Whether to include items with no data

        Returns:
            pd.DataFrame: DataFrame representation of the statement

        Raises:
            DataValidationError: If the data is invalid for the statement
        """
        # Validate data
        try:
            self.validate_calculations(data)
        except DataValidationError:
            # Re-raise any validation errors
            raise
        except Exception as e:
            logger.exception("Unexpected error validating calculations")
            raise DataValidationError(
                message="Statement data validation failed",
                validation_errors=[f"Unexpected error: {e!s}"],
            ) from e

        # Get all periods from the data
        periods = set()
        for values in data.values():
            periods.update(values.keys())
        periods = sorted(periods)

        # Create DataFrame columns
        columns = ["Item", "Name"]
        columns.extend(periods)

        # Create rows
        rows = []
        try:
            self._generate_dataframe_rows(
                self.statement,
                data,
                rows,
                periods,
                0,
                apply_sign_convention,
                include_empty_items,
            )
        except Exception as e:  # pragma: no cover
            logger.exception("Error generating DataFrame rows")
            raise DataValidationError(
                message="Failed to generate DataFrame",
                validation_errors=[f"Error generating rows: {e!s}"],
            ) from e

        # Create and return DataFrame
        if not rows:
            return pd.DataFrame(columns=columns)
        return pd.DataFrame(rows, columns=columns)

    def _generate_dataframe_rows(
        self,
        item: Union[StatementStructure, Section, StatementItem],
        data: dict[str, dict[str, float]],
        rows: list[list[Any]],
        periods: list[str],
        level: int,
        apply_sign_convention: bool = True,
        include_empty_items: bool = False,
    ) -> None:
        """Recursively generate rows for the DataFrame.

        Args:
            item: The statement structure item to generate rows for
            data: Dictionary mapping node IDs to period values
            rows: List of rows to append to
            periods: List of periods to include
            level: Current nesting level
            apply_sign_convention: Whether to apply sign conventions
            include_empty_items: Whether to include items with no data
        """
        # Add section or statement header
        if isinstance(item, (StatementStructure, Section)):
            # Add header row
            indent = " " * (level * 2)
            row = [f"{indent}{item.id}", item.name]

            # Add empty values for periods
            row.extend([""] * len(periods))
            rows.append(row)

            # Add nested items
            for child in item.items:
                self._generate_dataframe_rows(
                    child,
                    data,
                    rows,
                    periods,
                    level + 1,
                    apply_sign_convention,
                    include_empty_items,
                )

        # Add line item
        elif isinstance(item, LineItem):
            # Skip empty items if not including them
            has_data = False
            if isinstance(item, (CalculatedLineItem, SubtotalLineItem)):
                # For calculated items, check if the item's ID is a node in the data
                has_data = item.id in data
            else:
                # For regular items, check if the node_id is in the data
                has_data = item.node_id in data

            if not has_data and not include_empty_items:
                return

            # Add line item row
            indent = " " * (level * 2)
            row = [f"{indent}{item.id}", item.name]

            # Add values for each period
            for period in periods:
                value = None

                # Get value based on item type
                if isinstance(item, (CalculatedLineItem, SubtotalLineItem)):
                    # For calculated items, use the item's ID
                    if item.id in data and period in data[item.id]:
                        value = data[item.id][period]
                # For regular items, use the node_id
                elif item.node_id in data and period in data[item.node_id]:
                    value = data[item.node_id][period]

                # Apply sign convention if enabled
                if value is not None and apply_sign_convention and item.sign_convention == -1:
                    value = -value

                # Format the value
                if value is None:
                    row.append("")
                elif pd.isna(value):
                    row.append("NaN")  # pragma: no cover
                else:
                    row.append(value)

            rows.append(row)

    def format_html(
        self,
        data: dict[str, dict[str, float]],
        apply_sign_convention: bool = True,
        include_empty_items: bool = False,
        css_styles: Optional[dict[str, str]] = None,
    ) -> str:
        """Generate an HTML representation of the statement.

        Args:
            data: Dictionary mapping node IDs to period values
            apply_sign_convention: Whether to apply sign conventions
            include_empty_items: Whether to include items with no data
            css_styles: Custom CSS styles for the HTML

        Returns:
            str: HTML representation of the statement

        Raises:
            DataValidationError: If the data is invalid for the statement
        """
        html_content = ""
        try:
            # Generate DataFrame
            df = self.generate_dataframe(
                data,
                apply_sign_convention=apply_sign_convention,
                include_empty_items=include_empty_items,
            )

            # Define default CSS styles
            default_styles = {
                "table": "border-collapse: collapse; width: 100%; font-family: Arial, sans-serif;",
                "th": (
                    "background-color: #f2f2f2; border: 1px solid #ddd; padding: 8px; "
                    "text-align: left;"
                ),
                "td": "border: 1px solid #ddd; padding: 8px;",
                "tr:nth-child(even)": "background-color: #f9f9f9;",
                ".section": "font-weight: bold;",
                ".subtotal": "font-weight: bold; border-top: 2px solid #ddd;",
                ".total": (
                    "font-weight: bold; border-top: 2px solid #000; border-bottom: 2px solid #000;"
                ),
            }

            # Merge with custom styles
            styles = default_styles
            if css_styles:
                styles.update(css_styles)

            # Generate CSS
            css = "\n".join([f"{selector} {{ {style} }}" for selector, style in styles.items()])

            # Convert DataFrame to HTML table string
            if df.empty:
                html_table = "<p>(Statement is empty)</p>"
            else:
                html_table = df.to_html(index=False, na_rep="")

            # Construct the final HTML string with title, style, and table
            html_content = f"""
            <style>
            {css}
            </style>
            <h2>{self.statement.name}</h2>
            {html_table}
            """

        except Exception as e:  # pragma: no cover
            if isinstance(e, DataValidationError):
                raise
            else:
                logger.exception("Error formatting statement as HTML")
                raise DataValidationError(
                    message="Failed to format statement as HTML",
                    validation_errors=[f"Formatting error: {e!s}"],
                ) from e

        return html_content

    def get_calculation_dependencies(self) -> dict[str, set[str]]:
        """Get the calculation dependencies for the statement.

        Returns:
            Dict[str, Set[str]]: Dictionary mapping item IDs to sets of dependency IDs
        """
        dependencies = {}

        # Get all calculation items
        calc_items = self.statement.get_calculation_items()

        # Build dependency map
        for item in calc_items:
            if isinstance(item, (CalculatedLineItem, SubtotalLineItem)):
                dependencies[item.id] = set(item.input_ids)

        return dependencies

    def validate_calculations(self, data: dict[str, dict[str, float]]) -> None:
        """Validate that all calculation dependencies are satisfied.

        Args:
            data: Dictionary mapping node IDs to period values

        Raises:
            DataValidationError: If any dependencies are not satisfied
        """
        # Get dependencies
        dependencies = self.get_calculation_dependencies()

        # Check each calculation item
        errors = []

        for item_id, deps in dependencies.items():
            # Check if the calculation result is in the data
            if item_id not in data:
                errors.append(f"Calculation result '{item_id}' is missing from data")
                continue

            # Check if all dependencies are in the data
            # Use list comprehension for PERF401
            missing_deps = [dep_id for dep_id in deps if dep_id not in data]

            if missing_deps:
                errors.append(
                    f"Missing dependencies for calculation '{item_id}': {', '.join(missing_deps)}"
                )

        # Raise exception if there are errors
        if errors:
            raise DataValidationError(
                message="Statement calculation validation failed",
                validation_errors=errors,
            )

# --- END FILE: fin_statement_model/statements/formatter.py ---

# --- START FILE: fin_statement_model/statements/importer/cell_importer.py ---
"""Importer module for reading cell-based financial statement data into a FinancialStatementGraph."""

from typing import Any
from fin_statement_model.statements.graph.financial_graph import FinancialStatementGraph

__all__ = ["import_from_cells"]


def import_from_cells(cells_info: list[dict[str, Any]]) -> FinancialStatementGraph:
    """Import a list of cell dictionaries into a FinancialStatementGraph.

    Each cell dict should include at minimum:
    - 'row_name': identifier for the line item
    - 'column_name': the period label
    - 'value': the numeric value

    Args:
        cells_info: List of cell metadata dictionaries.

    Returns:
        A FinancialStatementGraph populated with detected periods and items.
    """
    # Group cells by row_name to aggregate values per financial statement item
    items: dict[str, dict[str, Any]] = {}
    unique_periods: set = set()

    for cell in cells_info:
        # Clean the item name and period
        item_name = cell.get("row_name", "").strip()
        period = cell.get("column_name", "").strip()
        value = cell.get("value")

        if not item_name or not period:
            continue

        unique_periods.add(period)
        if item_name not in items:
            items[item_name] = {}
        items[item_name][period] = value

    # Sort periods and create the graph
    sorted_periods = sorted(unique_periods)
    fsg = FinancialStatementGraph(periods=sorted_periods)

    # Add each financial statement item to the graph
    for name, values in items.items():
        fsg.add_financial_statement_item(name, values)

    return fsg

# --- END FILE: fin_statement_model/statements/importer/cell_importer.py ---

# --- START FILE: fin_statement_model/statements/importer/__init__.py ---
"""Importer package for financial statement data.

Provides functions to import raw data (e.g., cell dicts) into the graph.
"""

from .cell_importer import import_from_cells

__all__ = ["import_from_cells"]

# --- END FILE: fin_statement_model/statements/importer/__init__.py ---

# --- START FILE: fin_statement_model/statements/mixins/metrics_mixin.py ---
"""Metrics mixin module for FinancialStatementGraph operations."""

from typing import Optional


class MetricsOperationsMixin:
    """Mixin providing metric operations for FinancialStatementGraph.

    - add_metric.
    """

    def add_metric(self, metric_name: str, node_name: Optional[str] = None):
        """Add a financial metric calculation node to the graph.

        Args:
            metric_name: The name of the metric from METRIC_DEFINITIONS
            node_name: Optional custom name for the node (defaults to metric_name)
        """
        self._calculation_engine.add_metric(metric_name, node_name)

# --- END FILE: fin_statement_model/statements/mixins/metrics_mixin.py ---

# --- START FILE: fin_statement_model/statements/mixins/forecast_mixin.py ---
"""Forecast operations mixin for financial statements."""

from fin_statement_model.core.graph.forecast_mixin import ForecastOperationsMixin

__all__ = ["ForecastOperationsMixin"]

# --- END FILE: fin_statement_model/statements/mixins/forecast_mixin.py ---

# --- START FILE: fin_statement_model/statements/mixins/__init__.py ---
"""Core statement mixins package."""

from .analysis_mixin import AnalysisOperationsMixin
from .merge_mixin import MergeOperationsMixin
from .metrics_mixin import MetricsOperationsMixin
from .forecast_mixin import ForecastOperationsMixin

__all__ = [
    "AnalysisOperationsMixin",
    "ForecastOperationsMixin",
    "MergeOperationsMixin",
    "MetricsOperationsMixin",
]

# --- END FILE: fin_statement_model/statements/mixins/__init__.py ---

# --- START FILE: fin_statement_model/statements/mixins/analysis_mixin.py ---
"""Analysis mixin module for FinancialStatementGraph operations."""

from typing import Optional
import pandas as pd


class AnalysisOperationsMixin:
    """Mixin providing analysis methods for FinancialStatementGraph.

    - normalize_data
    - analyze_time_series
    - convert_periods.
    """

    def normalize_data(
        self,
        normalization_type: str = "percent_of",
        reference: Optional[str] = None,
        scale_factor: Optional[float] = None,
    ) -> pd.DataFrame:
        """Normalize the financial statement data."""
        df = self.to_dataframe()
        return self._transformation_service.normalize_data(
            df, normalization_type, reference, scale_factor
        )

    def analyze_time_series(
        self,
        transformation_type: str = "growth_rate",
        periods: int = 1,
        window_size: int = 3,
    ) -> pd.DataFrame:
        """Apply time series preprocessing to the financial data."""
        df = self.to_dataframe()
        return self._transformation_service.transform_time_series(
            df, transformation_type, periods, window_size
        )

    def convert_periods(
        self,
        conversion_type: str,
        aggregation: str = "sum",
    ) -> pd.DataFrame:
        """Convert data between different period types."""
        df = self.to_dataframe()
        return self._transformation_service.convert_periods(df, conversion_type, aggregation)

# --- END FILE: fin_statement_model/statements/mixins/analysis_mixin.py ---

# --- START FILE: fin_statement_model/statements/mixins/merge_mixin.py ---
"""Merge operations mixin module for FinancialStatementGraph.

Provides methods to merge graphs and add metric nodes to the statement graph.
"""

from typing import Optional, TYPE_CHECKING

if TYPE_CHECKING:
    from fin_statement_model.statements.graph.financial_graph import (
        FinancialStatementGraph,
    )

"""Merge mixin module for FinancialStatementGraph operations."""


class MergeOperationsMixin:
    """Mixin providing merge methods for FinancialStatementGraph.

    - _merge_graph
    - add_metric.
    """

    def _merge_graph(self, other_graph: "FinancialStatementGraph"):
        """Merge another FinancialStatementGraph into this one.

        Args:
            other_graph: Graph to merge into this one
        """
        # Update periods
        for period in other_graph.graph.periods:
            if period not in self.graph.periods:
                self.graph.periods.append(period)
        self.graph.periods.sort()

        # Merge nodes
        for node_name, node in other_graph.graph.nodes.items():
            existing_node = self.graph.get_node(node_name)
            if existing_node is not None:
                # Update existing node with new values
                if hasattr(node, "values"):
                    for period, value in node.values.items():
                        existing_node.values[period] = value  # type: ignore
                self.graph.add_node(existing_node)  # Re-add to update
            else:
                # Add new node
                self.graph.add_node(node)

    def add_metric(self, metric_name: str, node_name: Optional[str] = None):
        """Add a financial metric calculation node to the graph.

        Args:
            metric_name: The name of the metric from METRIC_DEFINITIONS
            node_name: Optional custom name for the node (defaults to metric_name)
        """
        target_node_name = node_name if node_name is not None else metric_name
        self._calculation_engine.add_metric(metric_name, target_node_name)

# --- END FILE: fin_statement_model/statements/mixins/merge_mixin.py ---

# --- START FILE: fin_statement_model/statements/config/config.py ---
"""Statement configuration handling for Financial Statement Model.

This module provides utilities for loading and parsing statement configuration files,
which define the structure of financial statements including sections and line items.
"""

import json
import yaml
import logging
from typing import Any, Union, Optional
from pathlib import Path

# Use absolute imports
from fin_statement_model.statements.errors import ConfigurationError
from fin_statement_model.statements.structure import (
    StatementStructure,
    Section,
    LineItem,
    CalculatedLineItem,
    SubtotalLineItem,
)

# Configure logging
logger = logging.getLogger(__name__)


class StatementConfig:
    """Manages configuration for financial statement structures.

    This class handles loading, parsing, and validating statement configuration files,
    and building StatementStructure objects from these configurations.
    """

    def __init__(
        self,
        config_data: Optional[dict[str, Any]] = None,
        config_path: Optional[str] = None,
    ):
        """Initialize a statement configuration.

        Args:
            config_data: Optional dictionary containing the configuration data
            config_path: Optional path to a configuration file (JSON or YAML)

        If both config_data and config_path are provided, config_data takes precedence.

        Raises:
            ConfigurationError: If the configuration file is invalid or cannot be loaded
        """
        self.config_data = {}
        self.config_path = config_path

        if config_data:
            self.config_data = config_data
        elif config_path:
            self.load_config(config_path)

    def load_config(self, config_path: str) -> None:
        """Load configuration from a file.

        Args:
            config_path: Path to the configuration file (JSON or YAML)

        Raises:
            ConfigurationError: If the file cannot be loaded or parsed
        """
        self.config_path = config_path
        path = Path(config_path)

        if not path.exists():
            raise ConfigurationError(
                message="Configuration file not found", config_path=config_path
            )

        extension = path.suffix.lower()

        try:
            if extension == ".json":
                with open(path) as f:
                    self.config_data = json.load(f)
            elif extension in [".yaml", ".yml"]:
                with open(path) as f:
                    self.config_data = yaml.safe_load(f)
            else:
                raise ConfigurationError(
                    message="Unsupported file extension",
                    config_path=config_path,
                    errors=[f"Use .json, .yaml, or .yml instead of {extension}"],
                )

            logger.info(f"Loaded statement configuration from {config_path}")
        except json.JSONDecodeError as e:
            logger.exception(f"Error parsing JSON configuration file {config_path}")
            raise ConfigurationError(
                message="Invalid JSON format",
                config_path=config_path,
                errors=[f"JSON decode error at line {e.lineno}, column {e.colno}: {e.msg}"],
            ) from e
        except yaml.YAMLError as e:
            logger.exception(f"Error parsing YAML configuration file {config_path}")
            if hasattr(e, "problem_mark"):
                mark = e.problem_mark
                error_detail = (
                    f"YAML parse error at line {mark.line + 1}, column {mark.column + 1}: "
                    f"{e.problem}"
                )
            else:
                error_detail = str(e)
            raise ConfigurationError(
                message="Invalid YAML format",
                config_path=config_path,
                errors=[error_detail],
            ) from e
        except Exception as e:
            logger.exception(f"Unexpected error loading configuration from {config_path}")
            raise ConfigurationError(
                message="Failed to load configuration",
                config_path=config_path,
                errors=[str(e)],
            ) from e

    def validate_config(self) -> list[str]:
        """Validate the configuration data.

        Returns:
            List[str]: List of validation errors, or empty list if valid
        """
        errors = []

        # Check for required top-level fields
        required_fields = ["id", "name", "sections"]
        errors.extend(
            [
                f"Missing required field: {field}"
                for field in required_fields
                if field not in self.config_data
            ]
        )

        # Check for sections
        if "sections" in self.config_data:
            # Validate each section
            sections = self.config_data.get("sections", [])
            if not isinstance(sections, list):
                errors.append("'sections' must be a list")
            else:
                for i, section in enumerate(sections):
                    section_errors = self._validate_section(section, i)
                    errors.extend(section_errors)

        return errors

    def _validate_section(self, section: dict[str, Any], index: int) -> list[str]:
        """Validate a section configuration.

        Args:
            section: Section configuration dictionary
            index: Index of the section in the sections list

        Returns:
            List[str]: List of validation errors, or empty list if valid
        """
        errors = []

        # Check if section is a dictionary
        if not isinstance(section, dict):
            return [f"Section[{index}]: Must be a dictionary"]

        # Check for required section fields
        required_fields = ["id", "name"]
        errors.extend(
            [
                f"Section[{index}]: Missing required field: {field}"
                for field in required_fields
                if field not in section
            ]
        )

        # Validate section ID format
        section_id = section.get("id", "")
        if not section_id:
            errors.append(f"Section[{index}]: ID cannot be empty")
        elif not isinstance(section_id, str):
            errors.append(f"Section[{index}]: ID must be a string")
        elif " " in section_id:
            errors.append(f"Section[{index}]: ID '{section_id}' should not contain spaces")

        # Validate items
        if "items" in section:
            # Validate each item
            items = section.get("items", [])
            if not isinstance(items, list):
                errors.append(f"Section[{index}]: 'items' must be a list")
            else:
                for j, item in enumerate(items):
                    item_errors = self._validate_item(item, index, j)
                    errors.extend(item_errors)

        # Validate subsections if present
        if "subsections" in section:
            subsections = section.get("subsections", [])
            if not isinstance(subsections, list):
                errors.append(f"Section[{index}]: 'subsections' must be a list")
            else:
                for j, subsection in enumerate(subsections):
                    subsection_errors = self._validate_section(subsection, f"{index}.{j}")
                    errors.extend(subsection_errors)

        return errors

    def _validate_item(self, item: dict[str, Any], section_idx: int, item_idx: int) -> list[str]:
        """Validate an item configuration.

        Args:
            item: Item configuration dictionary
            section_idx: Index of the parent section
            item_idx: Index of the item within the section

        Returns:
            List[str]: List of validation errors, or empty list if valid
        """
        errors = []

        # Check if item is a dictionary
        if not isinstance(item, dict):
            return [f"Section[{section_idx}].Item[{item_idx}]: Must be a dictionary"]

        # Check for required item fields
        required_fields = ["id", "name"]
        errors.extend(
            [
                f"Section[{section_idx}].Item[{item_idx}]: Missing required field: {field}"
                for field in required_fields
                if field not in item
            ]
        )

        # Validate item ID format
        item_id = item.get("id", "")
        if not item_id:
            errors.append(f"Section[{section_idx}].Item[{item_idx}]: ID cannot be empty")
        elif not isinstance(item_id, str):
            errors.append(f"Section[{section_idx}].Item[{item_idx}]: ID must be a string")
        elif " " in item_id:
            errors.append(
                f"Section[{section_idx}].Item[{item_idx}]: ID '{item_id}' should not contain spaces"
            )

        # Validate based on item type
        item_type = item.get("type", "line_item")

        if item_type == "section":
            # This is a nested section
            if "items" not in item:
                errors.append(
                    f"Section[{section_idx}].Item[{item_idx}]: Nested section missing 'items' field"
                )
            else:
                nested_items = item.get("items", [])
                if not isinstance(nested_items, list):
                    errors.append(
                        f"Section[{section_idx}].Item[{item_idx}]: 'items' must be a list"
                    )
                else:
                    for k, nested_item in enumerate(nested_items):
                        nested_errors = self._validate_item(
                            nested_item, f"{section_idx}.{item_idx}", k
                        )
                        errors.extend(nested_errors)

        elif item_type == "line_item":
            # Basic line item should have a node_id
            if "node_id" not in item:
                errors.append(
                    f"Section[{section_idx}].Item[{item_idx}]: Line item missing 'node_id' field"
                )

        elif item_type == "calculated":
            if "calculation" not in item:
                errors.append(
                    f"Section[{section_idx}].Item[{item_idx}]: Calculated item missing 'calculation' field"
                )
            else:
                calculation = item.get("calculation", {})
                if not isinstance(calculation, dict):
                    errors.append(
                        f"Section[{section_idx}].Item[{item_idx}]: 'calculation' must be a dictionary"
                    )
                else:
                    # Validate calculation
                    if "type" not in calculation:
                        errors.append(
                            f"Section[{section_idx}].Item[{item_idx}]: Calculation missing 'type' field"
                        )
                    if "inputs" not in calculation:
                        errors.append(
                            f"Section[{section_idx}].Item[{item_idx}]: Calculation missing 'inputs' field"
                        )
                    elif not isinstance(calculation.get("inputs", []), list):
                        errors.append(
                            f"Section[{section_idx}].Item[{item_idx}]: 'inputs' must be a list"
                        )

        elif item_type == "subtotal":
            # Check for calculation with addition type
            if "calculation" in item:
                calculation = item.get("calculation", {})
                if calculation.get("type") != "addition":
                    errors.append(
                        f"Section[{section_idx}].Item[{item_idx}]: Subtotal calculation type must be 'addition'"
                    )
            elif "items_to_sum" not in item:
                errors.append(
                    f"Section[{section_idx}].Item[{item_idx}]: Subtotal item missing 'items_to_sum' field"
                )
            elif not isinstance(item.get("items_to_sum", []), list):
                errors.append(
                    f"Section[{section_idx}].Item[{item_idx}]: 'items_to_sum' must be a list"
                )

        else:
            errors.append(
                f"Section[{section_idx}].Item[{item_idx}]: Unknown item type: {item_type}"
            )

        return errors

    def build_statement_structure(self) -> StatementStructure:
        """Build a StatementStructure object from the configuration.

        Returns:
            StatementStructure: The constructed statement structure

        Raises:
            ConfigurationError: If the configuration is invalid
        """
        # Validate the configuration
        errors = self.validate_config()
        if errors:
            error_msg = "Configuration validation failed"
            logger.error(f"{error_msg}: {'; '.join(errors)}")
            raise ConfigurationError(message=error_msg, config_path=self.config_path, errors=errors)

        try:
            # Create the statement structure
            statement = StatementStructure(
                id=self.config_data["id"],
                name=self.config_data["name"],
                description=self.config_data.get("description", ""),
                metadata=self.config_data.get("metadata", {}),
            )

            # Build sections
            sections = self.config_data.get("sections", [])
            for section_config in sections:
                section = self._build_section(section_config)
                statement.add_section(section)

            return statement
        except Exception as e:
            logger.exception("Error building statement structure")
            raise ConfigurationError(
                message="Failed to build statement structure",
                config_path=self.config_path,
                errors=[str(e)],
            ) from e
        else:
            return statement

    def _build_section(self, section_config: dict[str, Any]) -> Section:
        """Build a Section object from a section configuration.

        Args:
            section_config: Section configuration dictionary

        Returns:
            Section: The constructed section

        Raises:
            ConfigurationError: If the section configuration is invalid
        """
        try:
            # Create the section
            section = Section(
                id=section_config["id"],
                name=section_config["name"],
                description=section_config.get("description", ""),
                metadata=section_config.get("metadata", {}),
            )

            # Add items
            items = section_config.get("items", [])
            for item_config in items:
                item = self._build_item(item_config)
                section.add_item(item)

            # Add subsections
            subsections = section_config.get("subsections", [])
            for subsection_config in subsections:
                subsection = self._build_section(subsection_config)
                section.add_item(subsection)

            # Add subtotal if specified
            subtotal_config = section_config.get("subtotal")
            if subtotal_config:
                section.subtotal = self._build_subtotal(subtotal_config)

            return section
        except KeyError as e:
            section_id = section_config.get("id", "unknown")
            raise ConfigurationError(
                message=f"Missing required field '{e.args[0]}'",
                errors=[f"Section '{section_id}' is missing required field: {e.args[0]}"],
            ) from e
        except Exception as e:
            section_id = section_config.get("id", "unknown")
            raise ConfigurationError(
                message="Failed to build section",
                errors=[f"Error in section '{section_id}': {e!s}"],
            ) from e
        else:
            return section

    def _build_item(
        self, item_config: dict[str, Any]
    ) -> Union[LineItem, CalculatedLineItem, SubtotalLineItem, Section]:
        """Build a LineItem object from an item configuration.

        Args:
            item_config: Item configuration dictionary

        Returns:
            Union[LineItem, CalculatedLineItem, SubtotalLineItem, Section]:
                The constructed item

        Raises:
            ConfigurationError: If the item configuration is invalid
        """
        try:
            item_type = item_config.get("type", "line_item")

            if item_type == "section":
                # Handle nested section
                return self._build_section(item_config)

            elif item_type == "line_item":
                return LineItem(
                    id=item_config["id"],
                    name=item_config["name"],
                    node_id=item_config.get("node_id"),
                    description=item_config.get("description", ""),
                    sign_convention=item_config.get("sign_convention", 1),
                    metadata=item_config.get("metadata", {}),
                )

            elif item_type == "calculated":
                return CalculatedLineItem(
                    id=item_config["id"],
                    name=item_config["name"],
                    calculation=item_config["calculation"],
                    description=item_config.get("description", ""),
                    sign_convention=item_config.get("sign_convention", 1),
                    metadata=item_config.get("metadata", {}),
                )

            elif item_type == "subtotal":
                return self._build_subtotal(item_config)

            else:
                raise ConfigurationError(
                    message=f"Unknown item type: {item_type}",
                    errors=[
                        f"Item '{item_config.get('id', 'unknown')}' has invalid type: {item_type}"
                    ],
                )
        except KeyError as e:
            item_id = item_config.get("id", "unknown")
            raise ConfigurationError(
                message=f"Missing required field '{e.args[0]}'",
                errors=[f"Item '{item_id}' is missing required field: {e.args[0]}"],
            ) from e
        except Exception as e:
            item_id = item_config.get("id", "unknown")
            raise ConfigurationError(
                message="Failed to build item",
                errors=[f"Error in item '{item_id}': {e!s}"],
            ) from e

    def _build_subtotal(self, subtotal_config: dict[str, Any]) -> SubtotalLineItem:
        """Build a SubtotalLineItem object from a subtotal configuration.

        Args:
            subtotal_config: Subtotal configuration dictionary

        Returns:
            SubtotalLineItem: The constructed subtotal line item

        Raises:
            ConfigurationError: If the subtotal configuration is invalid
        """
        try:
            # Get items to sum
            items_to_sum = []

            if "calculation" in subtotal_config:
                # If using calculation format
                calculation = subtotal_config.get("calculation", {})
                items_to_sum = calculation.get("inputs", [])
            elif "item_ids" in subtotal_config:
                # If using item_ids format
                items_to_sum = subtotal_config.get("item_ids", [])
            else:
                # If using items_to_sum format
                items_to_sum = subtotal_config.get("items_to_sum", [])

            # Create subtotal
            return SubtotalLineItem(
                id=subtotal_config["id"],
                name=subtotal_config["name"],
                item_ids=items_to_sum,
                description=subtotal_config.get("description", ""),
                sign_convention=subtotal_config.get("sign_convention", 1),
                metadata=subtotal_config.get("metadata", {}),
            )
        except KeyError as e:
            subtotal_id = subtotal_config.get("id", "unknown")
            raise ConfigurationError(
                message=f"Missing required field '{e.args[0]}'",
                errors=[f"Subtotal '{subtotal_id}' is missing required field: {e.args[0]}"],
            ) from e
        except Exception as e:
            subtotal_id = subtotal_config.get("id", "unknown")
            raise ConfigurationError(
                message="Failed to build subtotal",
                errors=[f"Error in subtotal '{subtotal_id}': {e!s}"],
            ) from e


def load_statement_config(config_path: str) -> StatementStructure:
    """Load and build a statement structure from a configuration file.

    Args:
        config_path: Path to the configuration file (JSON or YAML)

    Returns:
        StatementStructure: The constructed statement structure

    Raises:
        ConfigurationError: If the configuration file cannot be loaded or is invalid
    """
    try:
        config = StatementConfig(config_path=config_path)
        return config.build_statement_structure()
    except Exception as e:
        if isinstance(e, ConfigurationError):
            # Re-raise ConfigurationError
            raise
        else:
            # Wrap other exceptions
            logger.exception("Unexpected error loading statement configuration")
            raise ConfigurationError(
                message="Failed to load statement configuration",
                config_path=config_path,
                errors=[str(e)],
            ) from e

# --- END FILE: fin_statement_model/statements/config/config.py ---

# --- START FILE: fin_statement_model/statements/config/loader.py ---
"""Loader for statement configuration files and built-in mappings.

Provides:
  - load_statement_config: load any JSON/YAML config via StatementConfig
  - list_built_in_statements: list mapping file names in config/mappings/
  - load_built_in_statement: load a named mapping from config/mappings/
"""

import logging
import os
from pathlib import Path

from fin_statement_model.statements.errors import ConfigurationError
from fin_statement_model.statements.config.config import StatementConfig
from fin_statement_model.statements.structure import StatementStructure

logger = logging.getLogger(__name__)

# Directory where built-in mapping files live (allow override via env var)
this_dir = Path(__file__).parent


def _get_mapping_dir() -> Path:
    """Return path to mapping directory, using FIN_STATEMENTS_MAPPING_DIR if set."""
    mapping_env = os.getenv("FIN_STATEMENTS_MAPPING_DIR")
    if mapping_env:
        return Path(mapping_env)
    return this_dir / "mappings"


__all__ = [
    "list_built_in_statements",
    "load_built_in_statement",
    "load_statement_config",
]


def load_statement_config(config_path: str) -> StatementStructure:
    """Load a statement structure from a JSON or YAML file at any path.

    Args:
        config_path: Path to .json, .yaml, or .yml file defining the statement

    Returns:
        StatementStructure: Parsed statement structure

    Raises:
        ConfigurationError: If the file cannot be parsed or is invalid
    """
    try:
        cfg = StatementConfig(config_path=config_path)
        return cfg.build_statement_structure()
    except Exception as e:
        if isinstance(e, ConfigurationError):
            raise
        logger.exception(f"Error loading statement config from {config_path}")
        raise ConfigurationError(
            message="Failed to load statement configuration",
            config_path=config_path,
            errors=[str(e)],
        ) from e


def list_built_in_statements() -> list[str]:
    """List the names of all built-in statement mappings available.

    Returns:
        List[str]: List of mapping names (filename without extension)
    """
    mapping_dir = _get_mapping_dir()
    if not mapping_dir.exists():
        return []
    names = [
        p.stem
        for p in mapping_dir.iterdir()
        if p.is_file() and p.suffix.lower() in (".yaml", ".yml", ".json")
    ]
    return sorted(names)


def load_built_in_statement(name: str) -> StatementStructure:
    """Load a built-in statement by name from the config/mappings directory.

    Args:
        name: Mapping name (filename without extension)

    Returns:
        StatementStructure: Parsed statement structure

    Raises:
        ConfigurationError: If no such mapping exists or parsing fails
    """
    mapping_dir = _get_mapping_dir()
    for ext in (".yaml", ".yml", ".json"):
        path = mapping_dir / f"{name}{ext}"
        if path.exists():
            return load_statement_config(str(path))
    raise ConfigurationError(
        message=f"Built-in statement '{name}' not found",
        config_path=str(mapping_dir),
        errors=[f"No file for '{name}' with .yaml, .yml, or .json extension"],
    )

# --- END FILE: fin_statement_model/statements/config/loader.py ---

# --- START FILE: fin_statement_model/statements/config/mappings/__init__.py ---
"""Configuration mappings for statement importers and extensions."""

# --- END FILE: fin_statement_model/statements/config/mappings/__init__.py ---

# --- START FILE: fin_statement_model/statements/graph/financial_graph.py ---
"""FinancialStatementGraph module for statement-specific graph operations.

This module defines `FinancialStatementGraph`, which extends the core `Graph`
with mixins for statement analysis, merging, metrics, forecasting, and conversion to DataFrame.
"""

from typing import Optional
from fin_statement_model.core.graph import Graph
from fin_statement_model.preprocessing.transformation_service import (
    TransformationService,
)
from fin_statement_model.statements.mixins.analysis_mixin import AnalysisOperationsMixin
from fin_statement_model.statements.mixins.merge_mixin import MergeOperationsMixin
from fin_statement_model.statements.mixins.metrics_mixin import MetricsOperationsMixin
from fin_statement_model.statements.mixins.forecast_mixin import ForecastOperationsMixin
from fin_statement_model.io import write_data
import pandas as pd


class FinancialStatementGraph(
    Graph,
    TransformationService,
    AnalysisOperationsMixin,
    MergeOperationsMixin,
    MetricsOperationsMixin,
    ForecastOperationsMixin,
):
    """Main class for managing financial statement data and calculations.

    This class combines functionality from multiple mixins to provide a complete
    financial statement modeling solution.
    """

    def __init__(self, periods: Optional[list[str]] = None):
        """Initialize a new FinancialStatementGraph.

        Args:
            periods: Optional list of time periods to initialize the graph with.
        """
        super().__init__(periods=periods)

    @property
    def graph(self) -> Graph:
        """Alias to self for compatibility with importer expecting a graph attribute."""
        return self

    def to_dataframe(self) -> pd.DataFrame:
        """Exports the financial statement graph data to a pandas DataFrame.

        Returns:
            pd.DataFrame: A DataFrame representation of the graph's node values over periods.
        """
        return write_data(format_type="dataframe", graph=self, target=None)

# --- END FILE: fin_statement_model/statements/graph/financial_graph.py ---

# --- START FILE: fin_statement_model/statements/__init__.py ---
"""Financial statements module for the Financial Statement Model.

This module defines configurable financial statement structures,
including various types of financial statements (Income Statement,
Balance Sheet, Cash Flow) with hierarchical sections and line items
defined through configuration.
"""

from .structure import (
    StatementStructure,
    Section,
    LineItem,
    CalculatedLineItem,
    SubtotalLineItem,
    StatementItemType,
)
from .config.config import StatementConfig, load_statement_config
from .formatter import StatementFormatter
from .manager import StatementManager
from .factory import StatementFactory
from .graph.financial_graph import FinancialStatementGraph

__all__ = [
    "CalculatedLineItem",
    "FinancialStatementGraph",
    "LineItem",
    "Section",
    "StatementConfig",
    "StatementFactory",
    "StatementFormatter",
    "StatementItemType",
    "StatementManager",
    "StatementStructure",
    "SubtotalLineItem",
    "load_statement_config",
]

# --- END FILE: fin_statement_model/statements/__init__.py ---

# --- START FILE: fin_statement_model/statements/factory.py ---
"""Statement factory module for building, formatting, and exporting financial statements.

Provides `StatementFactory` with convenience methods to build managers, format DataFrame/JSON outputs,
and export statements to Excel or JSON files.
"""

from typing import Any
import pandas as pd
from fin_statement_model.core.graph import Graph
from .manager import StatementManager
import os
import json


class StatementFactory:
    """Factory for building and formatting financial statements.

    Provides convenience methods to create a StatementManager and produce
    formatted outputs based on configuration files.
    """

    @staticmethod
    def build_manager(graph: Graph, config_path: str) -> StatementManager:
        """Create and return a StatementManager loaded with the given configuration.

        Args:
            graph: An instance of the core Graph to use for calculations.
            config_path: Path to the statement configuration file (JSON/YAML).

        Returns:
            StatementManager: Manager with the statement loaded and registered.
        """
        manager = StatementManager(graph)
        # Support loading a single config file or all configs in a directory
        if os.path.isdir(config_path):
            manager.load_statements_from_directory(config_path)
        else:
            manager.load_statement(config_path)
        return manager

    @staticmethod
    def create_statement_dataframe(
        graph: Graph, config_path: str, format_type: str = "dataframe", **kwargs: Any
    ) -> pd.DataFrame:
        """Load, calculate, and format the statement as a pandas DataFrame.

        Args:
            graph: An instance of the core Graph to use for calculations.
            config_path: Path to the statement configuration file.
            format_type: Formatting type to use (default 'dataframe').
            **kwargs: Additional parameters for the formatter (e.g., subtotals).

        Returns:
            pd.DataFrame: The formatted statement data.
        """
        manager = StatementFactory.build_manager(graph, config_path)
        stmt_ids = manager.get_all_statement_ids()
        if not stmt_ids:
            raise ValueError("No statements registered in manager.")
        # Generate formatted output for each statement
        outputs: dict[str, pd.DataFrame] = {}
        for stmt_id in stmt_ids:
            manager.create_calculations(stmt_id)
            outputs[stmt_id] = manager.format_statement(stmt_id, format_type, **kwargs)
        # If only one statement, return its DataFrame directly
        if len(outputs) == 1:
            return next(iter(outputs.values()))
        return outputs

    @staticmethod
    def create_statement_json(
        graph: Graph,
        config_path: str,
    ) -> dict[str, object]:
        """Load statements, calculate all, and return JSON-serializable dict of statement data."""
        manager = StatementFactory.build_manager(graph, config_path)
        stmt_ids = manager.get_all_statement_ids()
        if not stmt_ids:
            raise ValueError("No statements registered in manager.")
        json_outputs: dict[str, Any] = {}
        for stmt_id in stmt_ids:
            manager.create_calculations(stmt_id)
            json_outputs[stmt_id] = manager.build_data_dictionary(stmt_id)
        return json_outputs

    @staticmethod
    def export_statements_to_excel(
        graph: Graph, config_path: str, output_dir: str, **kwargs: Any
    ) -> None:
        """Export all registered statements to individual Excel files in output_dir."""
        manager = StatementFactory.build_manager(graph, config_path)
        os.makedirs(output_dir, exist_ok=True)
        for stmt_id in manager.get_all_statement_ids():
            manager.create_calculations(stmt_id)
            file_path = os.path.join(output_dir, f"{stmt_id}.xlsx")
            manager.export_to_excel(stmt_id, file_path, **kwargs)

    @staticmethod
    def export_statements_to_json(
        graph: Graph,
        config_path: str,
        output_dir: str,
    ) -> None:
        """Export all registered statements to individual JSON files in output_dir."""
        os.makedirs(output_dir, exist_ok=True)
        json_outputs = StatementFactory.create_statement_json(graph, config_path)
        for stmt_id, data in json_outputs.items():
            file_path = os.path.join(output_dir, f"{stmt_id}.json")
            with open(file_path, "w", encoding="utf-8") as f:
                json.dump(data, f, indent=4)

# --- END FILE: fin_statement_model/statements/factory.py ---

# --- START FILE: fin_statement_model/statements/formatter/formatter.py ---
"""Formatter for financial statements.

This module provides functionality for formatting financial statements
for display or reporting, including applying formatting rules, adding subtotals,
and applying sign conventions.
"""

import pandas as pd
from typing import Optional, Any
from pandas.api.types import is_numeric_dtype
import logging

from fin_statement_model.statements.structure import StatementStructure
from fin_statement_model.statements.structure import (
    Section,
    CalculatedLineItem,
    SubtotalLineItem,
    StatementItem,
)

# Configure logging
logger = logging.getLogger(__name__)


class StatementFormatter:
    """Formats financial statements for display or reporting.

    This class provides methods to transform raw financial data into
    formatted financial statements with proper headers, indentation,
    subtotals, and sign conventions.
    """

    def __init__(self, statement: StatementStructure):
        """Initialize a statement formatter.

        Args:
            statement: The statement structure to format
        """
        self.statement = statement
        self.config = {}
        self.default_formats = {
            "precision": 2,
            "use_thousands_separator": True,
            "show_zero_values": True,
            "show_negative_sign": True,
            "indent_character": "  ",
            "subtotal_style": "bold",
            "total_style": "bold",
            "header_style": "bold",
        }

    def generate_dataframe(
        self,
        data: dict[str, dict[str, float]],
        apply_sign_convention: bool = True,
        include_empty_items: bool = False,
        number_format: Optional[str] = None,
    ) -> pd.DataFrame:
        """Generate a formatted DataFrame of the statement.

        Combines the statement structure with period data.

        Args:
            data: Mapping of node IDs to period-value dicts.
            apply_sign_convention: Whether to apply sign conventions.
            include_empty_items: Whether to include items with no data.
            number_format: Optional format string for numbers

        Returns:
            pd.DataFrame: Formatted statement DataFrame
        """
        # Convert structure to base DataFrame
        # This needs modification to incorporate period data
        # Placeholder: Creates structure, but needs data merge
        rows = []
        all_periods = sorted(list(set(p for node_data in data.values() for p in node_data))) if data else []

        # Helper to recursively build rows including data
        def _process_item_with_data(
            item: StatementItem, depth: int, rows_list: list[dict[str, Any]]
        ) -> None:
            item_data = data.get(getattr(item, "node_id", None), {})
            row = {
                "Line Item": "  " * depth + item.name, # Indentation
                "ID": item.id, # Added ID for clarity
                # Add periods as columns
                **{period: item_data.get(period) for period in all_periods},
                # Metadata (could be added later or made optional)
                "line_type": self._get_item_type(item),
                "node_id": getattr(item, "node_id", None),
                "sign_convention": getattr(item, "sign_convention", 1),
                "is_subtotal": isinstance(item, SubtotalLineItem),
                "is_calculated": isinstance(item, CalculatedLineItem),
            }
            if include_empty_items or any(row[p] is not None for p in all_periods):
                 rows_list.append(row)

            if hasattr(item, "children"):
                for child in item.children:
                    _process_item_with_data(child, depth + 1, rows_list)
            elif isinstance(item, Section):
                for child_item in item.items:
                    _process_item_with_data(child_item, depth + 1, rows_list)

        # Process sections and their items recursively
        for section in self.statement.sections:
            # Section Header (optional, depends on desired format)
            # rows.append({"Line Item": section.name, "ID": section.id, **{p: None for p in all_periods}})
             _process_item_with_data(section, 0, rows)


        if not rows:
            return pd.DataFrame(columns=["Line Item", "ID", *all_periods])

        df = pd.DataFrame(rows)
        # Reorder columns: Line Item, ID, then sorted periods
        cols = ["Line Item", "ID", *all_periods]
        df = df[cols + [c for c in df.columns if c not in cols]] # Keep metadata at end

        # Apply formatting
        if apply_sign_convention:
            df = self._apply_sign_convention_to_data(df, all_periods)

        # Format numbers (apply to period columns only)
        df = self._format_numbers(df, number_format, period_columns=all_periods)

        # TODO: Add subtotals (requires rework for multi-period data)
        # df = self._add_subtotals(df)

        # Remove metadata if not requested - keeping for now
        # if not include_metadata:
        #     metadata_cols = [col for col in df.columns if col.startswith("meta_")]
        #     if metadata_cols:
        #         df = df.drop(columns=metadata_cols)

        return df

    def _process_item(self, item: StatementItem, depth: int, rows: list[dict[str, Any]]) -> None:
        # This method seems less relevant now with _process_item_with_data
        # Keep it for now or remove if fully replaced
        pass

    def _get_item_type(self, item: StatementItem) -> str:
        """Get the type of a statement item.

        Args:
            item: Statement item to get type for

        Returns:
            str: Item type identifier
        """
        if isinstance(item, Section):
            return "section"
        elif isinstance(item, SubtotalLineItem):
            return "subtotal"
        elif isinstance(item, CalculatedLineItem):
            return "calculated"
        else:
            return "item"

    def _apply_sign_convention(self, df: pd.DataFrame) -> pd.DataFrame:
        # This method needs adjustment for multi-period data
        # The logic assumed a single 'value' column
        # Keep for reference, replace with _apply_sign_convention_to_data
        pass

    def _apply_sign_convention_to_data(self, df: pd.DataFrame, period_columns: list[str]) -> pd.DataFrame:
        """Apply sign conventions to the statement values across periods."""
        result = df.copy()
        if "sign_convention" in result.columns:
            for col in period_columns:
                if col in result.columns and is_numeric_dtype(result[col]):
                    mask = result[col].notna()
                    # Ensure sign_convention is treated as numeric if needed
                    sign_col = pd.to_numeric(result.loc[mask, "sign_convention"], errors="coerce").fillna(1)
                    result.loc[mask, col] = (
                        result.loc[mask, col] * sign_col
                    )
        return result

    def _add_subtotals(self, df: pd.DataFrame) -> pd.DataFrame:
        # This needs significant rework for multi-period data
        # Placeholder - current logic is single-value based
        logger.warning("Subtotal calculation needs rework for multi-period data.")
        return df

    def _calculate_section_subtotal(self, items: list[dict[str, Any]]) -> float:
        # This needs rework for multi-period data
        pass

    def _format_numbers(
        self, df: pd.DataFrame, number_format: Optional[str] = None, period_columns: Optional[list[str]] = None
    ) -> pd.DataFrame:
        """Format numeric values in the statement.

        Args:
            df: DataFrame to format numbers in
            number_format: Optional format string
            period_columns: List of columns containing period data to format.
                            If None, attempts to format all numeric columns
                            except metadata/indicators.

        Returns:
            pd.DataFrame: DataFrame with formatted numbers
        """
        result = df.copy()

        if period_columns:
            numeric_cols = [col for col in period_columns if col in result.columns and is_numeric_dtype(result[col])]
        else:
             # Original logic if period_columns not specified
            numeric_cols = [
                col
                for col in result.columns
                if is_numeric_dtype(result[col])
                and col not in ("sign_convention", "depth", "ID") # Added ID
                and not col.startswith("meta_")
                and col != "Line Item" # Ensure Line Item name is not formatted
            ]

        # Format to specified precision
        precision = self.config.get("precision", self.default_formats["precision"])

        if number_format:
            # Use provided format string
            for col in numeric_cols:
                # Check if column exists before applying format
                if col in result.columns:
                    result[col] = result[col].apply(
                        lambda x: f"{x:{number_format}}" if pd.notna(x) else ""
                    )
        else:
            # Use default formatting
            for col in numeric_cols:
                 # Check if column exists before applying format
                if col in result.columns:
                    result[col] = result[col].apply(
                        lambda x: (
                            (f"{x:,.{precision}f}" if pd.notna(x) else "")
                            if self.default_formats["use_thousands_separator"]
                            else (f"{x:.{precision}f}" if pd.notna(x) else "")
                        )
                    )

        return result

    def format_html(
        self,
        data: dict[str, dict[str, float]],
        apply_sign_convention: bool = True,
        include_empty_items: bool = False,
        css_styles: Optional[dict[str, str]] = None,
    ) -> str:
        """Format the statement data as HTML.

        Args:
            data: Mapping of node IDs to period-value dicts.
            apply_sign_convention: Whether to apply sign conventions.
            include_empty_items: Whether to include items with no data.
            css_styles: Optional dict of CSS styles for the HTML.

        Returns:
            str: HTML string representing the statement.
        """
        df = self.generate_dataframe(data, apply_sign_convention, include_empty_items)

        # Convert DataFrame to HTML
        html = df.to_html(index=False)

        # Add CSS styles if provided
        if css_styles:
            style_str = "<style>\n"
            for selector, style in css_styles.items():
                style_str += f"{selector} {{ {style} }}\n"
            style_str += "</style>\n"
            html = style_str + html

        return html

# --- END FILE: fin_statement_model/statements/formatter/formatter.py ---

# --- START FILE: fin_statement_model/statements/formatter/__init__.py ---
"""Formatter package for financial statements.

This package provides tools for formatting financial statements for display
and reporting, with controls for formatting, styling, and presentation.
"""

from .formatter import StatementFormatter

__all__ = ["StatementFormatter"]

# --- END FILE: fin_statement_model/statements/formatter/__init__.py ---

# --- START FILE: fin_statement_model/statements/errors.py ---
"""Exceptions for the statements package."""

from typing import Optional
from fin_statement_model.core.errors import FinancialModelError


class StatementError(FinancialModelError):
    """Base exception for statement-related errors."""


class ConfigurationError(StatementError):
    """Exception raised for statement configuration errors."""

    def __init__(
        self,
        message: str,
        config_path: Optional[str] = None,
        errors: Optional[list[str]] = None,
    ):
        """Initialize a configuration error.

        Args:
            message: Main error message
            config_path: Path to the configuration file that caused the error
            errors: List of specific validation errors
        """
        self.message = message
        self.config_path = config_path
        self.errors = errors or []

        # Build detailed error message
        details = []
        if config_path:
            details.append(f"Config file: {config_path}")
        if errors:
            details.append("Validation errors:")
            details.extend([f"  - {error}" for error in errors])

        full_message = message
        if details:
            full_message = f"{message}\n" + "\n".join(details)

        super().__init__(full_message)

# --- END FILE: fin_statement_model/statements/errors.py ---

# --- START FILE: fin_statement_model/statements/structure/containers.py ---
"""Container classes for defining hierarchical financial statement structures.

This module provides Section and StatementStructure, which organize
LineItem and CalculatedLineItem objects into nested groups.
"""

from typing import Any, Optional, Union, TYPE_CHECKING

from fin_statement_model.core.errors import StatementError
from fin_statement_model.statements.structure.items import (
    StatementItem,
    StatementItemType,
    CalculatedLineItem,
    SubtotalLineItem,
)

__all__ = ["Section", "StatementStructure"]

if TYPE_CHECKING:
    from fin_statement_model.statements.structure.items import StatementItem


class Section:
    """Represents a section in a financial statement.

    Sections group related items and subsections into a hierarchical container.
    """

    def __init__(
        self,
        id: str,
        name: str,
        description: str = "",
        metadata: Optional[dict[str, Any]] = None,
    ):
        """Initialize a section.

        Args:
            id: Unique identifier for the section.
            name: Display name for the section.
            description: Optional description text.
            metadata: Optional additional metadata.

        Raises:
            StatementError: If id or name is invalid.
        """
        if not id or not isinstance(id, str):
            raise StatementError(message=f"Invalid section ID: {id}")
        if not name or not isinstance(name, str):
            raise StatementError(message=f"Invalid section name: {name} for ID: {id}")

        self._id = id
        self._name = name
        self._description = description
        self._metadata = metadata or {}
        self._items: list[Union[Section, StatementItem]] = []

    @property
    def id(self) -> str:
        """Get the section identifier."""
        return self._id

    @property
    def name(self) -> str:
        """Get the section display name."""
        return self._name

    @property
    def description(self) -> str:
        """Get the section description."""
        return self._description

    @property
    def metadata(self) -> dict[str, Any]:
        """Get the section metadata."""
        return self._metadata

    @property
    def items(self) -> list[Union["Section", StatementItem]]:
        """Get the child items and subsections."""
        return list(self._items)

    @property
    def item_type(self) -> StatementItemType:
        """Get the item type (SECTION)."""
        return StatementItemType.SECTION

    def add_item(self, item: Union["Section", StatementItem]) -> None:
        """Add a child item or subsection to this section.

        Args:
            item: The Section or StatementItem to add.

        Raises:
            StatementError: If an item with the same id already exists.
        """
        if any(existing.id == item.id for existing in self._items):
            raise StatementError(message=f"Duplicate item ID: {item.id} in section: {self.id}")
        self._items.append(item)

    def find_item_by_id(self, item_id: str) -> Optional[Union["Section", StatementItem]]:
        """Recursively find an item by its identifier within this section.

        Args:
            item_id: Identifier of the item to search for.

        Returns:
            The found Section or StatementItem, or None if not found.
        """
        if self.id == item_id:
            return self
        for child in self._items:
            if child.id == item_id:
                return child
            if isinstance(child, Section):
                found = child.find_item_by_id(item_id)
                if found:
                    return found
        return None


class StatementStructure:
    """Top-level container for a financial statement structure.

    Manages a hierarchy of Section objects.
    """

    def __init__(
        self,
        id: str,
        name: str,
        description: str = "",
        metadata: Optional[dict[str, Any]] = None,
    ):
        """Initialize a statement structure.

        Args:
            id: Unique identifier for the statement.
            name: Display name for the statement.
            description: Optional description text.
            metadata: Optional additional metadata.

        Raises:
            StatementError: If id or name is invalid.
        """
        if not id or not isinstance(id, str):
            raise StatementError(message=f"Invalid statement ID: {id}")
        if not name or not isinstance(name, str):
            raise StatementError(message=f"Invalid statement name: {name} for ID: {id}")

        self._id = id
        self._name = name
        self._description = description
        self._metadata = metadata or {}
        self._sections: list[Section] = []

    @property
    def id(self) -> str:
        """Get the statement identifier."""
        return self._id

    @property
    def name(self) -> str:
        """Get the statement display name."""
        return self._name

    @property
    def description(self) -> str:
        """Get the statement description."""
        return self._description

    @property
    def metadata(self) -> dict[str, Any]:
        """Get the statement metadata."""
        return self._metadata

    @property
    def sections(self) -> list[Section]:
        """Get the top-level sections."""
        return list(self._sections)

    @property
    def items(self) -> list[Section]:
        """Alias for sections to ease iteration."""
        return self.sections

    def add_section(self, section: Section) -> None:
        """Add a section to the statement.

        Args:
            section: Section to add.

        Raises:
            StatementError: If a section with the same id already exists.
        """
        if any(s.id == section.id for s in self._sections):
            raise StatementError(
                message=f"Duplicate section ID: {section.id} in statement: {self.id}"
            )
        self._sections.append(section)

    def find_item_by_id(self, item_id: str) -> Optional[Union[Section, StatementItem]]:
        """Find an item by its ID in the statement structure.

        Args:
            item_id: The ID of the item to find.

        Returns:
            Optional[Union[Section, StatementItem]]: The found item or None if not found.
        """
        for section in self._sections:
            item = section.find_item_by_id(item_id)
            if item:
                return item
        return None

    def get_calculation_items(
        self,
    ) -> list[Union[CalculatedLineItem, SubtotalLineItem]]:
        """Get all calculation items from the statement structure.

        Returns:
            List[Union[CalculatedLineItem, SubtotalLineItem]]: List of calculation items.
        """
        calculation_items = []

        def collect_calculation_items(items: list[Union["Section", "StatementItem"]]):
            for item in items:
                if isinstance(item, (CalculatedLineItem, SubtotalLineItem)):
                    calculation_items.append(item)
                elif isinstance(item, Section):
                    collect_calculation_items(item.items)

        collect_calculation_items(self._sections)
        return calculation_items

    def get_all_items(self) -> list[Union[Section, StatementItem]]:
        """Get all items in the statement structure recursively.

        Returns:
            List[Union[Section, StatementItem]]: List of all items in the statement.
        """
        items = []
        for section in self._sections:
            items.append(section)
            items.extend(section._items)
        return items

# --- END FILE: fin_statement_model/statements/structure/containers.py ---

# --- START FILE: fin_statement_model/statements/structure/__init__.py ---
"""Statement structure package.

Re-export domain model classes from submodules.
"""

from .items import (
    StatementItem,
    StatementItemType,
    LineItem,
    CalculatedLineItem,
    SubtotalLineItem,
)
from .containers import Section, StatementStructure

__all__ = [
    "CalculatedLineItem",
    "LineItem",
    "Section",
    "StatementItem",
    "StatementItemType",
    "StatementStructure",
    "SubtotalLineItem",
]

# --- END FILE: fin_statement_model/statements/structure/__init__.py ---

# --- START FILE: fin_statement_model/statements/structure/items.py ---
"""Statement structure items module defining line items, calculated items, and subtotals."""

from abc import ABC, abstractmethod
from enum import Enum
from typing import Any, Optional

from fin_statement_model.core.errors import StatementError

__all__ = [
    "CalculatedLineItem",
    "LineItem",
    "StatementItem",
    "StatementItemType",
    "SubtotalLineItem",
]


class StatementItemType(Enum):
    """Types of statement structure items.

    Attributes:
      SECTION: Section container
      LINE_ITEM: Basic financial line item
      SUBTOTAL: Subtotal of multiple items
      CALCULATED: Derived calculation item
    """

    SECTION = "section"
    LINE_ITEM = "line_item"
    SUBTOTAL = "subtotal"
    CALCULATED = "calculated"


class StatementItem(ABC):
    """Abstract base class for all statement structure items.

    Defines a common interface: id, name, and item_type.
    """

    @property
    @abstractmethod
    def id(self) -> str:
        """Get the unique identifier of the item."""

    @property
    @abstractmethod
    def name(self) -> str:
        """Get the display name of the item."""

    @property
    @abstractmethod
    def item_type(self) -> StatementItemType:
        """Get the type of this statement item."""


class LineItem(StatementItem):
    """Represents a basic line item in a financial statement.

    Args:
      id: Unique ID for the line item
      name: Display name for the line item
      node_id: ID of the core graph node that holds values
      description: Optional explanatory text
      sign_convention: 1 for normal values, -1 for inverted
      metadata: Optional additional attributes

    Raises:
      StatementError: If inputs are invalid
    """

    def __init__(
        self,
        id: str,
        name: str,
        node_id: str,
        description: str = "",
        sign_convention: int = 1,
        metadata: Optional[dict[str, Any]] = None,
    ):
        """Initialize a basic LineItem.

        Args:
            id: Unique ID for the line item.
            name: Display name for the line item.
            node_id: ID of the core graph node holding values.
            description: Optional explanatory text.
            sign_convention: Sign convention (1 for positive, -1 for negative).
            metadata: Optional additional attributes.

        Raises:
            StatementError: If inputs are invalid.
        """
        if not id or not isinstance(id, str):
            raise StatementError(message=f"Invalid line item ID: {id}")
        if not name or not isinstance(name, str):
            raise StatementError(message=f"Invalid line item name: {name} for ID: {id}")
        if not node_id or not isinstance(node_id, str):
            raise StatementError(message=f"Invalid node ID for line item: {id}")
        if sign_convention not in (1, -1):
            raise StatementError(
                message=f"Invalid sign convention {sign_convention} for item: {id}"
            )
        self._id = id
        self._name = name
        self._node_id = node_id
        self._description = description
        self._sign_convention = sign_convention
        self._metadata = metadata or {}

    @property
    def id(self) -> str:
        """Get the unique identifier of the line item."""
        return self._id

    @property
    def name(self) -> str:
        """Get the display name of the line item."""
        return self._name

    @property
    def node_id(self) -> str:
        """Get the core graph node ID for this line item."""
        return self._node_id

    @property
    def description(self) -> str:
        """Get the description for this line item."""
        return self._description

    @property
    def sign_convention(self) -> int:
        """Get the sign convention (1 or -1)."""
        return self._sign_convention

    @property
    def metadata(self) -> dict[str, Any]:
        """Get custom metadata associated with this item."""
        return self._metadata

    @property
    def item_type(self) -> StatementItemType:
        """Get the type of this item (LINE_ITEM)."""
        return StatementItemType.LINE_ITEM


class CalculatedLineItem(LineItem):
    """Represents a calculated line item whose values come from graph calculations.

    Args:
      id: Unique ID (also used as node_id)
      name: Display name
      calculation: Dict with 'type', 'inputs', optional 'parameters'
      description: Optional description
      sign_convention: 1 or -1
      metadata: Optional metadata

    Raises:
      StatementError: If calculation dictionary is invalid
    """

    def __init__(
        self,
        id: str,
        name: str,
        calculation: dict[str, Any],
        description: str = "",
        sign_convention: int = 1,
        metadata: Optional[dict[str, Any]] = None,
    ):
        """Initialize a CalculatedLineItem based on calculation specification.

        Args:
            id: Unique ID (also used as node_id).
            name: Display name.
            calculation: Calculation spec dict with 'type', 'inputs', optional 'parameters'.
            description: Optional description.
            sign_convention: Sign convention (1 or -1).
            metadata: Optional metadata.

        Raises:
            StatementError: If calculation dictionary is invalid.
        """
        super().__init__(
            id=id,
            name=name,
            node_id=id,
            description=description,
            sign_convention=sign_convention,
            metadata=metadata,
        )
        if not isinstance(calculation, dict):
            raise StatementError(message=f"Invalid calculation spec for item: {id}")
        if "type" not in calculation:
            raise StatementError(message=f"Missing calculation type for item: {id}")
        inputs = calculation.get("inputs")
        if not isinstance(inputs, list) or not inputs:
            raise StatementError(
                message=f"Calculation inputs must be a non-empty list for item: {id}"
            )
        self._calculation = calculation

    @property
    def calculation_type(self) -> str:
        """Get the calculation operation type (e.g., 'addition')."""
        return self._calculation["type"]

    @property
    def input_ids(self) -> list[str]:
        """Get the list of input item IDs for this calculation."""
        return self._calculation["inputs"]

    @property
    def parameters(self) -> dict[str, Any]:
        """Get optional parameters for the calculation."""
        return self._calculation.get("parameters", {})

    @property
    def item_type(self) -> StatementItemType:
        """Get the type of this item (CALCULATED)."""
        return StatementItemType.CALCULATED


class SubtotalLineItem(CalculatedLineItem):
    """Represents a subtotal line item summing multiple other items.

    Args:
      id: Unique ID (also used as node_id)
      name: Display name
      item_ids: List of IDs to sum
      description: Optional description
      sign_convention: 1 or -1
      metadata: Optional metadata

    Raises:
      StatementError: If item_ids is empty or not a list
    """

    def __init__(
        self,
        id: str,
        name: str,
        item_ids: list[str],
        description: str = "",
        sign_convention: int = 1,
        metadata: Optional[dict[str, Any]] = None,
    ):
        """Initialize a SubtotalLineItem summing multiple items.

        Args:
            id: Unique ID (also used as node_id).
            name: Display name.
            item_ids: List of IDs to sum.
            description: Optional description.
            sign_convention: Sign convention (1 or -1).
            metadata: Optional metadata.

        Raises:
            StatementError: If item_ids is empty or not a list.
        """
        if not isinstance(item_ids, list) or not item_ids:
            raise StatementError(message=f"Invalid or empty item IDs for subtotal: {id}")
        calculation = {"type": "addition", "inputs": item_ids, "parameters": {}}
        super().__init__(
            id=id,
            name=name,
            calculation=calculation,
            description=description,
            sign_convention=sign_convention,
            metadata=metadata,
        )
        self._item_ids = item_ids

    @property
    def item_ids(self) -> list[str]:
        """Get the IDs of items summed by this subtotal."""
        return self._item_ids

    @property
    def item_type(self) -> StatementItemType:
        """Get the type of this item (SUBTOTAL)."""
        return StatementItemType.SUBTOTAL

# --- END FILE: fin_statement_model/statements/structure/items.py ---

# --- START FILE: fin_statement_model/statements/manager.py ---
"""Statement manager for Financial Statement Model.

This module provides a manager for handling statement structures and formatting
in the Financial Statement Model.
"""

import os
import logging
from typing import Any, Optional, Union
import pandas as pd
from pathlib import Path

from fin_statement_model.core.graph import Graph
from fin_statement_model.core.errors import StatementError, ConfigurationError
from .structure import (
    StatementStructure,
    LineItem,
)
from .config.config import load_statement_config
from .services.calculation_service import CalculationService
from .services.export_service import ExportService
from .services.format_service import FormatService

# Configure logging
logger = logging.getLogger(__name__)


class StatementManager:
    """Manages financial statement structures and their integration with the graph.

    This class handles loading statement configurations, creating the necessary
    nodes in the graph, calculating values, and formatting the results.
    """

    def __init__(self, graph: Graph):
        """Initialize a statement manager.

        Args:
            graph: The graph to use for calculations
        """
        self.graph = graph
        self.statements: dict[str, StatementStructure] = {}
        self.calculation_service = CalculationService(self.graph)
        self.export_service = ExportService(self)
        self.format_service = FormatService(self)

    def load_statement(self, config_path: str) -> StatementStructure:
        """Load a statement configuration and register it with the manager.

        Args:
            config_path: Path to the statement configuration file

        Returns:
            StatementStructure: The loaded statement structure

        Raises:
            ConfigurationError: If the configuration file is invalid or cannot be loaded
            StatementError: If the statement cannot be registered
        """
        logger.info(f"Loading statement configuration from {config_path}")
        try:
            statement = load_statement_config(config_path)
            self.register_statement(statement)
        except ConfigurationError:
            # Re-raise ConfigurationError directly
            raise
        except Exception as e:
            logger.exception(f"Unexpected error loading statement configuration from {config_path}")
            raise StatementError(
                message="Failed to load statement configuration",
                statement_id=os.path.basename(config_path),
            ) from e
        else:
            return statement

    def register_statement(self, statement: StatementStructure) -> None:
        """Register a statement structure with the manager.

        Args:
            statement: The statement structure to register

        Raises:
            StatementError: If a statement with the same ID is already registered
                or if the statement is invalid
        """
        try:
            if statement.id in self.statements:
                raise StatementError(
                    message="Statement with this ID is already registered",
                    statement_id=statement.id,
                )

            self.statements[statement.id] = statement
            logger.info(f"Registered statement '{statement.name}' with ID '{statement.id}'")
        except Exception as e:
            if isinstance(e, StatementError):
                # Re-raise StatementError
                raise
            else:
                # Wrap other exceptions
                statement_id = getattr(statement, "id", "unknown")
                logger.exception(f"Error registering statement '{statement_id}'")
                raise StatementError(
                    message="Failed to register statement", statement_id=statement_id
                ) from e

    def get_statement(self, statement_id: str) -> Optional[StatementStructure]:
        """Get a registered statement by ID.

        Args:
            statement_id: The ID of the statement to get

        Returns:
            Optional[StatementStructure]: The statement structure, or None if not found
        """
        return self.statements.get(statement_id)

    def create_calculations(self, statement_id: str) -> list[str]:
        """Delegate calculation creation to the CalculationService.

        Args:
            statement_id: The ID of the statement to create calculations for

        Returns:
            List[str]: List of created calculation node IDs
        """
        statement = self.get_statement(statement_id)
        if statement is None:
            raise StatementError(message="Statement not found", statement_id=statement_id)
        return self.calculation_service.create_calculations(statement)

    def build_data_dictionary(self, statement_id: str) -> dict[str, dict[str, float]]:
        """Build a data dictionary for a statement from the graph.

        Args:
            statement_id: The ID of the statement to build data for

        Returns:
            Dict[str, Dict[str, float]]: Dictionary mapping node IDs to period values

        Raises:
            StatementError: If the statement ID is not registered
        """
        statement = self.get_statement(statement_id)
        if statement is None:
            raise StatementError(message="Statement not found", statement_id=statement_id)

        data = {}

        # Get all items that need data
        all_items = statement.get_all_items()

        # Build data dictionary
        for item in all_items:
            if isinstance(item, LineItem):
                node_id = item.node_id
                if self.graph.get_node(node_id) is not None:
                    # Get the values for all periods
                    values = {}
                    for period in self.graph.periods:
                        try:
                            value = self.graph.calculate(node_id, period)
                            values[period] = value
                        except Exception:
                            logger.warning(f"Error calculating {node_id} for {period}")

                    if values:
                        data[node_id] = values

        return data

    def format_statement(
        self,
        statement_id: str,
        format_type: str = "dataframe",
        **fmt_kwargs: dict[str, object],
    ) -> Union[pd.DataFrame, str]:
        """Format a statement with data from the graph.

        Args:
            statement_id: The ID of the statement to format
            format_type: The type of formatting to apply ('dataframe' or 'html')
            **fmt_kwargs: Additional arguments for the formatter

        Returns:
            Union[pd.DataFrame, str]: The formatted statement (DataFrame or HTML string)

        Raises:
            StatementError: If the statement ID is not registered
            ValueError: If the format type is not supported
        """
        statement = self.get_statement(statement_id)
        if statement is None:
            raise StatementError(message="Statement not found", statement_id=statement_id)

        # Delegate to the format service
        return self.format_service.format(statement_id, format_type, **fmt_kwargs)

    def export_to_excel(self, statement_id: str, file_path: str, **kwargs: dict[str, Any]) -> None:
        """Export a statement to an Excel file.

        Args:
            statement_id: The ID of the statement to export
            file_path: Path to save the Excel file
            **kwargs: Additional arguments for the formatter

        Raises:
            StatementError: If the statement ID is not registered
            ExportError: If the export fails
        """
        return self.export_service.to_excel(statement_id, file_path, **kwargs)

    def export_to_json(
        self,
        statement_id: str,
        file_path: str,
        orient: str = "columns",
        **kwargs: dict[str, Any],
    ) -> None:
        """Export a statement to a JSON file.

        Args:
            statement_id: The ID of the statement to export
            file_path: Path to save the JSON file
            orient: JSON orientation format
            **kwargs: Additional arguments for the formatter

        Raises:
            StatementError: If the statement ID is not registered
            ExportError: If the export fails
        """
        return self.export_service.to_json(statement_id, file_path, orient=orient, **kwargs)

    def get_all_statement_ids(self) -> list[str]:
        """Get the IDs of all registered statements.

        Returns:
            List[str]: List of statement IDs
        """
        return list(self.statements.keys())

    def load_statements_from_directory(self, directory_path: str) -> list[str]:
        """Load all statement configurations from a directory.

        Args:
            directory_path: Path to the directory containing statement configurations

        Returns:
            List[str]: List of loaded statement IDs

        Raises:
            ConfigurationError: If the directory does not exist or is not a directory
        """
        loaded_ids = []
        path = Path(directory_path)

        if not path.exists() or not path.is_dir():
            raise ConfigurationError(
                message="Invalid directory path",
                config_path=directory_path,
                errors=[f"Path does not exist or is not a directory: {directory_path}"],
            )

        errors = []

        # Load all JSON and YAML files
        for file_path in path.glob("*.json"):
            try:
                statement = self.load_statement(str(file_path))
                loaded_ids.append(statement.id)
            except Exception as e:
                errors.append(f"Error loading {file_path}: {e!s}")
                logger.exception(f"Error loading statement from {file_path}")

        for file_path in path.glob("*.y*ml"):
            try:
                statement = self.load_statement(str(file_path))
                loaded_ids.append(statement.id)
            except Exception as e:
                errors.append(f"Error loading {file_path}: {e!s}")
                logger.exception(f"Error loading statement from {file_path}")

        if not loaded_ids and errors:
            # If no statements were loaded and there were errors, raise an exception
            raise ConfigurationError(
                message="Failed to load any statements from directory",
                config_path=directory_path,
                errors=errors,
            )

        logger.info(f"Loaded {len(loaded_ids)} statements from {directory_path}")
        return loaded_ids

# --- END FILE: fin_statement_model/statements/manager.py ---

# --- START FILE: fin_statement_model/statements/services/calculation_service.py ---
"""Calculation service for financial statements.

Encapsulates creation of calculation nodes and detection of circular dependencies.
"""

import logging
from typing import Union, Any

from fin_statement_model.core.errors import (
    NodeError,
    CalculationError,
    CircularDependencyError,
)
from fin_statement_model.statements.structure import (
    StatementStructure,
    CalculatedLineItem,
    SubtotalLineItem,
)
from fin_statement_model.core.calculation_engine import CalculationEngine

__all__ = ["CalculationService"]

logger = logging.getLogger(__name__)


class CalculationService:
    """Service to create calculation nodes in the graph for a given statement."""

    def __init__(self, engine: CalculationEngine):
        """Initialize the CalculationService.

        Args:
            engine: The CalculationEngine instance used for adding calculations.
        """
        self.engine = engine
        self._input_values: dict[str, Any] = {}  # Track input values for dependency resolution

    def set_input_values(self, values: dict[str, Any]) -> None:
        """Set input values for calculations.

        Args:
            values: Dictionary mapping node IDs to their values.
        """
        self._input_values = values
        # Update engine's shared registry with input values
        for node_id in values:
            if node_id not in self.engine._nodes:
                logger.warning(
                    f"Input value provided for {node_id}, but node does not exist in engine registry. "
                    "Cannot directly add value without creating a node."
                )
            else:
                # Node exists, potentially update its value if needed
                pass

    def create_calculations(self, statement: StatementStructure) -> list[str]:
        """Create calculation nodes for all calculated items in the statement.

        Args:
            statement (StatementStructure): The statement structure containing calculations.

        Returns:
            List[str]: List of created calculation node IDs.

        Raises:
            CircularDependencyError: If a circular dependency is detected.
            NodeError: If dependencies cannot be satisfied.
        """
        items = statement.get_calculation_items()

        if not items:
            return []

        processed: set[str] = set(self._input_values.keys())  # Start with known input values
        created_nodes: list[str] = []

        # Add input values to the processed set if they exist in the engine's registry
        for node_id in self._input_values:
            if node_id in self.engine._nodes:
                processed.add(node_id)
            else:
                pass

        remaining = items.copy()
        while remaining:
            progress = False

            for item in remaining[:]:
                deps_satisfied = all(
                    (
                        dep_id in processed
                        or dep_id in self._input_values
                        or dep_id in self.engine._nodes
                    )  # Check engine registry
                    for dep_id in item.input_ids
                )

                if deps_satisfied:
                    try:
                        self._create_calculation_node(item)
                        created_nodes.append(item.id)
                        processed.add(item.id)  # Mark this item's ID as processed
                        remaining.remove(item)
                        progress = True
                    except Exception:
                        logger.exception(f"Failed to create calculation node for {item.id}")
                        raise

            if not progress and remaining:
                cycle = self._detect_cycle(remaining)
                if cycle:
                    logger.error(f"Circular dependency detected: {cycle}")
                    raise CircularDependencyError(
                        message=f"Circular dependency detected in calculations: {cycle}",
                        cycle=cycle,
                    )
                else:
                    missing_deps = set()
                    for item in remaining:
                        missing_deps.update(
                            dep_id
                            for dep_id in item.input_ids
                            if not (
                                dep_id in processed
                                or dep_id in self._input_values
                                or dep_id in self.engine._nodes
                            )  # Check engine registry
                        )
                    if missing_deps:
                        raise NodeError(
                            message=f"Missing dependencies for calculations: {missing_deps}",
                            node_id=remaining[0].id,  # Report first problematic item
                        )
                    else:
                        logger.error(
                            f"Calculation stalled for items: {[it.id for it in remaining]}. No progress made, no cycle detected, and no explicit missing dependencies found in registry."
                        )
                        raise CalculationError(
                            message="Calculation stalled without clear cause.",
                            node_id=remaining[0].id,
                        )

        return created_nodes

    def _detect_cycle(self, items: list[Union[CalculatedLineItem, SubtotalLineItem]]) -> list[str]:
        """Detects a cycle in the calculation dependency graph.

        Args:
            items: List of calculation items with unresolved dependencies.

        Returns:
            List[str]: List of item IDs forming a cycle, or empty if none found.
        """
        if not items:
            return []

        item_ids = {item.id for item in items}
        graph_map = {item.id: {i for i in item.input_ids if i in item_ids} for item in items}

        visited = set()
        rec_stack = set()

        def dfs(node: str, path: list[str]) -> list[str]:
            if node in rec_stack:
                try:
                    start = path.index(node)
                    return path[start:]  # Return the cycle path
                except ValueError:
                    logger.exception(
                        f"Internal error: Node {node} in rec_stack but not in path {path}"
                    )
                    return [node]  # Fallback
            if node in visited:
                return []  # Already visited this path, no cycle found here

            visited.add(node)
            rec_stack.add(node)
            path.append(node)

            for nbr in graph_map.get(node, set()):
                cycle = dfs(nbr, path)
                if cycle:
                    return cycle  # Propagate cycle found deeper

            rec_stack.remove(node)
            path.pop()
            return []

        for nid in graph_map:
            if nid not in visited:
                cycle = dfs(nid, [])
                if cycle:
                    return cycle
        return []  # No cycle found

    def _create_calculation_node(self, item: Union[CalculatedLineItem, SubtotalLineItem]) -> None:
        """Create a calculation node in the graph for a given calculation item.

        Args:
            item: The calculation item defining type, inputs, and parameters.

        Raises:
            NodeError: If an input node does not exist in the graph.
            CalculationError: If the calculation type is unsupported.
        """
        calc_type = item.calculation_type
        inputs = item.input_ids

        for input_id in inputs:
            if input_id not in self.engine._nodes and input_id not in self._input_values:
                raise NodeError(
                    message=f"Missing input node '{input_id}' in engine registry for '{item.id}'",
                    node_id=item.id,
                )

        try:
            if calc_type in ["addition", "subtraction", "multiplication", "division"]:
                self.engine.add_calculation(item.id, inputs, calc_type, **item.parameters)
            elif calc_type == "weighted_average":
                weights = item.parameters.get("weights")
                if not weights:
                    raise CalculationError(
                        message="Weights required for weighted_average calculation",
                        node_id=item.id,
                    )
                self.engine.add_calculation(item.id, inputs, "weighted_average", weights=weights)
            elif isinstance(item, SubtotalLineItem):
                self.engine.add_calculation(item.id, inputs, "addition", **item.parameters)
            else:
                raise CalculationError(
                    message=f"Unsupported calculation type: {calc_type}",
                    node_id=item.id,
                )
        except (NodeError, CalculationError, ValueError, TypeError) as e:
            logger.exception(f"CalculationEngine failed to add calculation for '{item.id}'")
            raise CalculationError(
                message=f"Engine failed to create calculation node for {item.id}",
                node_id=item.id,
                details={"original_error": str(e)},
            )

# --- END FILE: fin_statement_model/statements/services/calculation_service.py ---

# --- START FILE: fin_statement_model/statements/services/data_service.py ---
"""Data service for financial statements.

Encapsulates building of the data dictionary from the graph and statement structure.
"""

from __future__ import annotations

import logging
from typing import TYPE_CHECKING

from fin_statement_model.statements.structure import StatementStructure, LineItem
from fin_statement_model.core.graph.graph import Graph
from fin_statement_model.statements.errors import StatementError

logger = logging.getLogger(__name__)

__all__ = ["DataService"]

if TYPE_CHECKING:
    from fin_statement_model.statements.manager import StatementManager


class DataService:
    """Service to build data dictionaries for statements."""

    def __init__(self, manager: StatementManager) -> None:
        """Initialize the DataService.

        Args:
            manager: The StatementManager instance providing graph and statements.
        """
        self.manager = manager
        self.graph: Graph = manager.graph
        self.statements: dict[str, StatementStructure] = manager.statements

    def build_data_dictionary(self, statement_id: str) -> dict[str, dict[str, float]]:
        """Build a data dictionary for a statement from the graph.

        Args:
            statement_id: The ID of the statement to build data for.

        Returns:
            Dictionary mapping node IDs to their period-value maps.

        Raises:
            StatementError: If the statement ID is not registered.
        """
        statement = self.statements.get(statement_id)
        if statement is None:
            raise StatementError(message="Statement not found", statement_id=statement_id)

        data: dict[str, dict[str, float]] = {}

        # Get all items that need data
        all_items = statement.get_all_items()

        # Build data dictionary
        for item in all_items:
            # Only line items
            if isinstance(item, LineItem):
                node_id = item.node_id
                node = self.graph.get_node(node_id)
                if node is None:
                    continue
                values = {}
                for period in self.graph.periods:
                    try:
                        value = self.graph.calculate(node_id, period)
                        values[period] = value
                    except Exception as e:
                        logger.warning(
                            f"Could not calculate value for node '{node_id}' in period '{period}'. Skipping. Error: {e}"
                        )
                        continue
                if values:
                    data[node_id] = values
        return data

# --- END FILE: fin_statement_model/statements/services/data_service.py ---

# --- START FILE: fin_statement_model/statements/services/__init__.py ---
"""Services package for statements: formatting, calculation, export, etc."""

from .formatting_service import DataFrameFormatter, HtmlFormatter
from .calculation_service import CalculationService
from .export_service import ExportService
from .format_service import FormatService

__all__ = [
    "CalculationService",
    "DataFrameFormatter",
    "ExportService",
    "FormatService",
    "HtmlFormatter",
]

# --- END FILE: fin_statement_model/statements/services/__init__.py ---

# --- START FILE: fin_statement_model/statements/services/format_service.py ---
"""Format service for financial statements.

Delegates formatting requests to DataFrameFormatter or HtmlFormatter.
"""

from __future__ import annotations

import logging
from typing import TYPE_CHECKING

from fin_statement_model.statements.services.formatting_service import (
    DataFrameFormatter,
    HtmlFormatter,
)
from fin_statement_model.statements.errors import StatementError

logger = logging.getLogger(__name__)

__all__ = ["FormatService"]

if TYPE_CHECKING:
    from fin_statement_model.statements.manager import StatementManager
    import pandas as pd


class FormatService:
    """Service to format statements into various formats."""

    def __init__(self, manager: StatementManager) -> None:
        """Initialize the FormatService.

        Args:
            manager: The StatementManager instance used for data and formatting.
        """
        self.manager = manager

    def format(
        self,
        statement_id: str,
        format_type: str = "dataframe",
        **fmt_kwargs: dict[str, object],
    ) -> pd.DataFrame | str:
        """Format a statement into the specified format.

        Args:
            statement_id: The ID of the statement to format.
            format_type: "dataframe" or "html".
            **fmt_kwargs: Additional arguments for the formatter.

        Returns:
            The formatted statement (DataFrame or HTML string).

        Raises:
            StatementError: If the statement ID is invalid or format_type is unsupported.
        """
        if format_type == "dataframe":
            return DataFrameFormatter(self.manager.get_statement(statement_id)).generate(
                self.manager.build_data_dictionary(statement_id), **fmt_kwargs
            )
        elif format_type == "html":
            return HtmlFormatter(self.manager.get_statement(statement_id)).generate(
                self.manager.build_data_dictionary(statement_id), **fmt_kwargs
            )
        else:
            raise StatementError(
                message=f"Unsupported format type: {format_type}",
                statement_id=statement_id,
            )

# --- END FILE: fin_statement_model/statements/services/format_service.py ---

# --- START FILE: fin_statement_model/statements/services/export_service.py ---
"""Export service for financial statements.

Encapsulates export of formatted statements to various file formats.
"""

from __future__ import annotations
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from fin_statement_model.statements.manager import StatementManager

from fin_statement_model.statements.errors import StatementError
from fin_statement_model.core.errors import ExportError

__all__ = ["ExportService"]


class ExportService:
    """Service to export formatted statements to files."""

    def __init__(self, manager: StatementManager) -> None:
        """Initialize the ExportService.

        Args:
            manager: The StatementManager instance used for formatting.
        """
        self.manager = manager

    def to_excel(self, statement_id: str, file_path: str, **fmt_kwargs: dict[str, object]) -> None:
        """Export a statement to an Excel file.

        Args:
            statement_id: The ID of the statement to export.
            file_path: Path to save the Excel file.
            **fmt_kwargs: Additional arguments passed to the formatter.

        Raises:
            StatementError: If the statement ID is invalid.
            ExportError: If writing the file fails.
        """
        try:
            df = self.manager.format_statement(statement_id, format_type="dataframe", **fmt_kwargs)
            df.to_excel(file_path, index=False)
        except StatementError:
            # Propagate statement lookup issues
            raise
        except Exception as e:
            raise ExportError(
                message="Failed to export statement to Excel",
                target=file_path,
                format_type="excel",
                original_error=e,
            ) from e

    def to_json(
        self,
        statement_id: str,
        file_path: str,
        orient: str = "columns",
        **fmt_kwargs: dict[str, object],
    ) -> None:
        """Export a statement to a JSON file.

        Args:
            statement_id: The ID of the statement to export.
            file_path: Path to save the JSON file.
            orient: JSON orientation (default "columns").
            **fmt_kwargs: Additional arguments passed to the formatter.

        Raises:
            StatementError: If the statement ID is invalid.
            ExportError: If writing the file fails.
        """
        try:
            df = self.manager.format_statement(statement_id, format_type="dataframe", **fmt_kwargs)
            df.to_json(file_path, orient=orient)
        except StatementError:
            raise
        except Exception as e:
            raise ExportError(
                message="Failed to export statement to JSON",
                target=file_path,
                format_type="json",
                original_error=e,
            ) from e

# --- END FILE: fin_statement_model/statements/services/export_service.py ---

# --- START FILE: fin_statement_model/statements/services/formatting_service.py ---
"""Formatting service for financial statements.

Provides classes to generate pandas DataFrame or HTML outputs from statement data.
"""

import pandas as pd
from typing import Optional

from fin_statement_model.statements.formatter import StatementFormatter
from fin_statement_model.statements.structure import StatementStructure

__all__ = ["DataFrameFormatter", "HtmlFormatter"]


class DataFrameFormatter:
    """Formatter for generating pandas DataFrame from statement data."""

    def __init__(self, structure: StatementStructure):
        """Initialize the DataFrameFormatter.

        Args:
            structure: The StatementStructure defining items and hierarchy.
        """
        self._formatter = StatementFormatter(structure)

    def generate(
        self,
        data: dict[str, dict[str, float]],
        apply_sign_convention: bool = True,
        include_empty_items: bool = False,
    ) -> pd.DataFrame:
        """Generate a formatted DataFrame of the statement.

        Args:
            data: Mapping of node IDs to period-value dicts.
            apply_sign_convention: Whether to apply sign conventions.
            include_empty_items: Whether to include items with no data.

        Returns:
            pd.DataFrame: Formatted statement DataFrame.
        """
        return self._formatter.generate_dataframe(
            data, apply_sign_convention, include_empty_items
        )


class HtmlFormatter:
    """Formatter for generating HTML representation of statement data."""

    def __init__(self, structure: StatementStructure):
        """Initialize the HtmlFormatter.

        Args:
            structure: The StatementStructure defining items and hierarchy.
        """
        self._formatter = StatementFormatter(structure)

    def generate(
        self,
        data: dict[str, dict[str, float]],
        apply_sign_convention: bool = True,
        include_empty_items: bool = False,
        css_styles: Optional[dict[str, str]] = None,
    ) -> str:
        """Generate an HTML table of the statement.

        Args:
            data: Mapping of node IDs to period-value dicts.
            apply_sign_convention: Whether to apply sign conventions.
            include_empty_items: Whether to include empty items.
            css_styles: Optional dict of CSS styles for the HTML.

        Returns:
            str: HTML string representing the statement.
        """
        return self._formatter.format_html(
            data, apply_sign_convention, include_empty_items, css_styles
        )

# --- END FILE: fin_statement_model/statements/services/formatting_service.py ---

# --- START FILE: fin_statement_model/preprocessing/transformer_factory.py ---
"""Provide TransformerFactory to create and manage data transformers.

This module implements a factory for registering and instantiating transformers.
"""

from __future__ import annotations

import importlib
import inspect
import pkgutil
import logging
from typing import ClassVar, Any

from .base_transformer import DataTransformer

logger = logging.getLogger(__name__)


class TransformerFactory:
    """Create and manage transformer instances.

    Centralizes transformer registration, discovery, and instantiation.
    """

    # Registry of transformer types
    _transformers: ClassVar[dict[str, type[DataTransformer]]] = {}

    @classmethod
    def register_transformer(cls, name: str, transformer_class: type[DataTransformer]) -> None:
        """Register a transformer class with the factory.

        Args:
            name: Name to register the transformer under
            transformer_class: The transformer class to register

        Raises:
            ValueError: If the name is already registered
            TypeError: If transformer_class is not a subclass of DataTransformer
        """
        if name in cls._transformers:
            raise ValueError(f"Transformer name '{name}' is already registered")

        if not issubclass(transformer_class, DataTransformer):
            raise TypeError("Transformer class must be a subclass of DataTransformer")

        cls._transformers[name] = transformer_class
        logger.info(f"Registered transformer '{name}'")

    @classmethod
    def create_transformer(cls, name: str, **kwargs: dict[str, Any]) -> DataTransformer:
        """Create a transformer instance by name.

        Args:
            name: Name of the registered transformer
            **kwargs: Arguments to pass to the transformer constructor

        Returns:
            DataTransformer: An instance of the requested transformer

        Raises:
            ValueError: If no transformer is registered with the given name
        """
        if name not in cls._transformers:
            raise ValueError(f"No transformer registered with name '{name}'")

        transformer_class = cls._transformers[name]
        transformer = transformer_class(**kwargs)
        logger.debug(f"Created transformer '{name}'")
        return transformer

    @classmethod
    def list_transformers(cls) -> list[str]:
        """List all registered transformer names.

        Returns:
            List[str]: List of registered transformer names
        """
        return list(cls._transformers.keys())

    @classmethod
    def get_transformer_class(cls, name: str) -> type[DataTransformer]:
        """Get a transformer class by name.

        Args:
            name: Name of the registered transformer

        Returns:
            Type[DataTransformer]: The requested transformer class

        Raises:
            ValueError: If no transformer is registered with the given name
        """
        if name not in cls._transformers:
            raise ValueError(f"No transformer registered with name '{name}'")

        return cls._transformers[name]

    @classmethod
    def discover_transformers(cls, package_name: str) -> None:
        """Discover and register all transformers in a package.

        This method imports all modules in the specified package and
        registers any DataTransformer subclasses found.

        Args:
            package_name: Name of the package to search
        """
        try:
            package = importlib.import_module(package_name)
            package_path = package.__path__

            # Import all modules in the package
            for _, module_name, _ in pkgutil.iter_modules(package_path):
                full_module_name = f"{package_name}.{module_name}"
                module = importlib.import_module(full_module_name)

                # Find all DataTransformer subclasses in the module
                for name, obj in inspect.getmembers(module):
                    if (
                        inspect.isclass(obj)
                        and issubclass(obj, DataTransformer)
                        and obj != DataTransformer
                    ):
                        # Register the transformer with its class name
                        cls.register_transformer(name, obj)

            logger.info(f"Discovered transformers from package '{package_name}'")

        except ImportError:
            logger.exception(f"Error discovering transformers from package '{package_name}'")

    @classmethod
    def create_composite_transformer(
        cls, transformer_names: list[str], **kwargs: dict[str, Any]
    ) -> DataTransformer:
        """Create a composite transformer from a list of transformer names.

        Args:
            transformer_names: List of registered transformer names to include in the pipeline
            **kwargs: Additional arguments to pass to individual transformers

        Returns:
            DataTransformer: A composite transformer containing the specified transformers

        Raises:
            ValueError: If any transformer name is not registered
        """
        from .base_transformer import CompositeTransformer

        # Use list comprehension for PERF401
        transformers = [cls.create_transformer(name, **kwargs) for name in transformer_names]

        return CompositeTransformer(transformers)

# --- END FILE: fin_statement_model/preprocessing/transformer_factory.py ---

# --- START FILE: fin_statement_model/preprocessing/transforms.py ---
"""Delegate data transformation pipeline to TransformationService.

This module provides `apply_transformation_pipeline` to run transformer sequences.
"""

from __future__ import annotations

from typing import Any
import logging


from .transformation_service import TransformationService
from .types import TabularData


logger = logging.getLogger(__name__)

__all__ = ["apply_transformation_pipeline"]


def apply_transformation_pipeline(
    data: TabularData,  # type: ignore
    transformers_config: list[dict[str, Any]],
) -> TabularData:  # type: ignore
    """Apply a sequence of transformations to data using TransformationService.

    Each config dictionary must contain a 'name' key and transformer-specific parameters.

    Args:
        data: Input data (DataFrame or dict) to transform
        transformers_config: List of transformer configuration dicts

    Returns:
        Transformed data (same type as input)
    """
    logger.debug("Applying transformer pipeline: %s", transformers_config)
    service = TransformationService()
    return service.apply_transformation_pipeline(data, transformers_config)

# --- END FILE: fin_statement_model/preprocessing/transforms.py ---

# --- START FILE: fin_statement_model/preprocessing/enums.py ---
"""Define Enum classes for preprocessing transformer types.

Centralize transformer type constants as Enums for clarity.
"""

from enum import Enum


class NormalizationType(Enum):
    """Available normalization types for NormalizationTransformer."""

    PERCENT_OF = "percent_of"
    MINMAX = "minmax"
    STANDARD = "standard"
    SCALE_BY = "scale_by"


class TransformationType(Enum):
    """Available transformation types for TimeSeriesTransformer."""

    GROWTH_RATE = "growth_rate"
    MOVING_AVG = "moving_avg"
    CAGR = "cagr"
    YOY = "yoy"
    QOQ = "qoq"


class ConversionType(Enum):
    """Available conversion types for PeriodConversionTransformer."""

    QUARTERLY_TO_ANNUAL = "quarterly_to_annual"
    MONTHLY_TO_QUARTERLY = "monthly_to_quarterly"
    MONTHLY_TO_ANNUAL = "monthly_to_annual"
    ANNUAL_TO_TTM = "annual_to_ttm"


class StatementType(Enum):
    """Available statement types for StatementFormattingTransformer."""

    INCOME_STATEMENT = "income_statement"
    BALANCE_SHEET = "balance_sheet"
    CASH_FLOW = "cash_flow"

# --- END FILE: fin_statement_model/preprocessing/enums.py ---

# --- START FILE: fin_statement_model/preprocessing/__init__.py ---
"""Export DataTransformer, CompositeTransformer, and TransformerFactory for preprocessing.

This module exposes core transformer interfaces and factory for the preprocessing layer.
"""

from .base_transformer import DataTransformer, CompositeTransformer
from .transformer_factory import TransformerFactory

__all__ = ["CompositeTransformer", "DataTransformer", "TransformerFactory"]

# --- END FILE: fin_statement_model/preprocessing/__init__.py ---

# --- START FILE: fin_statement_model/preprocessing/types.py ---
"""Define types and TypedDicts for preprocessing transformers.

This module provides TabularData alias and configuration TypedDicts.
"""

from typing import TypeAlias, TypedDict, Union
import pandas as pd

# Alias for tabular data inputs accepted by transformers
TabularData: TypeAlias = Union[pd.DataFrame, dict[str, float]]


class NormalizationConfig(TypedDict, total=False):
    """Configuration for normalization transformations.

    Attributes:
        normalization_type: 'percent_of', 'minmax', 'standard', or 'scale_by'
        reference: reference field name for 'percent_of' normalization
        scale_factor: factor to apply for 'scale_by' normalization
    """

    normalization_type: str  # 'percent_of', 'minmax', 'standard', 'scale_by'
    reference: str  # reference field name for percent_of
    scale_factor: float  # factor for scale_by normalization


class TimeSeriesConfig(TypedDict, total=False):
    """Configuration for time series transformations.

    Attributes:
        transformation_type: 'growth_rate', 'moving_avg', 'cagr', 'yoy', or 'qoq'
        periods: number of periods for percentage change or other transformations
        window_size: window size for rolling calculations
    """

    transformation_type: str  # 'growth_rate', 'moving_avg', 'cagr', 'yoy', 'qoq'
    periods: int  # periods for pct_change or other
    window_size: int  # window size for rolling calculations


class PeriodConversionConfig(TypedDict, total=False):
    """Configuration for period conversion transformations.

    Attributes:
        conversion_type: 'quarterly_to_annual', 'monthly_to_quarterly', etc.
        aggregation: aggregation method: 'sum', 'mean', 'last', etc.
    """

    conversion_type: str  # 'quarterly_to_annual', 'monthly_to_quarterly', etc.
    aggregation: str  # aggregation method: sum, mean, last, etc.


class StatementFormattingConfig(TypedDict, total=False):
    """Configuration for formatting statement output.

    Attributes:
        statement_type: 'income_statement', 'balance_sheet', 'cash_flow'
        add_subtotals: whether to insert computed subtotals
        apply_sign_convention: whether to apply sign rules to values
    """

    statement_type: str  # 'income_statement', 'balance_sheet', 'cash_flow'
    add_subtotals: bool  # whether to insert subtotals
    apply_sign_convention: bool  # whether to apply sign rules

# --- END FILE: fin_statement_model/preprocessing/types.py ---

# --- START FILE: fin_statement_model/preprocessing/base_transformer.py ---
"""Define base DataTransformer interface for preprocessing layer.

This module provides the DataTransformer abstract base class and CompositeTransformer.
"""

from abc import ABC, abstractmethod
from typing import Optional
import logging

logger = logging.getLogger(__name__)


class DataTransformer(ABC):
    """Define base class for data transformers.

    Data transformers convert data between formats and apply business rules.

    This separation follows the Single Responsibility Principle for maintainability.
    """

    def __init__(self, config: Optional[dict[str, object]] = None):
        """Initialize the transformer with optional configuration.

        Args:
            config: Optional configuration dictionary for the transformer
        """
        self.config = config or {}
        logger.debug(f"Initialized {self.__class__.__name__} with config: {self.config}")

    @abstractmethod
    def transform(self, data: object) -> object:
        """Transform the input data.

        Args:
            data: The input data to transform

        Returns:
            Transformed data

        Raises:
            ValueError: If the data cannot be transformed
        """

    def validate_input(self, data: object) -> bool:
        """Validate that the input data is acceptable for this transformer.

        This method must be overridden by subclasses with custom validation logic.

        Raises:
            NotImplementedError: if not implemented in subclass
        """
        raise NotImplementedError(f"{self.__class__.__name__} must implement validate_input()")

    def _pre_transform_hook(self, data: object) -> object:
        """Hook method called before transformation.

        Args:
            data: The input data

        Returns:
            Processed data to be passed to the transform method

        This method can be overridden by subclasses to add pre-processing steps.
        """
        return data

    def _post_transform_hook(self, data: object) -> object:
        """Hook method called after transformation.

        Args:
            data: The transformed data

        Returns:
            Final processed data

        This method can be overridden by subclasses to add post-processing steps.
        """
        return data

    def execute(self, data: object) -> object:
        """Execute the complete transformation pipeline.

        Args:
            data: The input data to transform

        Returns:
            Transformed data

        Raises:
            ValueError: If the data is invalid or cannot be transformed
        """
        if not self.validate_input(data):
            raise ValueError(f"Invalid input data for {self.__class__.__name__}")

        try:
            # Apply pre-transform hook
            processed_data = self._pre_transform_hook(data)

            # Perform transformation
            result = self.transform(processed_data)
            result = self._post_transform_hook(result)
            logger.debug(f"Successfully transformed data with {self.__class__.__name__}")
        except Exception as e:
            logger.exception(f"Error transforming data with {self.__class__.__name__}")
            raise ValueError("Error transforming data") from e
        else:
            return result


class CompositeTransformer(DataTransformer):
    """Compose multiple transformers into a pipeline.

    This allows building complex transformation chains from simple steps.
    """

    def __init__(self, transformers: list[DataTransformer], config: Optional[dict] = None):
        """Initialize with a list of transformers.

        Args:
            transformers: List of transformers to apply in sequence
            config: Optional configuration dictionary
        """
        super().__init__(config)
        self.transformers = transformers

    def transform(self, data: object) -> object:
        """Apply each transformer in sequence.

        Args:
            data: The input data to transform

        Returns:
            Data transformed by the pipeline
        """
        result = data
        for transformer in self.transformers:
            result = transformer.execute(result)
        return result

    def add_transformer(self, transformer: DataTransformer) -> None:
        """Add a transformer to the pipeline.

        Args:
            transformer: The transformer to add
        """
        self.transformers.append(transformer)

    def remove_transformer(self, index: int) -> Optional[DataTransformer]:
        """Remove a transformer from the pipeline.

        Args:
            index: Index of the transformer to remove

        Returns:
            The removed transformer or None if index is invalid
        """
        if 0 <= index < len(self.transformers):
            return self.transformers.pop(index)
        return None

    def validate_input(self, data: object) -> bool:
        """CompositeTransformer always accepts data; individual transformers validate."""
        return True

# --- END FILE: fin_statement_model/preprocessing/base_transformer.py ---

# --- START FILE: fin_statement_model/preprocessing/transformers/period_conversion.py ---
"""Financial data transformers for the Financial Statement Model.

This module provides the PeriodConversionTransformer for converting between period types:
quarterly_to_annual, monthly_to_quarterly, monthly_to_annual, and annual_to_ttm.
"""

from __future__ import annotations

import pandas as pd
from typing import Optional, Union, ClassVar

from fin_statement_model.preprocessing.base_transformer import DataTransformer
from fin_statement_model.preprocessing.types import PeriodConversionConfig
from fin_statement_model.preprocessing.enums import ConversionType

# Configure logging


class PeriodConversionTransformer(DataTransformer):
    """Transformer for converting between different period types.

    This transformer can convert:
    - Quarterly data to annual
    - Monthly data to quarterly or annual
    - Annual data to trailing twelve months (TTM)
    """

    # All valid conversion types
    CONVERSION_TYPES: ClassVar[list[str]] = [t.value for t in ConversionType]

    def __init__(
        self,
        conversion_type: Union[str, ConversionType] = ConversionType.QUARTERLY_TO_ANNUAL,
        aggregation: str = "sum",
        config: Optional[PeriodConversionConfig] = None,
    ):
        """Initialize the period conversion transformer.

        Args:
            conversion_type: Type of period conversion to apply (enum or string)
            aggregation: How to aggregate data (sum, mean, last, etc.)
            config: Optional transformer configuration
        """
        super().__init__(config)
        # Normalize enum to string
        if isinstance(conversion_type, ConversionType):
            ctype = conversion_type.value
        else:
            ctype = conversion_type
        if ctype not in self.CONVERSION_TYPES:
            raise ValueError(
                f"Invalid conversion type: {ctype}. Must be one of {self.CONVERSION_TYPES}"
            )
        self.conversion_type = ctype
        self.aggregation = aggregation

    def transform(self, data: pd.DataFrame) -> pd.DataFrame:
        """Transform data by converting between period types.

        Args:
            data: DataFrame with DatetimeIndex or period labels in the index

        Returns:
            DataFrame with transformed periods
        """
        # Ensure we have a DataFrame
        if not isinstance(data, pd.DataFrame):
            raise TypeError("Period conversion requires a pandas DataFrame")

        # Try to convert index to datetime if it's not already
        if not isinstance(data.index, pd.DatetimeIndex):
            try:
                data = data.copy()
                data.index = pd.to_datetime(data.index, format="%Y-%m-%d")
            except Exception:
                raise ValueError("Index must be convertible to datetime for period conversion")

        if self.conversion_type == ConversionType.QUARTERLY_TO_ANNUAL.value:
            # Group by year and aggregate
            return data.groupby(data.index.year).agg(self.aggregation)

        elif self.conversion_type == ConversionType.MONTHLY_TO_QUARTERLY.value:
            # Group by year and quarter
            return data.groupby([data.index.year, data.index.quarter]).agg(self.aggregation)

        elif self.conversion_type == ConversionType.MONTHLY_TO_ANNUAL.value:
            # Group by year
            return data.groupby(data.index.year).agg(self.aggregation)

        elif self.conversion_type == ConversionType.ANNUAL_TO_TTM.value:
            # Implement TTM as rolling sum with window=4 for quarterly data
            if self.aggregation == "sum":
                return data.rolling(window=4).sum()
            else:
                # For other aggregation methods, we need custom logic
                raise ValueError("annual_to_ttm conversion only supports 'sum' aggregation")

        return data  # pragma: no cover

# --- END FILE: fin_statement_model/preprocessing/transformers/period_conversion.py ---

# --- START FILE: fin_statement_model/preprocessing/transformers/time_series.py ---
"""Financial data transformers for the Financial Statement Model.

This module provides the TimeSeriesTransformer which applies growth rates,
moving averages, CAGR, year-over-year, and quarter-over-quarter conversions.
"""

import pandas as pd
from typing import Union, Optional, ClassVar

from fin_statement_model.preprocessing.types import TabularData, TimeSeriesConfig
from fin_statement_model.preprocessing.enums import TransformationType
from fin_statement_model.preprocessing.base_transformer import DataTransformer


class TimeSeriesTransformer(DataTransformer):
    """Transformer for time series financial data.

    This transformer can apply common time series transformations like:
    - Calculating growth rates
    - Calculating moving averages
    - Computing compound annual growth rate (CAGR)
    - Converting to year-over-year or quarter-over-quarter comparisons
    """

    TRANSFORMATION_TYPES: ClassVar[list[str]] = [t.value for t in TransformationType]

    def __init__(
        self,
        transformation_type: Union[str, TransformationType] = TransformationType.GROWTH_RATE,
        periods: int = 1,
        window_size: int = 3,
        config: Optional[TimeSeriesConfig] = None,
    ):
        """Initialize the time series transformer.

        Args:
            transformation_type: Type of transformation to apply
                - 'growth_rate': Calculate period-to-period growth rates
                - 'moving_avg': Calculate moving average
                - 'cagr': Calculate compound annual growth rate
                - 'yoy': Year-over-year comparison
                - 'qoq': Quarter-over-quarter comparison
            periods: Number of periods to use in calculations
            window_size: Size of the moving average window
            config: Additional configuration options
        """
        super().__init__(config)
        # Normalize to string
        if isinstance(transformation_type, TransformationType):
            ttype = transformation_type.value
        else:
            ttype = transformation_type
        if ttype not in self.TRANSFORMATION_TYPES:
            raise ValueError(
                f"Invalid transformation type: {ttype}. Must be one of {self.TRANSFORMATION_TYPES}"
            )
        self.transformation_type = ttype

        self.periods = periods
        self.window_size = window_size

    def transform(self, data: TabularData) -> TabularData:  # type: ignore
        """Transform time series data based on the configured transformation type.

        Args:
            data: DataFrame or dictionary containing time series financial data

        Returns:
            Transformed data in the same format as input
        """
        if isinstance(data, pd.DataFrame):
            return self._transform_dataframe(data)
        elif isinstance(data, dict):
            # For dictionaries, we assume the keys are time periods in chronological order
            return self._transform_dict(data)
        else:
            raise TypeError(f"Unsupported data type: {type(data)}")

    def _transform_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:
        """Transform a DataFrame with time series data."""
        result = df.copy()

        if self.transformation_type == "growth_rate":
            for col in df.columns:
                result[f"{col}_growth"] = df[col].pct_change(periods=self.periods) * 100

        elif self.transformation_type == "moving_avg":
            for col in df.columns:
                result[f"{col}_ma{self.window_size}"] = (
                    df[col].rolling(window=self.window_size).mean()
                )

        elif self.transformation_type == "cagr":
            # Assuming the index represents time periods
            n_periods = len(df) - 1
            for col in df.columns:
                start = df[col].iloc[0]
                end = df[col].iloc[-1]
                if start > 0:
                    result[f"{col}_cagr"] = ((end / start) ** (1 / n_periods) - 1) * 100

        elif self.transformation_type == "yoy":
            for col in df.columns:
                result[f"{col}_yoy"] = df[col].pct_change(periods=12) * 100

        elif self.transformation_type == "qoq":
            for col in df.columns:
                result[f"{col}_qoq"] = df[col].pct_change(periods=3) * 100

        return result

    def _transform_dict(self, data: dict) -> dict:
        """Transform a dict of time series data."""
        result = {}
        values = list(data.values())

        if self.transformation_type == "growth_rate":
            for i, (key, value) in enumerate(data.items()):
                if i == 0:
                    result[key] = None
                else:
                    prev = values[i - 1]
                    result[key] = (value - prev) / prev * 100 if prev != 0 else None

        elif self.transformation_type == "moving_avg":
            from collections import deque

            window = deque(maxlen=self.window_size)
            for key, value in data.items():
                window.append(value)
                result[key] = sum(window) / len(window) if len(window) == self.window_size else None

        elif self.transformation_type == "cagr":
            start = values[0]
            end = values[-1]
            n = len(values) - 1
            for key in data:
                result[key] = ((end / start) ** (1 / n) - 1) * 100 if start > 0 else None

        elif self.transformation_type == "yoy":
            for i, (key, value) in enumerate(data.items()):
                if i < 12:
                    result[key] = None
                else:
                    prev = values[i - 12]
                    result[key] = (value - prev) / prev * 100 if prev else None

        elif self.transformation_type == "qoq":
            for i, (key, value) in enumerate(data.items()):
                if i < 3:
                    result[key] = None
                else:
                    prev = values[i - 3]
                    result[key] = (value - prev) / prev * 100 if prev else None

        return result

# --- END FILE: fin_statement_model/preprocessing/transformers/time_series.py ---

# --- START FILE: fin_statement_model/preprocessing/transformers/__init__.py ---
"""Package for preprocessing transformers.

This package exports built-in data transformer classes for the preprocessing layer.
"""

from .normalization import NormalizationTransformer
from .time_series import TimeSeriesTransformer
from .period_conversion import PeriodConversionTransformer
from .statement_formatting import StatementFormattingTransformer

__all__ = [
    "NormalizationTransformer",
    "PeriodConversionTransformer",
    "StatementFormattingTransformer",
    "TimeSeriesTransformer",
]

# --- END FILE: fin_statement_model/preprocessing/transformers/__init__.py ---

# --- START FILE: fin_statement_model/preprocessing/transformers/statement_formatting.py ---
"""Financial data transformer for the Financial Statement Model.

This module provides the StatementFormattingTransformer for formatting financial statements:
adding subtotals, applying sign conventions, and reordering line items.
"""

import pandas as pd
from typing import Optional, Union

from fin_statement_model.preprocessing.base_transformer import DataTransformer
from fin_statement_model.preprocessing.types import StatementFormattingConfig
from fin_statement_model.preprocessing.enums import StatementType

# Configure logging


class StatementFormattingTransformer(DataTransformer):
    """Transformer for formatting financial statements.

    This transformer can:
    - Add subtotals and totals
    - Reorder line items according to standard formats
    - Apply sign conventions (negative expenses, etc.)
    """

    def __init__(
        self,
        statement_type: Union[str, StatementType] = StatementType.INCOME_STATEMENT,
        add_subtotals: bool = True,
        apply_sign_convention: bool = True,
        config: Optional[StatementFormattingConfig] = None,
    ):
        """Initialize the statement formatting transformer.

        Args:
            statement_type: Type of statement ('income_statement', 'balance_sheet', 'cash_flow')
            add_subtotals: Whether to add standard subtotals
            apply_sign_convention: Whether to apply standard sign conventions
            config: Additional configuration options
        """
        super().__init__(config)
        # Normalize enum to string
        if isinstance(statement_type, StatementType):
            stype = statement_type.value
        else:
            stype = statement_type
        if stype not in [t.value for t in StatementType]:
            raise ValueError(
                f"Invalid statement type: {stype}. Must be one of {[t.value for t in StatementType]}"
            )
        self.statement_type = stype
        self.add_subtotals = add_subtotals
        self.apply_sign_convention = apply_sign_convention

        # Define standard orderings for different statement types
        self.item_order = self._get_standard_order()

    def _get_standard_order(self) -> list[str]:
        """Get the standard ordering of items for the current statement type."""
        if self.statement_type == "income_statement":
            return [
                "revenue",
                "total_revenue",
                "cost_of_goods_sold",
                "gross_profit",
                "operating_expenses",
                "operating_income",
                "other_income",
                "interest_expense",
                "interest_income",
                "income_before_taxes",
                "income_tax",
                "net_income",
            ]

        elif self.statement_type == "balance_sheet":
            return [
                # Assets
                "cash_and_equivalents",
                "short_term_investments",
                "accounts_receivable",
                "inventory",
                "current_assets",
                "property_plant_equipment",
                "long_term_investments",
                "intangible_assets",
                "total_assets",
                # Liabilities
                "accounts_payable",
                "short_term_debt",
                "current_liabilities",
                "long_term_debt",
                "total_liabilities",
                # Equity
                "common_stock",
                "retained_earnings",
                "total_equity",
                "total_liabilities_and_equity",
            ]

        elif self.statement_type == "cash_flow":
            return [
                "net_income",
                "depreciation_amortization",
                "changes_in_working_capital",
                "cash_from_operating_activities",
                "capital_expenditures",
                "investments",
                "cash_from_investing_activities",
                "debt_issuance",
                "debt_repayment",
                "dividends",
                "share_repurchases",
                "cash_from_financing_activities",
                "net_change_in_cash",
            ]

        return []  # pragma: no cover

    def transform(self, data: pd.DataFrame) -> pd.DataFrame:
        """Format a financial statement DataFrame.

        Args:
            data: DataFrame containing financial statement data

        Returns:
            Formatted DataFrame
        """
        result = data.copy()

        if self.apply_sign_convention:
            result = self._apply_sign_convention(result)

        if self.add_subtotals:
            result = self._add_subtotals(result)

        result = self._reorder_items(result)

        return result

    def _apply_sign_convention(self, df: pd.DataFrame) -> pd.DataFrame:
        """Apply standard sign conventions to line items."""
        result = df.copy()
        negative_items: list[str] = []

        if self.statement_type == "income_statement":
            negative_items = [
                "cost_of_goods_sold",
                "operating_expenses",
                "interest_expense",
                "income_tax",
            ]

        elif self.statement_type == "cash_flow":
            negative_items = [
                "capital_expenditures",
                "investments",
                "debt_repayment",
                "dividends",
                "share_repurchases",
            ]

        for item in negative_items:
            if item in result.index:
                result.loc[item] = (
                    result.loc[item] * -1 if result.loc[item].mean() > 0 else result.loc[item]
                )

        return result

    def _add_subtotals(self, df: pd.DataFrame) -> pd.DataFrame:
        """Add standard subtotals to the statement."""
        result = df.copy()

        if self.statement_type == "income_statement":
            if (
                "revenue" in result.index
                and "cost_of_goods_sold" in result.index
                and "gross_profit" not in result.index
            ):
                result.loc["gross_profit"] = (
                    result.loc["revenue"] + result.loc["cost_of_goods_sold"]
                )

            if (
                "gross_profit" in result.index
                and "operating_expenses" in result.index
                and "operating_income" not in result.index
            ):
                result.loc["operating_income"] = (
                    result.loc["gross_profit"] + result.loc["operating_expenses"]
                )

            if (
                "operating_income" in result.index
                and "interest_expense" in result.index
                and "income_before_taxes" not in result.index
            ):
                result.loc["income_before_taxes"] = (
                    result.loc["operating_income"] + result.loc["interest_expense"]
                )

            if (
                "income_before_taxes" in result.index
                and "income_tax" in result.index
                and "net_income" not in result.index
            ):
                result.loc["net_income"] = (
                    result.loc["income_before_taxes"] + result.loc["income_tax"]
                )

        elif self.statement_type == "balance_sheet":
            current_assets = [
                "cash_and_equivalents",
                "short_term_investments",
                "accounts_receivable",
                "inventory",
            ]
            if (
                any(item in result.index for item in current_assets)
                and "current_assets" not in result.index
            ):
                result.loc["current_assets"] = sum(
                    result.loc[item] for item in current_assets if item in result.index
                )

            if (
                "current_assets" in result.index
                and "property_plant_equipment" in result.index
                and "total_assets" not in result.index
            ):
                result.loc["total_assets"] = (
                    result.loc["current_assets"] + result.loc["property_plant_equipment"]
                )

            current_liabilities = ["accounts_payable", "short_term_debt"]
            if (
                any(item in result.index for item in current_liabilities)
                and "current_liabilities" not in result.index
            ):
                result.loc["current_liabilities"] = sum(
                    result.loc[item] for item in current_liabilities if item in result.index
                )

            if (
                "current_liabilities" in result.index
                and "long_term_debt" in result.index
                and "total_liabilities" not in result.index
            ):
                result.loc["total_liabilities"] = (
                    result.loc["current_liabilities"] + result.loc["long_term_debt"]
                )

            equity_items = ["common_stock", "retained_earnings"]
            if (
                any(item in result.index for item in equity_items)
                and "total_equity" not in result.index
            ):
                result.loc["total_equity"] = sum(
                    result.loc[item] for item in equity_items if item in result.index
                )  # pragma: no cover

            if (
                "total_liabilities" in result.index
                and "total_equity" in result.index
                and "total_liabilities_and_equity" not in result.index
            ):
                result.loc["total_liabilities_and_equity"] = (
                    result.loc["total_liabilities"] + result.loc["total_equity"]
                )  # pragma: no cover

        elif self.statement_type == "cash_flow":
            operating_items = [
                "net_income",
                "depreciation_amortization",
                "changes_in_working_capital",
            ]
            if (
                any(item in result.index for item in operating_items)
                and "cash_from_operating_activities" not in result.index
            ):
                result.loc["cash_from_operating_activities"] = sum(
                    result.loc[item] for item in operating_items if item in result.index
                )

            investing_items = ["capital_expenditures", "investments"]
            if (
                any(item in result.index for item in investing_items)
                and "cash_from_investing_activities" not in result.index
            ):
                result.loc["cash_from_investing_activities"] = sum(
                    result.loc[item] for item in investing_items if item in result.index
                )

            financing_items = [
                "debt_issuance",
                "debt_repayment",
                "dividends",
                "share_repurchases",
            ]
            if (
                any(item in result.index for item in financing_items)
                and "cash_from_financing_activities" not in result.index
            ):
                result.loc["cash_from_financing_activities"] = sum(
                    result.loc[item] for item in financing_items if item in result.index
                )

            cash_flow_categories = [
                "cash_from_operating_activities",
                "cash_from_investing_activities",
                "cash_from_financing_activities",
            ]
            if (
                any(item in result.index for item in cash_flow_categories)
                and "net_change_in_cash" not in result.index
            ):
                result.loc["net_change_in_cash"] = sum(
                    result.loc[item] for item in cash_flow_categories if item in result.index
                )

        return result

    def _reorder_items(self, df: pd.DataFrame) -> pd.DataFrame:
        """Reorder the DataFrame according to standard financial statement ordering."""
        ordered_items = [item for item in self.item_order if item in df.index]
        ordered_items.extend([item for item in df.index if item not in self.item_order])
        return df.loc[ordered_items]

# --- END FILE: fin_statement_model/preprocessing/transformers/statement_formatting.py ---

# --- START FILE: fin_statement_model/preprocessing/transformers/normalization.py ---
"""Provide a NormalizationTransformer to normalize financial data.

Transforms data by percent_of, minmax, standard, or scale_by methods.

This module implements the NormalizationTransformer for the preprocessing layer.
"""

from __future__ import annotations

from typing import Optional, Union, ClassVar

import numpy as np
import pandas as pd

from fin_statement_model.preprocessing.base_transformer import DataTransformer
from fin_statement_model.preprocessing.enums import NormalizationType
from fin_statement_model.preprocessing.types import NormalizationConfig, TabularData


class NormalizationTransformer(DataTransformer):
    """Transformer that normalizes financial data.

    This transformer can normalize values by:
    - Dividing by a reference value (e.g. convert to percentages of revenue)
    - Scaling to a specific range (e.g. 0-1)
    - Applying standard normalization ((x - mean) / std)

    It can operate on DataFrames or dictionary data structures.
    """

    NORMALIZATION_TYPES: ClassVar[list[str]] = [t.value for t in NormalizationType]

    def __init__(
        self,
        normalization_type: Union[str, NormalizationType] = NormalizationType.PERCENT_OF,
        reference: Optional[str] = None,
        scale_factor: Optional[float] = None,
        config: Optional[NormalizationConfig] = None,
    ):
        """Initialize the normalizer.

        Args:
            normalization_type: Type of normalization to apply
                - 'percent_of': Divides by a reference value
                - 'minmax': Scales to range [0,1]
                - 'standard': Applies (x - mean) / std
                - 'scale_by': Multiplies by a scale factor
            reference: Reference field for percent_of normalization
            scale_factor: Factor to scale by for scale_by normalization
            config: Additional configuration options
        """
        super().__init__(config)
        # Normalize enum to string
        if isinstance(normalization_type, NormalizationType):
            norm_type = normalization_type.value
        else:
            norm_type = normalization_type
        if norm_type not in self.NORMALIZATION_TYPES:
            raise ValueError(
                f"Invalid normalization type: {norm_type}. "
                f"Must be one of {self.NORMALIZATION_TYPES}"
            )
        self.normalization_type = norm_type

        self.reference = reference
        self.scale_factor = scale_factor

        # Validation
        if self.normalization_type == NormalizationType.PERCENT_OF.value and not reference:
            raise ValueError("Reference field must be provided for percent_of normalization")

        if self.normalization_type == NormalizationType.SCALE_BY.value and scale_factor is None:
            raise ValueError("Scale factor must be provided for scale_by normalization")

    def transform(self, data: TabularData) -> TabularData:  # type: ignore
        """Normalize the data based on the configured normalization type.

        Args:
            data: DataFrame or dictionary containing financial data

        Returns:
            Normalized data in the same format as input
        """
        if isinstance(data, pd.DataFrame):
            return self._transform_dataframe(data)
        elif isinstance(data, dict):
            return self._transform_dict(data)
        else:
            raise TypeError(f"Unsupported data type: {type(data)}")

    def _transform_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:
        """Transform a DataFrame."""
        result = df.copy()

        if self.normalization_type == NormalizationType.PERCENT_OF.value:
            if self.reference not in df.columns:
                raise ValueError(f"Reference column '{self.reference}' not found in DataFrame")

            for col in df.columns:
                if col != self.reference:
                    result[col] = df[col] / df[self.reference] * 100

        elif self.normalization_type == NormalizationType.MINMAX.value:  # pragma: no cover
            for col in df.columns:
                min_val = df[col].min()
                max_val = df[col].max()

                if max_val > min_val:
                    result[col] = (df[col] - min_val) / (max_val - min_val)  # pragma: no cover

        elif self.normalization_type == NormalizationType.STANDARD.value:
            for col in df.columns:
                mean = df[col].mean()
                std = df[col].std()

                if std > 0:
                    result[col] = (df[col] - mean) / std

        elif self.normalization_type == NormalizationType.SCALE_BY.value:
            for col in df.columns:
                result[col] = df[col] * self.scale_factor

        return result

    def _transform_dict(self, data: dict) -> dict:
        """Transform a dictionary."""
        result = {}

        if self.normalization_type == NormalizationType.PERCENT_OF.value:
            if self.reference not in data:
                raise ValueError(f"Reference key '{self.reference}' not found in data")

            ref_value = data[self.reference]
            for key, value in data.items():
                if key != self.reference and ref_value != 0:
                    result[key] = value / ref_value * 100
                else:
                    result[key] = value

        elif self.normalization_type == NormalizationType.MINMAX.value:
            values = list(data.values())
            min_val = min(values)
            max_val = max(values)

            if max_val > min_val:
                for key, value in data.items():
                    result[key] = (value - min_val) / (max_val - min_val)
            else:
                result = data.copy()

        elif self.normalization_type == NormalizationType.STANDARD.value:
            values = list(data.values())
            mean = sum(values) / len(values)
            std = np.std(list(values))

            if std > 0:
                for key, value in data.items():
                    result[key] = (value - mean) / std
            else:
                result = data.copy()

        elif self.normalization_type == NormalizationType.SCALE_BY.value:
            for key, value in data.items():
                result[key] = value * self.scale_factor

        return result

# --- END FILE: fin_statement_model/preprocessing/transformers/normalization.py ---

# --- START FILE: fin_statement_model/preprocessing/transformation_service.py ---
"""Transformation Service for the Financial Statement Model.

This module provides a high-level service for managing and applying data transformations.
"""

from typing import Optional, Union

import pandas as pd
import logging

from .base_transformer import DataTransformer, CompositeTransformer
from .transformer_factory import TransformerFactory

logger = logging.getLogger(__name__)


class TransformationService:
    """Service for managing and applying data transformations.

    This service separates data transformation logic from data processing,
    making it easier to maintain, test, and extend the codebase.

    It provides methods for common financial data transformations and allows
    for composing multiple transformations into pipelines.
    """

    def __init__(self):
        """Initialize the transformation service."""
        # Register built-in transformers
        self._register_builtin_transformers()
        logger.info("TransformationService initialized")

    def _register_builtin_transformers(self):
        """Automatically discover and register all transformers."""
        # Discover all DataTransformer subclasses in the transformers package
        TransformerFactory.discover_transformers("fin_statement_model.preprocessing.transformers")
        # Register snake_case aliases (e.g., 'normalization') for each discovered transformer
        import re

        existing = TransformerFactory.list_transformers()
        for class_name in existing:
            # Convert CamelCase to snake_case and strip '_transformer'
            snake = re.sub(r"(.)([A-Z][a-z]+)", r"\1_\2", class_name)
            snake = re.sub(r"([a-z0-9])([A-Z])", r"\1_\2", snake).lower()
            alias = snake.replace("_transformer", "")
            if alias not in existing:
                cls = TransformerFactory.get_transformer_class(class_name)
                TransformerFactory.register_transformer(alias, cls)

    def normalize_data(
        self,
        data: Union[pd.DataFrame, dict],
        normalization_type: str = "percent_of",
        reference: Optional[str] = None,
        scale_factor: Optional[float] = None,
    ) -> Union[pd.DataFrame, dict]:
        """Normalize financial data.

        Args:
            data: The data to normalize (DataFrame or Dict)
            normalization_type: Type of normalization
            reference: Reference field for percent_of normalization
            scale_factor: Scale factor for scale_by normalization

        Returns:
            Normalized data
        """
        transformer = TransformerFactory.create_transformer(
            "normalization",
            normalization_type=normalization_type,
            reference=reference,
            scale_factor=scale_factor,
        )

        return transformer.execute(data)

    def transform_time_series(
        self,
        data: Union[pd.DataFrame, dict],
        transformation_type: str = "growth_rate",
        periods: int = 1,
        window_size: int = 3,
    ) -> Union[pd.DataFrame, dict]:
        """Apply time series transformations to financial data.

        Args:
            data: The time series data to transform
            transformation_type: Type of transformation
            periods: Number of periods for calculations
            window_size: Window size for moving averages

        Returns:
            Transformed data
        """
        transformer = TransformerFactory.create_transformer(
            "time_series",
            transformation_type=transformation_type,
            periods=periods,
            window_size=window_size,
        )

        return transformer.execute(data)

    def convert_periods(
        self, data: pd.DataFrame, conversion_type: str, aggregation: str = "sum"
    ) -> pd.DataFrame:
        """Convert data between different period types.

        Args:
            data: DataFrame with time periods
            conversion_type: Type of period conversion
            aggregation: Aggregation method

        Returns:
            Transformed DataFrame with converted periods
        """
        transformer = TransformerFactory.create_transformer(
            "period_conversion",
            conversion_type=conversion_type,
            aggregation=aggregation,
        )

        return transformer.execute(data)

    def format_statement(
        self,
        data: pd.DataFrame,
        statement_type: str = "income_statement",
        add_subtotals: bool = True,
        apply_sign_convention: bool = True,
    ) -> pd.DataFrame:
        """Format a financial statement DataFrame.

        Args:
            data: Financial statement data
            statement_type: Type of statement
            add_subtotals: Whether to add standard subtotals
            apply_sign_convention: Whether to apply sign conventions

        Returns:
            Formatted financial statement
        """
        transformer = TransformerFactory.create_transformer(
            "statement_formatting",
            statement_type=statement_type,
            add_subtotals=add_subtotals,
            apply_sign_convention=apply_sign_convention,
        )

        return transformer.execute(data)

    def create_transformation_pipeline(
        self, transformers_config: list[dict[str, object]]
    ) -> DataTransformer:
        """Create a composite transformer from a list of transformer configurations.

        Args:
            transformers_config: List of dicts with transformer configurations
                Each dict should have:
                - 'name': Name of the transformer
                - Additional configuration parameters for that transformer

        Returns:
            A composite transformer with the configured pipeline

        Example:
            config = [
                {'name': 'period_conversion', 'conversion_type': 'quarterly_to_annual'},
                {'name': 'normalization', 'normalization_type': 'percent_of', 'reference': 'revenue'}
            ]
            pipeline = service.create_transformation_pipeline(config)
            transformed_data = pipeline.execute(data)
        """
        transformers = []

        for config in transformers_config:
            if "name" not in config:
                raise ValueError("Each transformer configuration must have a 'name' field")

            name = config.pop("name")
            transformer = TransformerFactory.create_transformer(name, **config)
            transformers.append(transformer)

        return CompositeTransformer(transformers)

    def apply_transformation_pipeline(
        self, data: object, transformers_config: list[dict[str, object]]
    ) -> object:
        """Apply a transformation pipeline to data.

        Args:
            data: The data to transform
            transformers_config: List of transformer configurations

        Returns:
            Transformed data
        """
        pipeline = self.create_transformation_pipeline(transformers_config)
        return pipeline.execute(data)

    def register_custom_transformer(
        self, name: str, transformer_class: type[DataTransformer]
    ) -> None:
        """Register a custom transformer with the factory.

        Args:
            name: Name for the transformer
            transformer_class: The transformer class to register
        """
        TransformerFactory.register_transformer(name, transformer_class)
        logger.info(f"Registered custom transformer: {name}")

    def list_available_transformers(self) -> list[str]:
        """List all available transformer types.

        Returns:
            List of transformer names
        """
        return TransformerFactory.list_transformers()

# --- END FILE: fin_statement_model/preprocessing/transformation_service.py ---

